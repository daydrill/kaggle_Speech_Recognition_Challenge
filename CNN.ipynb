{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.fftpack import fft\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "from glob import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "import gc\n",
    "from scipy.io import wavfile\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import optimizers, losses, activations, models\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.layers import Convolution2D, Dense, Input, Flatten, Dropout, MaxPooling2D, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# new_sample_rate = 8000\n",
    "\n",
    "LABELS = ['_silence', '_unknown', 'down', 'go', 'left', 'no', 'off', 'on', 'right', 'stop', 'up', 'yes']\n",
    "TRAIN_PATH = './input/train/audio/'\n",
    "TEST_PATH = './input/test/audio/'\n",
    "OUTPUT_PATH = './output/'\n",
    "MODEL_NAME = 'cnn_new.h5'\n",
    "\n",
    "# class_weight = {0: 13.0,\n",
    "#  1: 1.0,\n",
    "#  2: 9.0,\n",
    "#  3: 9.0,\n",
    "#  4: 9.0,\n",
    "#  5: 9.0,\n",
    "#  6: 9.0,\n",
    "#  7: 5.0,\n",
    "#  8: 9.0,\n",
    "#  9: 9.0,\n",
    "#  10: 9.0,\n",
    "#  11: 9.0}\n",
    "\n",
    "# class_weight = {0: 10.0,\n",
    "#  1: 1.0,\n",
    "#  2: 1.0,\n",
    "#  3: 1.0,\n",
    "#  4: 1.0,\n",
    "#  5: 1.0,\n",
    "#  6: 1.0,\n",
    "#  7: 1.0,\n",
    "#  8: 1.0,\n",
    "#  9: 1.0,\n",
    "#  10: 1.0,\n",
    "#  11: 1.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 원본 클래스 비율\n",
    "# {0: 1200,\n",
    "#  1: 41039,\n",
    "#  2: 2359,\n",
    "#  3: 2372,\n",
    "#  4: 2353,\n",
    "#  5: 2375,\n",
    "#  6: 2357,\n",
    "#  7: 2367,\n",
    "#  8: 2367,\n",
    "#  9: 2380,\n",
    "#  10: 2375,\n",
    "#  11: 2377}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## custom_fft and log_specgram functions written by DavidS.\n",
    "def custom_fft(y, fs):\n",
    "    T = 1.0 / fs\n",
    "    N = y.shape[0]\n",
    "    yf = fft(y)\n",
    "    xf = np.linspace(0.0, 1.0/(2.0*T), N//2)\n",
    "    # FFT 는 대칭(simmetrical)이므로 반쪽만 얻음.\n",
    "    # FFT 는 복소수이므로 실수값만 취하기 위해 abs()\n",
    "    vals = 2.0/N * np.abs(yf[0:N//2])\n",
    "    return xf, vals\n",
    "\n",
    "def log_specgram(audio, sample_rate, window_size=20, step_size=10, eps=1e-10):\n",
    "    nperseg = int(round(window_size * sample_rate / 1e3))\n",
    "    noverlap = int(round(step_size * sample_rate / 1e3))\n",
    "    freqs, times, spec = signal.spectrogram(audio,\n",
    "                                    fs=sample_rate,\n",
    "                                    window='hann',\n",
    "                                    nperseg=nperseg,\n",
    "                                    noverlap=noverlap,\n",
    "                                    detrend=False)\n",
    "    return freqs, times, np.log(spec.T.astype(np.float32) + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## utility function to grab all wav files inside train data folder.\n",
    "def list_wavs_fname(dirpath, ext='wav'):\n",
    "    print(dirpath)\n",
    "    fpaths = glob(os.path.join(dirpath, r'*/*' + ext))\n",
    "    pat = r'.+/(\\w+)/\\w+\\.' + ext + '$'\n",
    "    labels = []\n",
    "    for fpath in fpaths:\n",
    "        r = re.match(pat, fpath)\n",
    "        if r:\n",
    "            labels.append(r.group(1))\n",
    "    pat = r'.+/(\\w+\\.' + ext + ')$'\n",
    "    fnames = []\n",
    "    for fpath in fpaths:\n",
    "        r = re.match(pat, fpath)\n",
    "        if r:\n",
    "            fnames.append(r.group(1))\n",
    "    return labels, fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pad_audio(samples, L=16000):\n",
    "    '''\n",
    "    pad audios that are less than 16000(1 second) with 0s to make them all have the same length.\n",
    "    '''\n",
    "    if len(samples) >= L: \n",
    "        return samples\n",
    "    else: \n",
    "        return np.pad(samples, pad_width=(L - len(samples), 0), mode='constant', constant_values=(0, 0)) \n",
    "        # sample 앞뒤로 constant_values[0]과 constant_values[1]을 각각 pad_width 갯수 만큼 패딩\n",
    "        # 총길이는 len(samples) + 2*pad_width\n",
    "\n",
    "# def chop_audio(samples, L=16000, num=200):\n",
    "#     '''\n",
    "#     chop audios that are larger than 16000(eg. wav files in background noises folder) to 16000 in length.\n",
    "#     create several chunks out of one large wav files given the parameter 'num'.\n",
    "#     '''\n",
    "#     for i in range(num):\n",
    "#         beg = np.random.randint(0, len(samples) - L)\n",
    "#         yield samples[beg: beg + L]\n",
    "\n",
    "def label_transform(labels):\n",
    "    '''\n",
    "    레이블 정규화 및 one-hot벡터화 (더미화)\n",
    "    '''\n",
    "    nlabels = []\n",
    "    for label in labels:\n",
    "        if label == '_background_noise_':\n",
    "            nlabels.append('_silence')\n",
    "        elif label not in LABELS:\n",
    "            nlabels.append('_unknown')\n",
    "        else:\n",
    "            nlabels.append(label)\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(nlabels)\n",
    "    nlabels = encoder.transform(nlabels)\n",
    "    return nlabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Data & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Load labels, fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./input/train/audio/\n"
     ]
    }
   ],
   "source": [
    "labels, fnames = list_wavs_fname(TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sample_rate, samples = wavfile.read(os.path.join(TRAIN_PATH, labels[0], fnames[0]))\n",
    "# len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 23s, sys: 3.18 s, total: 1min 26s\n",
      "Wall time: 1min 26s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chi/anaconda3/lib/python3.5/site-packages/scipy/io/wavfile.py:273: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  WavFileWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y = []\n",
    "X = []\n",
    "for i, (label, fname) in enumerate(zip(labels, fnames)):\n",
    "    sample_rate, samples = wavfile.read(os.path.join(TRAIN_PATH, label, fname))\n",
    "    if len(samples) > 16000:\n",
    "        pass\n",
    "    else:\n",
    "        samples = pad_audio(samples)\n",
    "#         resampled = signal.resample(samples, int(new_sample_rate / sample_rate * samples.shape[0]))\n",
    "#         _, _, specgram = log_specgram(resampled, sample_rate=new_sample_rate)\n",
    "        _, _, specgram = log_specgram(samples, sample_rate=16000)\n",
    "        y.append(label)\n",
    "        X.append(specgram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "X = X.reshape(tuple(list(X.shape) + [1])) # (64841, 99, 81, 1) 로 reshape\n",
    "y = to_categorical(label_transform(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Train Validation Set Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.05, random_state=1130) # 9:1로 train, valid 셋 나눔.\n",
    "del X, y\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = load_model(os.path.join(OUTPUT_PATH, MODEL_NAME))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape = (99, 161, 1) #(99, 81, 1) # in order to fit into Conv2D layer, we need to reshape it.\n",
    "nclass = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 99, 161, 1)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 99, 161, 1)        4         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 98, 160, 8)        40        \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 97, 159, 8)        264       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 48, 79, 8)         0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 48, 79, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 46, 77, 16)        1168      \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 44, 75, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 22, 37, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 20, 35, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 18, 33, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 9, 16, 32)         0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 9, 16, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 7, 14, 32)         9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 3, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 3, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 672)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 128)               86144     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 12)                1548      \n",
      "=================================================================\n",
      "Total params: 148,672\n",
      "Trainable params: 148,158\n",
      "Non-trainable params: 514\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Modeling\n",
    "inp = Input(shape=input_shape)\n",
    "norm_inp = BatchNormalization()(inp)\n",
    "img_1 = Convolution2D(8, kernel_size=2, activation=activations.relu)(norm_inp)\n",
    "img_1 = Convolution2D(8, kernel_size=2, activation=activations.relu)(img_1)\n",
    "img_1 = MaxPooling2D(pool_size=(2, 2))(img_1)\n",
    "img_1 = Dropout(rate=0.2)(img_1)\n",
    "img_1 = Convolution2D(16, kernel_size=3, activation=activations.relu)(img_1)\n",
    "img_1 = Convolution2D(16, kernel_size=3, activation=activations.relu)(img_1)\n",
    "img_1 = MaxPooling2D(pool_size=(2, 2))(img_1)\n",
    "img_1 = Convolution2D(32, kernel_size=3, activation=activations.relu)(img_1)\n",
    "img_1 = Convolution2D(32, kernel_size=3, activation=activations.relu)(img_1)\n",
    "img_1 = MaxPooling2D(pool_size=(2, 2))(img_1)\n",
    "img_1 = Dropout(rate=0.2)(img_1)\n",
    "img_1 = Convolution2D(32, kernel_size=3, activation=activations.relu)(img_1)\n",
    "img_1 = MaxPooling2D(pool_size=(2, 2))(img_1)\n",
    "img_1 = Dropout(rate=0.2)(img_1)\n",
    "img_1 = Flatten()(img_1)\n",
    "\n",
    "dense_1 = BatchNormalization()(Dense(128, activation=activations.relu)(img_1))\n",
    "dense_1 = Dropout(rate=0.2)(dense_1)\n",
    "dense_1 = BatchNormalization()(Dense(128, activation=activations.relu)(dense_1))\n",
    "dense_1 = Dense(128, activation=activations.relu)(dense_1)\n",
    "dense_1 = Dense(nclass, activation=activations.softmax)(dense_1)\n",
    "\n",
    "model = models.Model(inputs=inp, outputs=dense_1)\n",
    "opt = optimizers.Adam()\n",
    "\n",
    "model.compile(optimizer=opt, loss=losses.binary_crossentropy, metrics=['categorical_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ## Modeling\n",
    "# inp = Input(shape=input_shape)\n",
    "# norm_inp = BatchNormalization()(inp)\n",
    "# img_1 = Convolution2D(8, kernel_size=2, activation=activations.relu, padding='same')(norm_inp)\n",
    "# img_1 = Convolution2D(8, kernel_size=2, activation=activations.relu, padding='same')(img_1)\n",
    "# img_1 = MaxPooling2D(pool_size=(2, 2))(img_1)\n",
    "# img_1 = Dropout(rate=0.2)(img_1)\n",
    "# img_1 = Convolution2D(16, kernel_size=2, activation=activations.relu, padding='same')(img_1)\n",
    "# img_1 = Convolution2D(16, kernel_size=2, activation=activations.relu, padding='same')(img_1)\n",
    "# img_1 = MaxPooling2D(pool_size=(2, 2))(img_1)\n",
    "# img_1 = Dropout(rate=0.2)(img_1)\n",
    "# img_1 = Convolution2D(16, kernel_size=3, activation=activations.relu, padding='same')(img_1)\n",
    "# img_1 = Convolution2D(16, kernel_size=3, activation=activations.relu, padding='same')(img_1)\n",
    "# img_1 = MaxPooling2D(pool_size=(2, 2))(img_1)\n",
    "# img_1 = Dropout(rate=0.2)(img_1)\n",
    "# img_1 = Convolution2D(32, kernel_size=3, activation=activations.relu, padding='same')(img_1)\n",
    "# img_1 = MaxPooling2D(pool_size=(2, 2))(img_1)\n",
    "# img_1 = Dropout(rate=0.2)(img_1)\n",
    "# img_1 = Flatten()(img_1)\n",
    "\n",
    "# dense_1 = BatchNormalization()(img_1)\n",
    "# dense_1 = Dense(512, activation=activations.relu)(dense_1)\n",
    "# dense_1 = Dropout(rate=0.2)(dense_1)\n",
    "# dense_1 = Dense(512, activation=activations.relu)(dense_1)\n",
    "# dense_1 = Dropout(rate=0.2)(dense_1)\n",
    "# dense_1 = Dense(512, activation=activations.relu)(dense_1)\n",
    "# dense_1 = Dropout(rate=0.2)(dense_1)\n",
    "# dense_1 = Dense(128, activation=activations.relu)(dense_1)\n",
    "# dense_1 = Dropout(rate=0.2)(dense_1)\n",
    "# dense_1 = Dense(64, activation=activations.relu)(dense_1)\n",
    "# dense_1 = Dense(nclass, activation=activations.softmax)(dense_1)\n",
    "\n",
    "# model = models.Model(inputs=inp, outputs=dense_1)\n",
    "# opt = optimizers.Adam(lr=0.001)\n",
    "\n",
    "# model.compile(optimizer=opt, loss=losses.binary_crossentropy, metrics=['categorical_accuracy'])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 네트워크 시각화\n",
    "# plot_model(model, to_file='output/model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 93413 samples, validate on 4917 samples\n",
      "Epoch 1/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.2056 - categorical_accuracy: 0.5676 - val_loss: 0.2153 - val_categorical_accuracy: 0.6179\n",
      "Epoch 2/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.1693 - categorical_accuracy: 0.6424 - val_loss: 0.1883 - val_categorical_accuracy: 0.6179\n",
      "Epoch 3/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.1256 - categorical_accuracy: 0.7044 - val_loss: 0.1899 - val_categorical_accuracy: 0.6179\n",
      "Epoch 4/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0915 - categorical_accuracy: 0.7807 - val_loss: 0.1513 - val_categorical_accuracy: 0.6347\n",
      "Epoch 5/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0754 - categorical_accuracy: 0.8212 - val_loss: 0.0986 - val_categorical_accuracy: 0.7393\n",
      "Epoch 6/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0647 - categorical_accuracy: 0.8489 - val_loss: 0.0670 - val_categorical_accuracy: 0.8351\n",
      "Epoch 7/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0583 - categorical_accuracy: 0.8648 - val_loss: 0.0495 - val_categorical_accuracy: 0.8853\n",
      "Epoch 8/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0532 - categorical_accuracy: 0.8786 - val_loss: 0.0436 - val_categorical_accuracy: 0.8973\n",
      "Epoch 9/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0491 - categorical_accuracy: 0.8875 - val_loss: 0.0403 - val_categorical_accuracy: 0.9077\n",
      "Epoch 10/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0456 - categorical_accuracy: 0.8955 - val_loss: 0.0345 - val_categorical_accuracy: 0.9223\n",
      "Epoch 11/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0426 - categorical_accuracy: 0.9032 - val_loss: 0.0349 - val_categorical_accuracy: 0.9152\n",
      "Epoch 12/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0408 - categorical_accuracy: 0.9074 - val_loss: 0.0302 - val_categorical_accuracy: 0.9321\n",
      "Epoch 13/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0393 - categorical_accuracy: 0.9108 - val_loss: 0.0317 - val_categorical_accuracy: 0.9252\n",
      "Epoch 14/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0364 - categorical_accuracy: 0.9178 - val_loss: 0.0279 - val_categorical_accuracy: 0.9374\n",
      "Epoch 15/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0360 - categorical_accuracy: 0.9191 - val_loss: 0.0278 - val_categorical_accuracy: 0.9370\n",
      "Epoch 16/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0340 - categorical_accuracy: 0.9231 - val_loss: 0.0282 - val_categorical_accuracy: 0.9376\n",
      "Epoch 17/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0334 - categorical_accuracy: 0.9245 - val_loss: 0.0277 - val_categorical_accuracy: 0.9353\n",
      "Epoch 18/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0324 - categorical_accuracy: 0.9266 - val_loss: 0.0278 - val_categorical_accuracy: 0.9345\n",
      "Epoch 19/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0312 - categorical_accuracy: 0.9302 - val_loss: 0.0254 - val_categorical_accuracy: 0.9418\n",
      "Epoch 20/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0304 - categorical_accuracy: 0.9324 - val_loss: 0.0278 - val_categorical_accuracy: 0.9359\n",
      "Epoch 21/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0301 - categorical_accuracy: 0.9324 - val_loss: 0.0236 - val_categorical_accuracy: 0.9443\n",
      "Epoch 22/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0287 - categorical_accuracy: 0.9346 - val_loss: 0.0226 - val_categorical_accuracy: 0.9481\n",
      "Epoch 23/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0280 - categorical_accuracy: 0.9371 - val_loss: 0.0221 - val_categorical_accuracy: 0.9481\n",
      "Epoch 24/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0275 - categorical_accuracy: 0.9378 - val_loss: 0.0215 - val_categorical_accuracy: 0.9496\n",
      "Epoch 25/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0274 - categorical_accuracy: 0.9385 - val_loss: 0.0234 - val_categorical_accuracy: 0.9475\n",
      "Epoch 26/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0266 - categorical_accuracy: 0.9395 - val_loss: 0.0215 - val_categorical_accuracy: 0.9506\n",
      "Epoch 27/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0258 - categorical_accuracy: 0.9422 - val_loss: 0.0213 - val_categorical_accuracy: 0.9500\n",
      "Epoch 28/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0258 - categorical_accuracy: 0.9417 - val_loss: 0.0223 - val_categorical_accuracy: 0.9492\n",
      "Epoch 29/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0252 - categorical_accuracy: 0.9433 - val_loss: 0.0204 - val_categorical_accuracy: 0.9516\n",
      "Epoch 30/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0245 - categorical_accuracy: 0.9445 - val_loss: 0.0200 - val_categorical_accuracy: 0.9512\n",
      "Epoch 31/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0243 - categorical_accuracy: 0.9451 - val_loss: 0.0187 - val_categorical_accuracy: 0.9561\n",
      "Epoch 32/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0238 - categorical_accuracy: 0.9467 - val_loss: 0.0189 - val_categorical_accuracy: 0.9553\n",
      "Epoch 33/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0236 - categorical_accuracy: 0.9471 - val_loss: 0.0189 - val_categorical_accuracy: 0.9549\n",
      "Epoch 34/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0228 - categorical_accuracy: 0.9489 - val_loss: 0.0185 - val_categorical_accuracy: 0.9571\n",
      "Epoch 35/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0231 - categorical_accuracy: 0.9482 - val_loss: 0.0187 - val_categorical_accuracy: 0.9567\n",
      "Epoch 36/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0225 - categorical_accuracy: 0.9491 - val_loss: 0.0192 - val_categorical_accuracy: 0.9553\n",
      "Epoch 37/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0222 - categorical_accuracy: 0.9502 - val_loss: 0.0181 - val_categorical_accuracy: 0.9589\n",
      "Epoch 38/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0213 - categorical_accuracy: 0.9524 - val_loss: 0.0173 - val_categorical_accuracy: 0.9571\n",
      "Epoch 39/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0216 - categorical_accuracy: 0.9516 - val_loss: 0.0167 - val_categorical_accuracy: 0.9612\n",
      "Epoch 40/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0215 - categorical_accuracy: 0.9520 - val_loss: 0.0196 - val_categorical_accuracy: 0.9551\n",
      "Epoch 41/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0212 - categorical_accuracy: 0.9522 - val_loss: 0.0179 - val_categorical_accuracy: 0.9569\n",
      "Epoch 42/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0212 - categorical_accuracy: 0.9526 - val_loss: 0.0169 - val_categorical_accuracy: 0.9591\n",
      "Epoch 43/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0208 - categorical_accuracy: 0.9533 - val_loss: 0.0182 - val_categorical_accuracy: 0.9585\n",
      "Epoch 44/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0203 - categorical_accuracy: 0.9553 - val_loss: 0.0172 - val_categorical_accuracy: 0.9577\n",
      "Epoch 45/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0201 - categorical_accuracy: 0.9545 - val_loss: 0.0175 - val_categorical_accuracy: 0.9583\n",
      "Epoch 46/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0198 - categorical_accuracy: 0.9557 - val_loss: 0.0159 - val_categorical_accuracy: 0.9626\n",
      "Epoch 47/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0198 - categorical_accuracy: 0.9556 - val_loss: 0.0176 - val_categorical_accuracy: 0.9595\n",
      "Epoch 48/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0194 - categorical_accuracy: 0.9562 - val_loss: 0.0163 - val_categorical_accuracy: 0.9610\n",
      "Epoch 49/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0195 - categorical_accuracy: 0.9560 - val_loss: 0.0155 - val_categorical_accuracy: 0.9603\n",
      "Epoch 50/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93413/93413 [==============================] - 48s - loss: 0.0193 - categorical_accuracy: 0.9569 - val_loss: 0.0154 - val_categorical_accuracy: 0.9656\n",
      "Epoch 51/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0190 - categorical_accuracy: 0.9571 - val_loss: 0.0157 - val_categorical_accuracy: 0.9642\n",
      "Epoch 52/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0189 - categorical_accuracy: 0.9575 - val_loss: 0.0153 - val_categorical_accuracy: 0.9660\n",
      "Epoch 53/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0184 - categorical_accuracy: 0.9586 - val_loss: 0.0153 - val_categorical_accuracy: 0.9650\n",
      "Epoch 54/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0183 - categorical_accuracy: 0.9598 - val_loss: 0.0152 - val_categorical_accuracy: 0.9650\n",
      "Epoch 55/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0185 - categorical_accuracy: 0.9585 - val_loss: 0.0169 - val_categorical_accuracy: 0.9614\n",
      "Epoch 56/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0186 - categorical_accuracy: 0.9585 - val_loss: 0.0152 - val_categorical_accuracy: 0.9638\n",
      "Epoch 57/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0180 - categorical_accuracy: 0.9596 - val_loss: 0.0146 - val_categorical_accuracy: 0.9662\n",
      "Epoch 58/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0177 - categorical_accuracy: 0.9602 - val_loss: 0.0169 - val_categorical_accuracy: 0.9620\n",
      "Epoch 59/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0177 - categorical_accuracy: 0.9603 - val_loss: 0.0164 - val_categorical_accuracy: 0.9614\n",
      "Epoch 60/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0174 - categorical_accuracy: 0.9612 - val_loss: 0.0158 - val_categorical_accuracy: 0.9636\n",
      "Epoch 61/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0177 - categorical_accuracy: 0.9598 - val_loss: 0.0147 - val_categorical_accuracy: 0.9664\n",
      "Epoch 62/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0172 - categorical_accuracy: 0.9621 - val_loss: 0.0145 - val_categorical_accuracy: 0.9691\n",
      "Epoch 63/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0169 - categorical_accuracy: 0.9626 - val_loss: 0.0158 - val_categorical_accuracy: 0.9632\n",
      "Epoch 64/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0168 - categorical_accuracy: 0.9619 - val_loss: 0.0137 - val_categorical_accuracy: 0.9711\n",
      "Epoch 65/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0168 - categorical_accuracy: 0.9625 - val_loss: 0.0156 - val_categorical_accuracy: 0.9660\n",
      "Epoch 66/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0168 - categorical_accuracy: 0.9630 - val_loss: 0.0156 - val_categorical_accuracy: 0.9648\n",
      "Epoch 67/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0170 - categorical_accuracy: 0.9619 - val_loss: 0.0132 - val_categorical_accuracy: 0.9707\n",
      "Epoch 68/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0162 - categorical_accuracy: 0.9637 - val_loss: 0.0141 - val_categorical_accuracy: 0.9687\n",
      "Epoch 69/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0164 - categorical_accuracy: 0.9633 - val_loss: 0.0145 - val_categorical_accuracy: 0.9671\n",
      "Epoch 70/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0163 - categorical_accuracy: 0.9641 - val_loss: 0.0144 - val_categorical_accuracy: 0.9689\n",
      "Epoch 71/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0161 - categorical_accuracy: 0.9639 - val_loss: 0.0145 - val_categorical_accuracy: 0.9671\n",
      "Epoch 72/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0160 - categorical_accuracy: 0.9645 - val_loss: 0.0139 - val_categorical_accuracy: 0.9673\n",
      "Epoch 73/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0161 - categorical_accuracy: 0.9641 - val_loss: 0.0143 - val_categorical_accuracy: 0.9683\n",
      "Epoch 74/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0157 - categorical_accuracy: 0.9651 - val_loss: 0.0143 - val_categorical_accuracy: 0.9673\n",
      "Epoch 75/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0155 - categorical_accuracy: 0.9651 - val_loss: 0.0136 - val_categorical_accuracy: 0.9701\n",
      "Epoch 76/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0164 - categorical_accuracy: 0.9627 - val_loss: 0.0135 - val_categorical_accuracy: 0.9697\n",
      "Epoch 77/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0155 - categorical_accuracy: 0.9651 - val_loss: 0.0138 - val_categorical_accuracy: 0.9677\n",
      "Epoch 78/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0155 - categorical_accuracy: 0.9652 - val_loss: 0.0127 - val_categorical_accuracy: 0.9705\n",
      "Epoch 79/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0156 - categorical_accuracy: 0.9651 - val_loss: 0.0135 - val_categorical_accuracy: 0.9681\n",
      "Epoch 80/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0153 - categorical_accuracy: 0.9661 - val_loss: 0.0135 - val_categorical_accuracy: 0.9699\n",
      "Epoch 81/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0157 - categorical_accuracy: 0.9650 - val_loss: 0.0139 - val_categorical_accuracy: 0.9703\n",
      "Epoch 82/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0152 - categorical_accuracy: 0.9657 - val_loss: 0.0132 - val_categorical_accuracy: 0.9695\n",
      "Epoch 83/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0152 - categorical_accuracy: 0.9658 - val_loss: 0.0125 - val_categorical_accuracy: 0.9719\n",
      "Epoch 84/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0149 - categorical_accuracy: 0.9666 - val_loss: 0.0132 - val_categorical_accuracy: 0.9703\n",
      "Epoch 85/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0145 - categorical_accuracy: 0.9675 - val_loss: 0.0125 - val_categorical_accuracy: 0.9701\n",
      "Epoch 86/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0151 - categorical_accuracy: 0.9665 - val_loss: 0.0133 - val_categorical_accuracy: 0.9715\n",
      "Epoch 87/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0148 - categorical_accuracy: 0.9671 - val_loss: 0.0129 - val_categorical_accuracy: 0.9705\n",
      "Epoch 88/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0142 - categorical_accuracy: 0.9688 - val_loss: 0.0128 - val_categorical_accuracy: 0.9727\n",
      "Epoch 89/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0147 - categorical_accuracy: 0.9671 - val_loss: 0.0123 - val_categorical_accuracy: 0.9736\n",
      "Epoch 90/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0146 - categorical_accuracy: 0.9675 - val_loss: 0.0135 - val_categorical_accuracy: 0.9707\n",
      "Epoch 91/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0146 - categorical_accuracy: 0.9677 - val_loss: 0.0127 - val_categorical_accuracy: 0.9725\n",
      "Epoch 92/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0144 - categorical_accuracy: 0.9677 - val_loss: 0.0126 - val_categorical_accuracy: 0.9721\n",
      "Epoch 93/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0143 - categorical_accuracy: 0.9678 - val_loss: 0.0127 - val_categorical_accuracy: 0.9721\n",
      "Epoch 94/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0142 - categorical_accuracy: 0.9689 - val_loss: 0.0137 - val_categorical_accuracy: 0.9699\n",
      "Epoch 95/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0140 - categorical_accuracy: 0.9688 - val_loss: 0.0126 - val_categorical_accuracy: 0.9730\n",
      "Epoch 96/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0139 - categorical_accuracy: 0.9693 - val_loss: 0.0123 - val_categorical_accuracy: 0.9719\n",
      "Epoch 97/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0141 - categorical_accuracy: 0.9681 - val_loss: 0.0119 - val_categorical_accuracy: 0.9738\n",
      "Epoch 98/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0144 - categorical_accuracy: 0.9682 - val_loss: 0.0134 - val_categorical_accuracy: 0.9703\n",
      "Epoch 99/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0143 - categorical_accuracy: 0.9678 - val_loss: 0.0127 - val_categorical_accuracy: 0.9703\n",
      "Epoch 100/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93413/93413 [==============================] - 48s - loss: 0.0140 - categorical_accuracy: 0.9688 - val_loss: 0.0115 - val_categorical_accuracy: 0.9754\n",
      "Epoch 101/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0138 - categorical_accuracy: 0.9694 - val_loss: 0.0131 - val_categorical_accuracy: 0.9719\n",
      "Epoch 102/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0137 - categorical_accuracy: 0.9695 - val_loss: 0.0125 - val_categorical_accuracy: 0.9730\n",
      "Epoch 103/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0140 - categorical_accuracy: 0.9682 - val_loss: 0.0117 - val_categorical_accuracy: 0.9750\n",
      "Epoch 104/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0135 - categorical_accuracy: 0.9695 - val_loss: 0.0115 - val_categorical_accuracy: 0.9764\n",
      "Epoch 105/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0134 - categorical_accuracy: 0.9699 - val_loss: 0.0116 - val_categorical_accuracy: 0.9738\n",
      "Epoch 106/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0133 - categorical_accuracy: 0.9700 - val_loss: 0.0114 - val_categorical_accuracy: 0.9754\n",
      "Epoch 107/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0137 - categorical_accuracy: 0.9690 - val_loss: 0.0126 - val_categorical_accuracy: 0.9725\n",
      "Epoch 108/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0135 - categorical_accuracy: 0.9696 - val_loss: 0.0122 - val_categorical_accuracy: 0.9734\n",
      "Epoch 109/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0129 - categorical_accuracy: 0.9706 - val_loss: 0.0120 - val_categorical_accuracy: 0.9744\n",
      "Epoch 110/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0134 - categorical_accuracy: 0.9701 - val_loss: 0.0121 - val_categorical_accuracy: 0.9727\n",
      "Epoch 111/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0134 - categorical_accuracy: 0.9698 - val_loss: 0.0118 - val_categorical_accuracy: 0.9744\n",
      "Epoch 112/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0131 - categorical_accuracy: 0.9706 - val_loss: 0.0128 - val_categorical_accuracy: 0.9709\n",
      "Epoch 113/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0132 - categorical_accuracy: 0.9704 - val_loss: 0.0128 - val_categorical_accuracy: 0.9697\n",
      "Epoch 114/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0132 - categorical_accuracy: 0.9706 - val_loss: 0.0117 - val_categorical_accuracy: 0.9746\n",
      "Epoch 115/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0133 - categorical_accuracy: 0.9703 - val_loss: 0.0120 - val_categorical_accuracy: 0.9736\n",
      "Epoch 116/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0130 - categorical_accuracy: 0.9705 - val_loss: 0.0125 - val_categorical_accuracy: 0.9715\n",
      "Epoch 117/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0128 - categorical_accuracy: 0.9714 - val_loss: 0.0116 - val_categorical_accuracy: 0.9736\n",
      "Epoch 118/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0127 - categorical_accuracy: 0.9712 - val_loss: 0.0118 - val_categorical_accuracy: 0.9742\n",
      "Epoch 119/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0129 - categorical_accuracy: 0.9716 - val_loss: 0.0124 - val_categorical_accuracy: 0.9734\n",
      "Epoch 120/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0127 - categorical_accuracy: 0.9717 - val_loss: 0.0127 - val_categorical_accuracy: 0.9723\n",
      "Epoch 121/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0128 - categorical_accuracy: 0.9717 - val_loss: 0.0115 - val_categorical_accuracy: 0.9752\n",
      "Epoch 122/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0134 - categorical_accuracy: 0.9699 - val_loss: 0.0136 - val_categorical_accuracy: 0.9705\n",
      "Epoch 123/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0128 - categorical_accuracy: 0.9716 - val_loss: 0.0110 - val_categorical_accuracy: 0.9762\n",
      "Epoch 124/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0124 - categorical_accuracy: 0.9725 - val_loss: 0.0118 - val_categorical_accuracy: 0.9746\n",
      "Epoch 125/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0125 - categorical_accuracy: 0.9717 - val_loss: 0.0114 - val_categorical_accuracy: 0.9752\n",
      "Epoch 126/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0122 - categorical_accuracy: 0.9727 - val_loss: 0.0118 - val_categorical_accuracy: 0.9732\n",
      "Epoch 127/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0122 - categorical_accuracy: 0.9728 - val_loss: 0.0110 - val_categorical_accuracy: 0.9742\n",
      "Epoch 128/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0127 - categorical_accuracy: 0.9722 - val_loss: 0.0120 - val_categorical_accuracy: 0.9734\n",
      "Epoch 129/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0123 - categorical_accuracy: 0.9727 - val_loss: 0.0109 - val_categorical_accuracy: 0.9758\n",
      "Epoch 130/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0122 - categorical_accuracy: 0.9726 - val_loss: 0.0115 - val_categorical_accuracy: 0.9764\n",
      "Epoch 131/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0119 - categorical_accuracy: 0.9736 - val_loss: 0.0120 - val_categorical_accuracy: 0.9760\n",
      "Epoch 132/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0128 - categorical_accuracy: 0.9710 - val_loss: 0.0108 - val_categorical_accuracy: 0.9764\n",
      "Epoch 133/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0123 - categorical_accuracy: 0.9725 - val_loss: 0.0106 - val_categorical_accuracy: 0.9788\n",
      "Epoch 134/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0119 - categorical_accuracy: 0.9735 - val_loss: 0.0119 - val_categorical_accuracy: 0.9730\n",
      "Epoch 135/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0122 - categorical_accuracy: 0.9730 - val_loss: 0.0110 - val_categorical_accuracy: 0.9772\n",
      "Epoch 136/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0123 - categorical_accuracy: 0.9721 - val_loss: 0.0106 - val_categorical_accuracy: 0.9772\n",
      "Epoch 137/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0120 - categorical_accuracy: 0.9732 - val_loss: 0.0106 - val_categorical_accuracy: 0.9762\n",
      "Epoch 138/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0118 - categorical_accuracy: 0.9737 - val_loss: 0.0112 - val_categorical_accuracy: 0.9748\n",
      "Epoch 139/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0123 - categorical_accuracy: 0.9726 - val_loss: 0.0111 - val_categorical_accuracy: 0.9752\n",
      "Epoch 140/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0119 - categorical_accuracy: 0.9742 - val_loss: 0.0110 - val_categorical_accuracy: 0.9746\n",
      "Epoch 141/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0123 - categorical_accuracy: 0.9727 - val_loss: 0.0113 - val_categorical_accuracy: 0.9744\n",
      "Epoch 142/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0117 - categorical_accuracy: 0.9736 - val_loss: 0.0126 - val_categorical_accuracy: 0.9725\n",
      "Epoch 143/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0122 - categorical_accuracy: 0.9727 - val_loss: 0.0108 - val_categorical_accuracy: 0.9762\n",
      "Epoch 144/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0114 - categorical_accuracy: 0.9748 - val_loss: 0.0104 - val_categorical_accuracy: 0.9770\n",
      "Epoch 145/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0117 - categorical_accuracy: 0.9739 - val_loss: 0.0103 - val_categorical_accuracy: 0.9784\n",
      "Epoch 146/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0117 - categorical_accuracy: 0.9738 - val_loss: 0.0116 - val_categorical_accuracy: 0.9740\n",
      "Epoch 147/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0115 - categorical_accuracy: 0.9745 - val_loss: 0.0109 - val_categorical_accuracy: 0.9754\n",
      "Epoch 148/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0120 - categorical_accuracy: 0.9733 - val_loss: 0.0107 - val_categorical_accuracy: 0.9758\n",
      "Epoch 149/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93413/93413 [==============================] - 48s - loss: 0.0118 - categorical_accuracy: 0.9740 - val_loss: 0.0107 - val_categorical_accuracy: 0.9758\n",
      "Epoch 150/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0115 - categorical_accuracy: 0.9741 - val_loss: 0.0111 - val_categorical_accuracy: 0.9756\n",
      "Epoch 151/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0117 - categorical_accuracy: 0.9739 - val_loss: 0.0117 - val_categorical_accuracy: 0.9750\n",
      "Epoch 152/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0117 - categorical_accuracy: 0.9740 - val_loss: 0.0123 - val_categorical_accuracy: 0.9758\n",
      "Epoch 153/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0116 - categorical_accuracy: 0.9742 - val_loss: 0.0100 - val_categorical_accuracy: 0.9780\n",
      "Epoch 154/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0112 - categorical_accuracy: 0.9745 - val_loss: 0.0101 - val_categorical_accuracy: 0.9770\n",
      "Epoch 155/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0113 - categorical_accuracy: 0.9748 - val_loss: 0.0119 - val_categorical_accuracy: 0.9734\n",
      "Epoch 156/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0114 - categorical_accuracy: 0.9745 - val_loss: 0.0105 - val_categorical_accuracy: 0.9788\n",
      "Epoch 157/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0114 - categorical_accuracy: 0.9745 - val_loss: 0.0109 - val_categorical_accuracy: 0.9756\n",
      "Epoch 158/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0113 - categorical_accuracy: 0.9749 - val_loss: 0.0098 - val_categorical_accuracy: 0.9786\n",
      "Epoch 159/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0113 - categorical_accuracy: 0.9745 - val_loss: 0.0101 - val_categorical_accuracy: 0.9797\n",
      "Epoch 160/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0112 - categorical_accuracy: 0.9751 - val_loss: 0.0116 - val_categorical_accuracy: 0.9770\n",
      "Epoch 161/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0114 - categorical_accuracy: 0.9747 - val_loss: 0.0102 - val_categorical_accuracy: 0.9791\n",
      "Epoch 162/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0113 - categorical_accuracy: 0.9748 - val_loss: 0.0103 - val_categorical_accuracy: 0.9780\n",
      "Epoch 163/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0110 - categorical_accuracy: 0.9758 - val_loss: 0.0110 - val_categorical_accuracy: 0.9772\n",
      "Epoch 164/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0109 - categorical_accuracy: 0.9760 - val_loss: 0.0104 - val_categorical_accuracy: 0.9784\n",
      "Epoch 165/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0114 - categorical_accuracy: 0.9748 - val_loss: 0.0102 - val_categorical_accuracy: 0.9786\n",
      "Epoch 166/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0108 - categorical_accuracy: 0.9760 - val_loss: 0.0108 - val_categorical_accuracy: 0.9774\n",
      "Epoch 167/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0112 - categorical_accuracy: 0.9755 - val_loss: 0.0103 - val_categorical_accuracy: 0.9782\n",
      "Epoch 168/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0109 - categorical_accuracy: 0.9760 - val_loss: 0.0107 - val_categorical_accuracy: 0.9762\n",
      "Epoch 169/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0112 - categorical_accuracy: 0.9749 - val_loss: 0.0091 - val_categorical_accuracy: 0.9793\n",
      "Epoch 170/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0109 - categorical_accuracy: 0.9751 - val_loss: 0.0103 - val_categorical_accuracy: 0.9768\n",
      "Epoch 171/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0111 - categorical_accuracy: 0.9751 - val_loss: 0.0109 - val_categorical_accuracy: 0.9768\n",
      "Epoch 172/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0114 - categorical_accuracy: 0.9741 - val_loss: 0.0098 - val_categorical_accuracy: 0.9793\n",
      "Epoch 173/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0112 - categorical_accuracy: 0.9746 - val_loss: 0.0106 - val_categorical_accuracy: 0.9770\n",
      "Epoch 174/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0107 - categorical_accuracy: 0.9760 - val_loss: 0.0099 - val_categorical_accuracy: 0.9801\n",
      "Epoch 175/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0113 - categorical_accuracy: 0.9746 - val_loss: 0.0109 - val_categorical_accuracy: 0.9782\n",
      "Epoch 176/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0109 - categorical_accuracy: 0.9754 - val_loss: 0.0093 - val_categorical_accuracy: 0.9784\n",
      "Epoch 177/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0110 - categorical_accuracy: 0.9756 - val_loss: 0.0104 - val_categorical_accuracy: 0.9778\n",
      "Epoch 178/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0106 - categorical_accuracy: 0.9767 - val_loss: 0.0094 - val_categorical_accuracy: 0.9807\n",
      "Epoch 179/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0109 - categorical_accuracy: 0.9759 - val_loss: 0.0099 - val_categorical_accuracy: 0.9803\n",
      "Epoch 180/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0108 - categorical_accuracy: 0.9759 - val_loss: 0.0099 - val_categorical_accuracy: 0.9791\n",
      "Epoch 181/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0107 - categorical_accuracy: 0.9768 - val_loss: 0.0107 - val_categorical_accuracy: 0.9770\n",
      "Epoch 182/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0106 - categorical_accuracy: 0.9768 - val_loss: 0.0101 - val_categorical_accuracy: 0.9791\n",
      "Epoch 183/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0105 - categorical_accuracy: 0.9773 - val_loss: 0.0097 - val_categorical_accuracy: 0.9788\n",
      "Epoch 184/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0107 - categorical_accuracy: 0.9761 - val_loss: 0.0097 - val_categorical_accuracy: 0.9784\n",
      "Epoch 185/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0103 - categorical_accuracy: 0.9769 - val_loss: 0.0104 - val_categorical_accuracy: 0.9786\n",
      "Epoch 186/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0108 - categorical_accuracy: 0.9761 - val_loss: 0.0100 - val_categorical_accuracy: 0.9782\n",
      "Epoch 187/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0105 - categorical_accuracy: 0.9766 - val_loss: 0.0106 - val_categorical_accuracy: 0.9778\n",
      "Epoch 188/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0105 - categorical_accuracy: 0.9767 - val_loss: 0.0101 - val_categorical_accuracy: 0.9801\n",
      "Epoch 189/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0104 - categorical_accuracy: 0.9767 - val_loss: 0.0096 - val_categorical_accuracy: 0.9807\n",
      "Epoch 190/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0101 - categorical_accuracy: 0.9776 - val_loss: 0.0097 - val_categorical_accuracy: 0.9795\n",
      "Epoch 191/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0104 - categorical_accuracy: 0.9769 - val_loss: 0.0103 - val_categorical_accuracy: 0.9788\n",
      "Epoch 192/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0111 - categorical_accuracy: 0.9750 - val_loss: 0.0097 - val_categorical_accuracy: 0.9809\n",
      "Epoch 193/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0105 - categorical_accuracy: 0.9765 - val_loss: 0.0095 - val_categorical_accuracy: 0.9793\n",
      "Epoch 194/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0105 - categorical_accuracy: 0.9768 - val_loss: 0.0102 - val_categorical_accuracy: 0.9784\n",
      "Epoch 195/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0102 - categorical_accuracy: 0.9773 - val_loss: 0.0094 - val_categorical_accuracy: 0.9782\n",
      "Epoch 196/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0103 - categorical_accuracy: 0.9775 - val_loss: 0.0102 - val_categorical_accuracy: 0.9776\n",
      "Epoch 197/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0102 - categorical_accuracy: 0.9774 - val_loss: 0.0104 - val_categorical_accuracy: 0.9776\n",
      "Epoch 198/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93413/93413 [==============================] - 48s - loss: 0.0104 - categorical_accuracy: 0.9771 - val_loss: 0.0091 - val_categorical_accuracy: 0.9803\n",
      "Epoch 199/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0101 - categorical_accuracy: 0.9777 - val_loss: 0.0103 - val_categorical_accuracy: 0.9797\n",
      "Epoch 200/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0102 - categorical_accuracy: 0.9771 - val_loss: 0.0093 - val_categorical_accuracy: 0.9793\n",
      "CPU times: user 1h 50min 12s, sys: 17min 40s, total: 2h 7min 52s\n",
      "Wall time: 2h 42min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# model.fit(X_train, y_train, batch_size=2048, validation_data=(X_valid, y_valid), \\\n",
    "#           class_weight=class_weight, epochs=300, shuffle=True, verbose=1)\n",
    "model.fit(X_train, y_train, batch_size=1024, validation_data=(X_valid, y_valid), \\\n",
    "          epochs=200, shuffle=True, verbose=1)\n",
    "model.save(os.path.join(OUTPUT_PATH, MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 93413 samples, validate on 4917 samples\n",
      "Epoch 1/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0100 - categorical_accuracy: 0.9772 - val_loss: 0.0101 - val_categorical_accuracy: 0.9793\n",
      "Epoch 2/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0102 - categorical_accuracy: 0.9775 - val_loss: 0.0100 - val_categorical_accuracy: 0.9793\n",
      "Epoch 3/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0103 - categorical_accuracy: 0.9773 - val_loss: 0.0103 - val_categorical_accuracy: 0.9782\n",
      "Epoch 4/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0104 - categorical_accuracy: 0.9771 - val_loss: 0.0101 - val_categorical_accuracy: 0.9776\n",
      "Epoch 5/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0096 - categorical_accuracy: 0.9785 - val_loss: 0.0099 - val_categorical_accuracy: 0.9788\n",
      "Epoch 6/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0100 - categorical_accuracy: 0.9779 - val_loss: 0.0100 - val_categorical_accuracy: 0.9799\n",
      "Epoch 7/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0106 - categorical_accuracy: 0.9763 - val_loss: 0.0100 - val_categorical_accuracy: 0.9784\n",
      "Epoch 8/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0105 - categorical_accuracy: 0.9769 - val_loss: 0.0104 - val_categorical_accuracy: 0.9780\n",
      "Epoch 9/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0101 - categorical_accuracy: 0.9778 - val_loss: 0.0096 - val_categorical_accuracy: 0.9803\n",
      "Epoch 10/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0100 - categorical_accuracy: 0.9776 - val_loss: 0.0093 - val_categorical_accuracy: 0.9819\n",
      "Epoch 11/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0100 - categorical_accuracy: 0.9775 - val_loss: 0.0107 - val_categorical_accuracy: 0.9774\n",
      "Epoch 12/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0101 - categorical_accuracy: 0.9773 - val_loss: 0.0101 - val_categorical_accuracy: 0.9797\n",
      "Epoch 13/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0098 - categorical_accuracy: 0.9780 - val_loss: 0.0098 - val_categorical_accuracy: 0.9791\n",
      "Epoch 14/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0100 - categorical_accuracy: 0.9779 - val_loss: 0.0102 - val_categorical_accuracy: 0.9786\n",
      "Epoch 15/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0100 - categorical_accuracy: 0.9776 - val_loss: 0.0101 - val_categorical_accuracy: 0.9788\n",
      "Epoch 16/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0096 - categorical_accuracy: 0.9785 - val_loss: 0.0097 - val_categorical_accuracy: 0.9795\n",
      "Epoch 17/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0101 - categorical_accuracy: 0.9778 - val_loss: 0.0102 - val_categorical_accuracy: 0.9795\n",
      "Epoch 18/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0106 - categorical_accuracy: 0.9765 - val_loss: 0.0101 - val_categorical_accuracy: 0.9784\n",
      "Epoch 19/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0099 - categorical_accuracy: 0.9779 - val_loss: 0.0099 - val_categorical_accuracy: 0.9807\n",
      "Epoch 20/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0096 - categorical_accuracy: 0.9782 - val_loss: 0.0090 - val_categorical_accuracy: 0.9815\n",
      "Epoch 21/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0097 - categorical_accuracy: 0.9784 - val_loss: 0.0090 - val_categorical_accuracy: 0.9811\n",
      "Epoch 22/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0100 - categorical_accuracy: 0.9781 - val_loss: 0.0092 - val_categorical_accuracy: 0.9807\n",
      "Epoch 23/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0098 - categorical_accuracy: 0.9782 - val_loss: 0.0096 - val_categorical_accuracy: 0.9815\n",
      "Epoch 24/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0097 - categorical_accuracy: 0.9786 - val_loss: 0.0098 - val_categorical_accuracy: 0.9782\n",
      "Epoch 25/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0096 - categorical_accuracy: 0.9790 - val_loss: 0.0092 - val_categorical_accuracy: 0.9797\n",
      "Epoch 26/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0098 - categorical_accuracy: 0.9782 - val_loss: 0.0105 - val_categorical_accuracy: 0.9772\n",
      "Epoch 27/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0093 - categorical_accuracy: 0.9790 - val_loss: 0.0089 - val_categorical_accuracy: 0.9817\n",
      "Epoch 28/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0099 - categorical_accuracy: 0.9783 - val_loss: 0.0089 - val_categorical_accuracy: 0.9799\n",
      "Epoch 29/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0098 - categorical_accuracy: 0.9783 - val_loss: 0.0094 - val_categorical_accuracy: 0.9809\n",
      "Epoch 30/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0097 - categorical_accuracy: 0.9783 - val_loss: 0.0098 - val_categorical_accuracy: 0.9805\n",
      "Epoch 31/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0097 - categorical_accuracy: 0.9786 - val_loss: 0.0088 - val_categorical_accuracy: 0.9807\n",
      "Epoch 32/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0094 - categorical_accuracy: 0.9791 - val_loss: 0.0092 - val_categorical_accuracy: 0.9819\n",
      "Epoch 33/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0099 - categorical_accuracy: 0.9787 - val_loss: 0.0091 - val_categorical_accuracy: 0.9795\n",
      "Epoch 34/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0094 - categorical_accuracy: 0.9791 - val_loss: 0.0096 - val_categorical_accuracy: 0.9805\n",
      "Epoch 35/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0097 - categorical_accuracy: 0.9786 - val_loss: 0.0093 - val_categorical_accuracy: 0.9799\n",
      "Epoch 36/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0092 - categorical_accuracy: 0.9790 - val_loss: 0.0095 - val_categorical_accuracy: 0.9807\n",
      "Epoch 37/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0097 - categorical_accuracy: 0.9781 - val_loss: 0.0090 - val_categorical_accuracy: 0.9811\n",
      "Epoch 38/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0094 - categorical_accuracy: 0.9794 - val_loss: 0.0092 - val_categorical_accuracy: 0.9801\n",
      "Epoch 39/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0092 - categorical_accuracy: 0.9792 - val_loss: 0.0096 - val_categorical_accuracy: 0.9803\n",
      "Epoch 40/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0094 - categorical_accuracy: 0.9793 - val_loss: 0.0091 - val_categorical_accuracy: 0.9801\n",
      "Epoch 41/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0093 - categorical_accuracy: 0.9793 - val_loss: 0.0090 - val_categorical_accuracy: 0.9799\n",
      "Epoch 42/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0096 - categorical_accuracy: 0.9789 - val_loss: 0.0100 - val_categorical_accuracy: 0.9774\n",
      "Epoch 43/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0095 - categorical_accuracy: 0.9792 - val_loss: 0.0090 - val_categorical_accuracy: 0.9801\n",
      "Epoch 44/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0094 - categorical_accuracy: 0.9787 - val_loss: 0.0093 - val_categorical_accuracy: 0.9797\n",
      "Epoch 45/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0095 - categorical_accuracy: 0.9795 - val_loss: 0.0092 - val_categorical_accuracy: 0.9799\n",
      "Epoch 46/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0097 - categorical_accuracy: 0.9783 - val_loss: 0.0089 - val_categorical_accuracy: 0.9813\n",
      "Epoch 47/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0094 - categorical_accuracy: 0.9793 - val_loss: 0.0092 - val_categorical_accuracy: 0.9819\n",
      "Epoch 48/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0096 - categorical_accuracy: 0.9792 - val_loss: 0.0104 - val_categorical_accuracy: 0.9780\n",
      "Epoch 49/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0094 - categorical_accuracy: 0.9790 - val_loss: 0.0097 - val_categorical_accuracy: 0.9788\n",
      "Epoch 50/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93413/93413 [==============================] - 48s - loss: 0.0094 - categorical_accuracy: 0.9793 - val_loss: 0.0100 - val_categorical_accuracy: 0.9801\n",
      "Epoch 51/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0095 - categorical_accuracy: 0.9791 - val_loss: 0.0097 - val_categorical_accuracy: 0.9801\n",
      "Epoch 52/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0093 - categorical_accuracy: 0.9797 - val_loss: 0.0095 - val_categorical_accuracy: 0.9797\n",
      "Epoch 53/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0096 - categorical_accuracy: 0.9788 - val_loss: 0.0091 - val_categorical_accuracy: 0.9821\n",
      "Epoch 54/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0093 - categorical_accuracy: 0.9792 - val_loss: 0.0087 - val_categorical_accuracy: 0.9813\n",
      "Epoch 55/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0092 - categorical_accuracy: 0.9796 - val_loss: 0.0098 - val_categorical_accuracy: 0.9805\n",
      "Epoch 56/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0090 - categorical_accuracy: 0.9800 - val_loss: 0.0095 - val_categorical_accuracy: 0.9803\n",
      "Epoch 57/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0090 - categorical_accuracy: 0.9802 - val_loss: 0.0097 - val_categorical_accuracy: 0.9793\n",
      "Epoch 58/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0095 - categorical_accuracy: 0.9793 - val_loss: 0.0093 - val_categorical_accuracy: 0.9809\n",
      "Epoch 59/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0093 - categorical_accuracy: 0.9793 - val_loss: 0.0097 - val_categorical_accuracy: 0.9801\n",
      "Epoch 60/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0091 - categorical_accuracy: 0.9800 - val_loss: 0.0090 - val_categorical_accuracy: 0.9811\n",
      "Epoch 61/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0092 - categorical_accuracy: 0.9794 - val_loss: 0.0095 - val_categorical_accuracy: 0.9793\n",
      "Epoch 62/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0091 - categorical_accuracy: 0.9796 - val_loss: 0.0095 - val_categorical_accuracy: 0.9799\n",
      "Epoch 63/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0092 - categorical_accuracy: 0.9797 - val_loss: 0.0089 - val_categorical_accuracy: 0.9813\n",
      "Epoch 64/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0090 - categorical_accuracy: 0.9801 - val_loss: 0.0096 - val_categorical_accuracy: 0.9803\n",
      "Epoch 65/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0094 - categorical_accuracy: 0.9797 - val_loss: 0.0088 - val_categorical_accuracy: 0.9809\n",
      "Epoch 66/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0090 - categorical_accuracy: 0.9794 - val_loss: 0.0090 - val_categorical_accuracy: 0.9805\n",
      "Epoch 67/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0089 - categorical_accuracy: 0.9803 - val_loss: 0.0093 - val_categorical_accuracy: 0.9799\n",
      "Epoch 68/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0093 - categorical_accuracy: 0.9793 - val_loss: 0.0094 - val_categorical_accuracy: 0.9807\n",
      "Epoch 69/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0091 - categorical_accuracy: 0.9799 - val_loss: 0.0091 - val_categorical_accuracy: 0.9813\n",
      "Epoch 70/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0090 - categorical_accuracy: 0.9806 - val_loss: 0.0086 - val_categorical_accuracy: 0.9813\n",
      "Epoch 71/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0090 - categorical_accuracy: 0.9800 - val_loss: 0.0089 - val_categorical_accuracy: 0.9817\n",
      "Epoch 72/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0088 - categorical_accuracy: 0.9804 - val_loss: 0.0088 - val_categorical_accuracy: 0.9825\n",
      "Epoch 73/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0091 - categorical_accuracy: 0.9797 - val_loss: 0.0091 - val_categorical_accuracy: 0.9815\n",
      "Epoch 74/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0090 - categorical_accuracy: 0.9801 - val_loss: 0.0091 - val_categorical_accuracy: 0.9815\n",
      "Epoch 75/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0091 - categorical_accuracy: 0.9799 - val_loss: 0.0093 - val_categorical_accuracy: 0.9801\n",
      "Epoch 76/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0092 - categorical_accuracy: 0.9795 - val_loss: 0.0101 - val_categorical_accuracy: 0.9776\n",
      "Epoch 77/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0088 - categorical_accuracy: 0.9803 - val_loss: 0.0094 - val_categorical_accuracy: 0.9791\n",
      "Epoch 78/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0088 - categorical_accuracy: 0.9801 - val_loss: 0.0093 - val_categorical_accuracy: 0.9803\n",
      "Epoch 79/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0088 - categorical_accuracy: 0.9807 - val_loss: 0.0099 - val_categorical_accuracy: 0.9795\n",
      "Epoch 80/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0090 - categorical_accuracy: 0.9802 - val_loss: 0.0102 - val_categorical_accuracy: 0.9801\n",
      "Epoch 81/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0090 - categorical_accuracy: 0.9798 - val_loss: 0.0088 - val_categorical_accuracy: 0.9819\n",
      "Epoch 82/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0086 - categorical_accuracy: 0.9809 - val_loss: 0.0095 - val_categorical_accuracy: 0.9788\n",
      "Epoch 83/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0087 - categorical_accuracy: 0.9805 - val_loss: 0.0091 - val_categorical_accuracy: 0.9813\n",
      "Epoch 84/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0088 - categorical_accuracy: 0.9803 - val_loss: 0.0094 - val_categorical_accuracy: 0.9805\n",
      "Epoch 85/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0090 - categorical_accuracy: 0.9803 - val_loss: 0.0091 - val_categorical_accuracy: 0.9817\n",
      "Epoch 86/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0088 - categorical_accuracy: 0.9808 - val_loss: 0.0094 - val_categorical_accuracy: 0.9797\n",
      "Epoch 87/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0092 - categorical_accuracy: 0.9796 - val_loss: 0.0091 - val_categorical_accuracy: 0.9807\n",
      "Epoch 88/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0091 - categorical_accuracy: 0.9800 - val_loss: 0.0098 - val_categorical_accuracy: 0.9803\n",
      "Epoch 89/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0087 - categorical_accuracy: 0.9805 - val_loss: 0.0088 - val_categorical_accuracy: 0.9815\n",
      "Epoch 90/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0087 - categorical_accuracy: 0.9804 - val_loss: 0.0094 - val_categorical_accuracy: 0.9811\n",
      "Epoch 91/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0086 - categorical_accuracy: 0.9810 - val_loss: 0.0086 - val_categorical_accuracy: 0.9823\n",
      "Epoch 92/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0084 - categorical_accuracy: 0.9810 - val_loss: 0.0090 - val_categorical_accuracy: 0.9811\n",
      "Epoch 93/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0088 - categorical_accuracy: 0.9806 - val_loss: 0.0089 - val_categorical_accuracy: 0.9811\n",
      "Epoch 94/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0085 - categorical_accuracy: 0.9808 - val_loss: 0.0094 - val_categorical_accuracy: 0.9809\n",
      "Epoch 95/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0084 - categorical_accuracy: 0.9814 - val_loss: 0.0089 - val_categorical_accuracy: 0.9809\n",
      "Epoch 96/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0087 - categorical_accuracy: 0.9803 - val_loss: 0.0099 - val_categorical_accuracy: 0.9801\n",
      "Epoch 97/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0086 - categorical_accuracy: 0.9811 - val_loss: 0.0083 - val_categorical_accuracy: 0.9827\n",
      "Epoch 98/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0087 - categorical_accuracy: 0.9810 - val_loss: 0.0091 - val_categorical_accuracy: 0.9825\n",
      "Epoch 99/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0085 - categorical_accuracy: 0.9807 - val_loss: 0.0092 - val_categorical_accuracy: 0.9813\n",
      "Epoch 100/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93413/93413 [==============================] - 48s - loss: 0.0086 - categorical_accuracy: 0.9809 - val_loss: 0.0096 - val_categorical_accuracy: 0.9815\n",
      "Epoch 101/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0087 - categorical_accuracy: 0.9809 - val_loss: 0.0096 - val_categorical_accuracy: 0.9805\n",
      "Epoch 102/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0084 - categorical_accuracy: 0.9815 - val_loss: 0.0095 - val_categorical_accuracy: 0.9823\n",
      "Epoch 103/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0089 - categorical_accuracy: 0.9805 - val_loss: 0.0090 - val_categorical_accuracy: 0.9813\n",
      "Epoch 104/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0086 - categorical_accuracy: 0.9813 - val_loss: 0.0094 - val_categorical_accuracy: 0.9815\n",
      "Epoch 105/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0086 - categorical_accuracy: 0.9807 - val_loss: 0.0098 - val_categorical_accuracy: 0.9799\n",
      "Epoch 106/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0089 - categorical_accuracy: 0.9798 - val_loss: 0.0090 - val_categorical_accuracy: 0.9791\n",
      "Epoch 107/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0083 - categorical_accuracy: 0.9815 - val_loss: 0.0092 - val_categorical_accuracy: 0.9825\n",
      "Epoch 108/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0086 - categorical_accuracy: 0.9811 - val_loss: 0.0095 - val_categorical_accuracy: 0.9801\n",
      "Epoch 109/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0089 - categorical_accuracy: 0.9802 - val_loss: 0.0090 - val_categorical_accuracy: 0.9823\n",
      "Epoch 110/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0086 - categorical_accuracy: 0.9813 - val_loss: 0.0098 - val_categorical_accuracy: 0.9803\n",
      "Epoch 111/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0088 - categorical_accuracy: 0.9802 - val_loss: 0.0086 - val_categorical_accuracy: 0.9821\n",
      "Epoch 112/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0087 - categorical_accuracy: 0.9809 - val_loss: 0.0092 - val_categorical_accuracy: 0.9837\n",
      "Epoch 113/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0086 - categorical_accuracy: 0.9812 - val_loss: 0.0094 - val_categorical_accuracy: 0.9809\n",
      "Epoch 114/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0087 - categorical_accuracy: 0.9808 - val_loss: 0.0092 - val_categorical_accuracy: 0.9819\n",
      "Epoch 115/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0083 - categorical_accuracy: 0.9814 - val_loss: 0.0094 - val_categorical_accuracy: 0.9803\n",
      "Epoch 116/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0082 - categorical_accuracy: 0.9816 - val_loss: 0.0092 - val_categorical_accuracy: 0.9815\n",
      "Epoch 117/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0084 - categorical_accuracy: 0.9814 - val_loss: 0.0090 - val_categorical_accuracy: 0.9817\n",
      "Epoch 118/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0085 - categorical_accuracy: 0.9813 - val_loss: 0.0091 - val_categorical_accuracy: 0.9801\n",
      "Epoch 119/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0084 - categorical_accuracy: 0.9814 - val_loss: 0.0097 - val_categorical_accuracy: 0.9809\n",
      "Epoch 120/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0084 - categorical_accuracy: 0.9819 - val_loss: 0.0086 - val_categorical_accuracy: 0.9819\n",
      "Epoch 121/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0086 - categorical_accuracy: 0.9813 - val_loss: 0.0097 - val_categorical_accuracy: 0.9807\n",
      "Epoch 122/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0087 - categorical_accuracy: 0.9805 - val_loss: 0.0094 - val_categorical_accuracy: 0.9819\n",
      "Epoch 123/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0085 - categorical_accuracy: 0.9812 - val_loss: 0.0089 - val_categorical_accuracy: 0.9825\n",
      "Epoch 124/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0086 - categorical_accuracy: 0.9806 - val_loss: 0.0094 - val_categorical_accuracy: 0.9805\n",
      "Epoch 125/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0085 - categorical_accuracy: 0.9812 - val_loss: 0.0094 - val_categorical_accuracy: 0.9795\n",
      "Epoch 126/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0081 - categorical_accuracy: 0.9819 - val_loss: 0.0091 - val_categorical_accuracy: 0.9809\n",
      "Epoch 127/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0080 - categorical_accuracy: 0.9821 - val_loss: 0.0089 - val_categorical_accuracy: 0.9817\n",
      "Epoch 128/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0082 - categorical_accuracy: 0.9814 - val_loss: 0.0089 - val_categorical_accuracy: 0.9821\n",
      "Epoch 129/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0085 - categorical_accuracy: 0.9810 - val_loss: 0.0097 - val_categorical_accuracy: 0.9793\n",
      "Epoch 130/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0085 - categorical_accuracy: 0.9815 - val_loss: 0.0088 - val_categorical_accuracy: 0.9825\n",
      "Epoch 131/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0081 - categorical_accuracy: 0.9824 - val_loss: 0.0089 - val_categorical_accuracy: 0.9827\n",
      "Epoch 132/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0084 - categorical_accuracy: 0.9815 - val_loss: 0.0096 - val_categorical_accuracy: 0.9821\n",
      "Epoch 133/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0082 - categorical_accuracy: 0.9818 - val_loss: 0.0083 - val_categorical_accuracy: 0.9817\n",
      "Epoch 134/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0080 - categorical_accuracy: 0.9825 - val_loss: 0.0088 - val_categorical_accuracy: 0.9809\n",
      "Epoch 135/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0080 - categorical_accuracy: 0.9823 - val_loss: 0.0089 - val_categorical_accuracy: 0.9817\n",
      "Epoch 136/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0084 - categorical_accuracy: 0.9818 - val_loss: 0.0095 - val_categorical_accuracy: 0.9803\n",
      "Epoch 137/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0082 - categorical_accuracy: 0.9814 - val_loss: 0.0095 - val_categorical_accuracy: 0.9788\n",
      "Epoch 138/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0083 - categorical_accuracy: 0.9815 - val_loss: 0.0088 - val_categorical_accuracy: 0.9815\n",
      "Epoch 139/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0081 - categorical_accuracy: 0.9823 - val_loss: 0.0096 - val_categorical_accuracy: 0.9799\n",
      "Epoch 140/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0085 - categorical_accuracy: 0.9810 - val_loss: 0.0100 - val_categorical_accuracy: 0.9807\n",
      "Epoch 141/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0084 - categorical_accuracy: 0.9814 - val_loss: 0.0093 - val_categorical_accuracy: 0.9821\n",
      "Epoch 142/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0083 - categorical_accuracy: 0.9815 - val_loss: 0.0088 - val_categorical_accuracy: 0.9827\n",
      "Epoch 143/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0081 - categorical_accuracy: 0.9821 - val_loss: 0.0089 - val_categorical_accuracy: 0.9819\n",
      "Epoch 144/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0083 - categorical_accuracy: 0.9820 - val_loss: 0.0087 - val_categorical_accuracy: 0.9829\n",
      "Epoch 145/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0083 - categorical_accuracy: 0.9820 - val_loss: 0.0090 - val_categorical_accuracy: 0.9819\n",
      "Epoch 146/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0083 - categorical_accuracy: 0.9817 - val_loss: 0.0091 - val_categorical_accuracy: 0.9821\n",
      "Epoch 147/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0082 - categorical_accuracy: 0.9816 - val_loss: 0.0092 - val_categorical_accuracy: 0.9823\n",
      "Epoch 148/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0087 - categorical_accuracy: 0.9806 - val_loss: 0.0087 - val_categorical_accuracy: 0.9835\n",
      "Epoch 149/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93413/93413 [==============================] - 48s - loss: 0.0083 - categorical_accuracy: 0.9814 - val_loss: 0.0091 - val_categorical_accuracy: 0.9819\n",
      "Epoch 150/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0080 - categorical_accuracy: 0.9825 - val_loss: 0.0093 - val_categorical_accuracy: 0.9823\n",
      "Epoch 151/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0081 - categorical_accuracy: 0.9821 - val_loss: 0.0088 - val_categorical_accuracy: 0.9813\n",
      "Epoch 152/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0081 - categorical_accuracy: 0.9815 - val_loss: 0.0084 - val_categorical_accuracy: 0.9823\n",
      "Epoch 153/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0079 - categorical_accuracy: 0.9824 - val_loss: 0.0093 - val_categorical_accuracy: 0.9817\n",
      "Epoch 154/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0079 - categorical_accuracy: 0.9822 - val_loss: 0.0087 - val_categorical_accuracy: 0.9813\n",
      "Epoch 155/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0080 - categorical_accuracy: 0.9823 - val_loss: 0.0116 - val_categorical_accuracy: 0.9770\n",
      "Epoch 156/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0081 - categorical_accuracy: 0.9822 - val_loss: 0.0088 - val_categorical_accuracy: 0.9819\n",
      "Epoch 157/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0081 - categorical_accuracy: 0.9822 - val_loss: 0.0087 - val_categorical_accuracy: 0.9829\n",
      "Epoch 158/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0079 - categorical_accuracy: 0.9825 - val_loss: 0.0092 - val_categorical_accuracy: 0.9811\n",
      "Epoch 159/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0084 - categorical_accuracy: 0.9816 - val_loss: 0.0088 - val_categorical_accuracy: 0.9819\n",
      "Epoch 160/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0084 - categorical_accuracy: 0.9815 - val_loss: 0.0094 - val_categorical_accuracy: 0.9791\n",
      "Epoch 161/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0081 - categorical_accuracy: 0.9821 - val_loss: 0.0094 - val_categorical_accuracy: 0.9797\n",
      "Epoch 162/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0081 - categorical_accuracy: 0.9823 - val_loss: 0.0089 - val_categorical_accuracy: 0.9815\n",
      "Epoch 163/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0082 - categorical_accuracy: 0.9820 - val_loss: 0.0094 - val_categorical_accuracy: 0.9821\n",
      "Epoch 164/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0083 - categorical_accuracy: 0.9819 - val_loss: 0.0085 - val_categorical_accuracy: 0.9825\n",
      "Epoch 165/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0082 - categorical_accuracy: 0.9821 - val_loss: 0.0089 - val_categorical_accuracy: 0.9823\n",
      "Epoch 166/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0079 - categorical_accuracy: 0.9828 - val_loss: 0.0086 - val_categorical_accuracy: 0.9809\n",
      "Epoch 167/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0080 - categorical_accuracy: 0.9827 - val_loss: 0.0088 - val_categorical_accuracy: 0.9821\n",
      "Epoch 168/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0083 - categorical_accuracy: 0.9813 - val_loss: 0.0092 - val_categorical_accuracy: 0.9805\n",
      "Epoch 169/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0080 - categorical_accuracy: 0.9824 - val_loss: 0.0087 - val_categorical_accuracy: 0.9827\n",
      "Epoch 170/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0078 - categorical_accuracy: 0.9834 - val_loss: 0.0094 - val_categorical_accuracy: 0.9817\n",
      "Epoch 171/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0080 - categorical_accuracy: 0.9823 - val_loss: 0.0090 - val_categorical_accuracy: 0.9825\n",
      "Epoch 172/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0080 - categorical_accuracy: 0.9824 - val_loss: 0.0087 - val_categorical_accuracy: 0.9817\n",
      "Epoch 173/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0080 - categorical_accuracy: 0.9822 - val_loss: 0.0089 - val_categorical_accuracy: 0.9805\n",
      "Epoch 174/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0077 - categorical_accuracy: 0.9830 - val_loss: 0.0089 - val_categorical_accuracy: 0.9821\n",
      "Epoch 175/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0080 - categorical_accuracy: 0.9820 - val_loss: 0.0090 - val_categorical_accuracy: 0.9811\n",
      "Epoch 176/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0081 - categorical_accuracy: 0.9816 - val_loss: 0.0090 - val_categorical_accuracy: 0.9811\n",
      "Epoch 177/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0079 - categorical_accuracy: 0.9825 - val_loss: 0.0090 - val_categorical_accuracy: 0.9819\n",
      "Epoch 178/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0079 - categorical_accuracy: 0.9829 - val_loss: 0.0102 - val_categorical_accuracy: 0.9819\n",
      "Epoch 179/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0081 - categorical_accuracy: 0.9818 - val_loss: 0.0094 - val_categorical_accuracy: 0.9823\n",
      "Epoch 180/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0078 - categorical_accuracy: 0.9829 - val_loss: 0.0092 - val_categorical_accuracy: 0.9825\n",
      "Epoch 181/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0079 - categorical_accuracy: 0.9830 - val_loss: 0.0085 - val_categorical_accuracy: 0.9837\n",
      "Epoch 182/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0078 - categorical_accuracy: 0.9826 - val_loss: 0.0083 - val_categorical_accuracy: 0.9831\n",
      "Epoch 183/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0077 - categorical_accuracy: 0.9830 - val_loss: 0.0093 - val_categorical_accuracy: 0.9801\n",
      "Epoch 184/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0079 - categorical_accuracy: 0.9826 - val_loss: 0.0089 - val_categorical_accuracy: 0.9801\n",
      "Epoch 185/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0078 - categorical_accuracy: 0.9827 - val_loss: 0.0091 - val_categorical_accuracy: 0.9819\n",
      "Epoch 186/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0078 - categorical_accuracy: 0.9827 - val_loss: 0.0092 - val_categorical_accuracy: 0.9805\n",
      "Epoch 187/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0077 - categorical_accuracy: 0.9830 - val_loss: 0.0082 - val_categorical_accuracy: 0.9821\n",
      "Epoch 188/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0080 - categorical_accuracy: 0.9824 - val_loss: 0.0085 - val_categorical_accuracy: 0.9815\n",
      "Epoch 189/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0077 - categorical_accuracy: 0.9832 - val_loss: 0.0092 - val_categorical_accuracy: 0.9823\n",
      "Epoch 190/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0075 - categorical_accuracy: 0.9834 - val_loss: 0.0092 - val_categorical_accuracy: 0.9815\n",
      "Epoch 191/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0080 - categorical_accuracy: 0.9828 - val_loss: 0.0096 - val_categorical_accuracy: 0.9819\n",
      "Epoch 192/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0078 - categorical_accuracy: 0.9827 - val_loss: 0.0092 - val_categorical_accuracy: 0.9815\n",
      "Epoch 193/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0078 - categorical_accuracy: 0.9831 - val_loss: 0.0095 - val_categorical_accuracy: 0.9815\n",
      "Epoch 194/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0079 - categorical_accuracy: 0.9824 - val_loss: 0.0088 - val_categorical_accuracy: 0.9837\n",
      "Epoch 195/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0077 - categorical_accuracy: 0.9827 - val_loss: 0.0096 - val_categorical_accuracy: 0.9809\n",
      "Epoch 196/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0080 - categorical_accuracy: 0.9827 - val_loss: 0.0087 - val_categorical_accuracy: 0.9833\n",
      "Epoch 197/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0079 - categorical_accuracy: 0.9825 - val_loss: 0.0088 - val_categorical_accuracy: 0.9827\n",
      "Epoch 198/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93413/93413 [==============================] - 48s - loss: 0.0076 - categorical_accuracy: 0.9830 - val_loss: 0.0088 - val_categorical_accuracy: 0.9833\n",
      "Epoch 199/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0080 - categorical_accuracy: 0.9825 - val_loss: 0.0098 - val_categorical_accuracy: 0.9799\n",
      "Epoch 200/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0078 - categorical_accuracy: 0.9829 - val_loss: 0.0085 - val_categorical_accuracy: 0.9831\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=1024, validation_data=(X_valid, y_valid), \\\n",
    "          epochs=200, shuffle=True, verbose=1)\n",
    "model.save(os.path.join(OUTPUT_PATH, 'cnn_new_400.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4917/4917 [==============================] - 1s     \n"
     ]
    }
   ],
   "source": [
    "preds_proba = model.predict(X_valid, batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 정확도 : 0.98312\n",
      "\n",
      " -------------------------- \n",
      "\n",
      "preds     _silence  _unknown  down   go  left   no  off   on  right  stop  \\\n",
      "actuals                                                                     \n",
      "_silence        49         2     0    0     0    0    0    0      0     0   \n",
      "_unknown         0      3030     2    2     0    1    0    0      1     1   \n",
      "down             0         7   167    0     0    1    0    0      0     0   \n",
      "go               0         5     0  161     0    0    0    0      1     0   \n",
      "left             0         9     0    0   202    0    0    0      0     0   \n",
      "no               0         1     2    1     0  175    0    0      0     0   \n",
      "off              0         7     0    0     0    0  167    0      0     0   \n",
      "on               0        11     0    0     0    0    1  190      0     0   \n",
      "right            0         9     0    0     0    0    0    0    163     0   \n",
      "stop             0         4     0    0     0    0    0    0      0   186   \n",
      "up               0         3     0    0     0    0    3    0      0     0   \n",
      "yes              1         1     0    0     0    0    0    0      0     0   \n",
      "\n",
      "preds      up  yes  \n",
      "actuals             \n",
      "_silence    0    0  \n",
      "_unknown    1    0  \n",
      "down        0    0  \n",
      "go          0    0  \n",
      "left        0    0  \n",
      "no          0    0  \n",
      "off         3    0  \n",
      "on          0    0  \n",
      "right       0    0  \n",
      "stop        2    0  \n",
      "up        187    0  \n",
      "yes         1  157  \n",
      "\n",
      " -------------------------- \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   _silence       0.98      0.96      0.97        51\n",
      "   _unknown       0.98      1.00      0.99      3038\n",
      "       down       0.98      0.95      0.97       175\n",
      "         go       0.98      0.96      0.97       167\n",
      "       left       1.00      0.96      0.98       211\n",
      "         no       0.99      0.98      0.98       179\n",
      "        off       0.98      0.94      0.96       177\n",
      "         on       1.00      0.94      0.97       202\n",
      "      right       0.99      0.95      0.97       172\n",
      "       stop       0.99      0.97      0.98       192\n",
      "         up       0.96      0.97      0.97       193\n",
      "        yes       1.00      0.98      0.99       160\n",
      "\n",
      "avg / total       0.98      0.98      0.98      4917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = [LABELS[i] for i in np.argmax(preds_proba, axis=1)]\n",
    "actuals = [LABELS[i] for i in np.argmax(y_valid, axis=1)]\n",
    "print('* 정확도 : %.5f' % (np.sum(np.array(actuals) == np.array(preds)) / float(len(actuals))))\n",
    "preds = pd.Categorical(preds, categories=LABELS)\n",
    "actuals = pd.Categorical(actuals, categories=LABELS)\n",
    "print('\\n -------------------------- \\n')\n",
    "print(pd.crosstab(actuals, preds, rownames=['actuals'], colnames=['preds']))\n",
    "print('\\n -------------------------- \\n')\n",
    "print(classification_report(actuals, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 정확도 : 0.96970\n",
      "\n",
      " -------------------------- \n",
      "\n",
      "preds     _silence  _unknown  down   go  left   no  off   on  right  stop  \\\n",
      "actuals                                                                     \n",
      "_silence        46         2     0    0     0    0    0    1      0     0   \n",
      "_unknown         2      2941    14   14     8    8    8   25      4     4   \n",
      "down             0         1   171    1     0    2    0    0      0     0   \n",
      "go               0         2     0  161     0    1    0    1      0     0   \n",
      "left             1         1     0    0   207    0    0    1      1     0   \n",
      "no               0         0     2    1     0  175    0    0      0     0   \n",
      "off              0         4     0    0     0    0  171    1      0     0   \n",
      "on               0         4     0    0     0    0    3  194      0     1   \n",
      "right            0         4     0    0     1    0    0    0    167     0   \n",
      "stop             0         1     1    1     0    0    0    0      0   188   \n",
      "up               0         0     0    0     0    0    3    1      0     0   \n",
      "yes              1         0     0    0     0    0    0    1      0     0   \n",
      "\n",
      "preds      up  yes  \n",
      "actuals             \n",
      "_silence    0    2  \n",
      "_unknown    8    2  \n",
      "down        0    0  \n",
      "go          2    0  \n",
      "left        0    0  \n",
      "no          0    1  \n",
      "off         1    0  \n",
      "on          0    0  \n",
      "right       0    0  \n",
      "stop        1    0  \n",
      "up        189    0  \n",
      "yes         0  158  \n",
      "\n",
      " -------------------------- \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   _silence       0.92      0.90      0.91        51\n",
      "   _unknown       0.99      0.97      0.98      3038\n",
      "       down       0.91      0.98      0.94       175\n",
      "         go       0.90      0.96      0.93       167\n",
      "       left       0.96      0.98      0.97       211\n",
      "         no       0.94      0.98      0.96       179\n",
      "        off       0.92      0.97      0.94       177\n",
      "         on       0.86      0.96      0.91       202\n",
      "      right       0.97      0.97      0.97       172\n",
      "       stop       0.97      0.98      0.98       192\n",
      "         up       0.94      0.98      0.96       193\n",
      "        yes       0.97      0.99      0.98       160\n",
      "\n",
      "avg / total       0.97      0.97      0.97      4917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = [LABELS[i] for i in np.argmax(preds_proba, axis=1)]\n",
    "actuals = [LABELS[i] for i in np.argmax(y_valid, axis=1)]\n",
    "print('* 정확도 : %.5f' % (np.sum(np.array(actuals) == np.array(preds)) / float(len(actuals))))\n",
    "preds = pd.Categorical(preds, categories=LABELS)\n",
    "actuals = pd.Categorical(actuals, categories=LABELS)\n",
    "print('\\n -------------------------- \\n')\n",
    "print(pd.crosstab(actuals, preds, rownames=['actuals'], colnames=['preds']))\n",
    "print('\\n -------------------------- \\n')\n",
    "print(classification_report(actuals, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 정확도 : 0.96658\n",
      "\n",
      " -------------------------- \n",
      "\n",
      "preds     _silence  _unknown  down   go  left   no  off   on  right  stop  \\\n",
      "actuals                                                                     \n",
      "_silence        63         0     0    0     0    0    0    0      0     0   \n",
      "_unknown         3      2971     7   25    11    9   19   20     10     8   \n",
      "down             0         0   169    2     0    3    0    0      0     0   \n",
      "go               0         1     0  161     0    2    1    1      0     1   \n",
      "left             0         1     0    0   173    0    0    4      0     0   \n",
      "no               0         1     0    1     0  175    0    1      0     0   \n",
      "off              1         0     0    1     0    0  168    1      0     0   \n",
      "on               0         1     0    3     0    0    1  160      0     0   \n",
      "right            2         2     0    0     0    0    0    1    154     0   \n",
      "stop             1         0     0    0     0    0    0    1      0   199   \n",
      "up               0         0     0    0     0    0    0    0      0     0   \n",
      "yes              0         1     0    0     0    0    0    0      0     0   \n",
      "\n",
      "preds      up  yes  \n",
      "actuals             \n",
      "_silence    0    0  \n",
      "_unknown   10    3  \n",
      "down        0    0  \n",
      "go          0    0  \n",
      "left        0    1  \n",
      "no          0    0  \n",
      "off         0    0  \n",
      "on          1    0  \n",
      "right       0    0  \n",
      "stop        2    0  \n",
      "up        171    0  \n",
      "yes         0  179  \n",
      "\n",
      " -------------------------- \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   _silence       0.90      1.00      0.95        63\n",
      "   _unknown       1.00      0.96      0.98      3096\n",
      "       down       0.96      0.97      0.97       174\n",
      "         go       0.83      0.96      0.89       167\n",
      "       left       0.94      0.97      0.95       179\n",
      "         no       0.93      0.98      0.95       178\n",
      "        off       0.89      0.98      0.93       171\n",
      "         on       0.85      0.96      0.90       166\n",
      "      right       0.94      0.97      0.95       159\n",
      "       stop       0.96      0.98      0.97       203\n",
      "         up       0.93      1.00      0.96       171\n",
      "        yes       0.98      0.99      0.99       180\n",
      "\n",
      "avg / total       0.97      0.97      0.97      4907\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = [LABELS[i] for i in np.argmax(preds_proba, axis=1)]\n",
    "actuals = [LABELS[i] for i in np.argmax(y_valid, axis=1)]\n",
    "print('* 정확도 : %.5f' % (np.sum(np.array(actuals) == np.array(preds)) / float(len(actuals))))\n",
    "preds = pd.Categorical(preds, categories=LABELS)\n",
    "actuals = pd.Categorical(actuals, categories=LABELS)\n",
    "print('\\n -------------------------- \\n')\n",
    "print(pd.crosstab(actuals, preds, rownames=['actuals'], colnames=['preds']))\n",
    "print('\\n -------------------------- \\n')\n",
    "print(classification_report(actuals, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      "[ 0.          0.95999998  0.03        0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.        ]\n",
      "[ 0.          0.          0.          0.99000001  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.        ]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      "[ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.          0.55000001  0.          0.01        0.          0.44        0.\n",
      "  0.          0.          0.          0.          0.        ]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.          0.99000001  0.          0.01        0.          0.          0.\n",
      "  0.          0.          0.          0.          0.        ]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.          0.98000002  0.01        0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.        ]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.          0.61000001  0.          0.          0.          0.          0.11\n",
      "  0.25999999  0.          0.01        0.          0.        ]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      "[ 0.          0.99000001  0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.01      ]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.95999998  0.03        0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.        ]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.          0.          0.92000002  0.08        0.          0.          0.\n",
      "  0.          0.          0.          0.          0.        ]\n",
      "[ 0.          0.25999999  0.73000002  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.        ]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.          0.95999998  0.04        0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.        ]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    t= preds_proba[i].round(decimals=2)\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 정확도 : 0.98288\n",
      "\n",
      " -------------------------- \n",
      "\n",
      "preds     _silence  _unknown  down   go  left   no  off   on  right  stop  \\\n",
      "actuals                                                                     \n",
      "_silence        63         0     0    0     0    0    0    0      0     0   \n",
      "_unknown         3      3075     1    4     0    3    1    2      2     2   \n",
      "down             0         2   170    1     0    0    0    0      0     0   \n",
      "go               0         4     0  158     0    3    0    0      0     2   \n",
      "left             0         6     0    0   171    0    0    0      0     0   \n",
      "no               0         1     1    3     0  172    0    0      0     0   \n",
      "off              1         2     0    0     0    0  162    2      0     0   \n",
      "on               0         6     0    1     0    0    4  155      0     0   \n",
      "right            2         2     0    0     1    0    0    0    153     0   \n",
      "stop             1         3     0    0     0    0    0    0      0   198   \n",
      "up               0         2     1    0     0    0    0    0      0     0   \n",
      "yes              0         1     0    0     0    1    0    0      0     0   \n",
      "\n",
      "preds      up  yes  \n",
      "actuals             \n",
      "_silence    0    0  \n",
      "_unknown    1    2  \n",
      "down        0    1  \n",
      "go          0    0  \n",
      "left        0    2  \n",
      "no          0    1  \n",
      "off         4    0  \n",
      "on          0    0  \n",
      "right       0    1  \n",
      "stop        1    0  \n",
      "up        168    0  \n",
      "yes         0  178  \n",
      "\n",
      " -------------------------- \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   _silence       0.90      1.00      0.95        63\n",
      "   _unknown       0.99      0.99      0.99      3096\n",
      "       down       0.98      0.98      0.98       174\n",
      "         go       0.95      0.95      0.95       167\n",
      "       left       0.99      0.96      0.97       179\n",
      "         no       0.96      0.97      0.96       178\n",
      "        off       0.97      0.95      0.96       171\n",
      "         on       0.97      0.93      0.95       166\n",
      "      right       0.99      0.96      0.97       159\n",
      "       stop       0.98      0.98      0.98       203\n",
      "         up       0.97      0.98      0.97       171\n",
      "        yes       0.96      0.99      0.98       180\n",
      "\n",
      "avg / total       0.98      0.98      0.98      4907\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = [LABELS[i] for i in np.argmax(preds_proba, axis=1)]\n",
    "actuals = [LABELS[i] for i in np.argmax(y_valid, axis=1)]\n",
    "print('* 정확도 : %.5f' % (np.sum(np.array(actuals) == np.array(preds)) / float(len(actuals))))\n",
    "preds = pd.Categorical(preds, categories=LABELS)\n",
    "actuals = pd.Categorical(actuals, categories=LABELS)\n",
    "print('\\n -------------------------- \\n')\n",
    "print(pd.crosstab(actuals, preds, rownames=['actuals'], colnames=['preds']))\n",
    "print('\\n -------------------------- \\n')\n",
    "print(classification_report(actuals, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 정확도 : 0.97493\n",
      "\n",
      " -------------------------- \n",
      "\n",
      "preds     _silence  _unknown  down   go  left   no  off   on  right  stop  \\\n",
      "actuals                                                                     \n",
      "_silence        63         0     0    0     0    0    0    0      0     0   \n",
      "_unknown         5      3014     1    7     4    6    6    9     20    12   \n",
      "down             0         2   169    2     0    1    0    0      0     0   \n",
      "go               0         5     0  160     0    1    0    0      0     0   \n",
      "left             0         1     0    0   173    0    0    2      0     1   \n",
      "no               0         0     0    2     0  175    0    0      0     1   \n",
      "off              1         0     0    1     0    0  166    1      0     0   \n",
      "on               0         2     1    2     0    0    1  160      0     0   \n",
      "right            2         2     0    0     0    0    0    0    154     0   \n",
      "stop             0         0     0    0     0    0    1    1      0   200   \n",
      "up               0         0     0    0     0    0    1    0      0     0   \n",
      "yes              0         0     0    0     0    0    0    0      0     0   \n",
      "\n",
      "preds      up  yes  \n",
      "actuals             \n",
      "_silence    0    0  \n",
      "_unknown    5    7  \n",
      "down        0    0  \n",
      "go          1    0  \n",
      "left        0    2  \n",
      "no          0    0  \n",
      "off         2    0  \n",
      "on          0    0  \n",
      "right       0    1  \n",
      "stop        1    0  \n",
      "up        170    0  \n",
      "yes         0  180  \n",
      "\n",
      " -------------------------- \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   _silence       0.89      1.00      0.94        63\n",
      "   _unknown       1.00      0.97      0.98      3096\n",
      "       down       0.99      0.97      0.98       174\n",
      "         go       0.92      0.96      0.94       167\n",
      "       left       0.98      0.97      0.97       179\n",
      "         no       0.96      0.98      0.97       178\n",
      "        off       0.95      0.97      0.96       171\n",
      "         on       0.92      0.96      0.94       166\n",
      "      right       0.89      0.97      0.92       159\n",
      "       stop       0.93      0.99      0.96       203\n",
      "         up       0.95      0.99      0.97       171\n",
      "        yes       0.95      1.00      0.97       180\n",
      "\n",
      "avg / total       0.98      0.97      0.98      4907\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = [LABELS[i] for i in np.argmax(preds_proba, axis=1)]\n",
    "actuals = [LABELS[i] for i in np.argmax(y_valid, axis=1)]\n",
    "print('* 정확도 : %.5f' % (np.sum(np.array(actuals) == np.array(preds)) / float(len(actuals))))\n",
    "preds = pd.Categorical(preds, categories=LABELS)\n",
    "actuals = pd.Categorical(actuals, categories=LABELS)\n",
    "print('\\n -------------------------- \\n')\n",
    "print(pd.crosstab(actuals, preds, rownames=['actuals'], colnames=['preds']))\n",
    "print('\\n -------------------------- \\n')\n",
    "print(classification_report(actuals, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 정확도 : 0.97330\n",
      "\n",
      " -------------------------- \n",
      "\n",
      "preds     _silence  _unknown  down   go  left   no  off   on  right  stop  \\\n",
      "actuals                                                                     \n",
      "_silence        63         0     0    0     0    0    0    0      0     0   \n",
      "_unknown         9      3013     4    7     5    5    7   13     13     8   \n",
      "down             0         1   171    1     0    1    0    0      0     0   \n",
      "go               0         3     0  158     0    2    0    0      1     2   \n",
      "left             0         1     0    0   172    1    1    2      0     0   \n",
      "no               0         0     1    1     0  175    0    0      0     0   \n",
      "off              1         1     0    1     0    0  166    1      0     0   \n",
      "on               0         4     0    1     0    0    1  159      0     0   \n",
      "right            3         1     0    0     0    0    0    0    154     0   \n",
      "stop             1         1     0    0     0    0    1    1      0   197   \n",
      "up               1         0     0    0     0    0    1    0      0     0   \n",
      "yes              0         0     0    0     1    0    0    0      0     0   \n",
      "\n",
      "preds      up  yes  \n",
      "actuals             \n",
      "_silence    0    0  \n",
      "_unknown    5    7  \n",
      "down        0    0  \n",
      "go          1    0  \n",
      "left        1    1  \n",
      "no          0    1  \n",
      "off         1    0  \n",
      "on          1    0  \n",
      "right       0    1  \n",
      "stop        2    0  \n",
      "up        169    0  \n",
      "yes         0  179  \n",
      "\n",
      " -------------------------- \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   _silence       0.81      1.00      0.89        63\n",
      "   _unknown       1.00      0.97      0.98      3096\n",
      "       down       0.97      0.98      0.98       174\n",
      "         go       0.93      0.95      0.94       167\n",
      "       left       0.97      0.96      0.96       179\n",
      "         no       0.95      0.98      0.97       178\n",
      "        off       0.94      0.97      0.95       171\n",
      "         on       0.90      0.96      0.93       166\n",
      "      right       0.92      0.97      0.94       159\n",
      "       stop       0.95      0.97      0.96       203\n",
      "         up       0.94      0.99      0.96       171\n",
      "        yes       0.95      0.99      0.97       180\n",
      "\n",
      "avg / total       0.97      0.97      0.97      4907\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = [LABELS[i] for i in np.argmax(preds_proba, axis=1)]\n",
    "actuals = [LABELS[i] for i in np.argmax(y_valid, axis=1)]\n",
    "print('* 정확도 : %.5f' % (np.sum(np.array(actuals) == np.array(preds)) / float(len(actuals))))\n",
    "preds = pd.Categorical(preds, categories=LABELS)\n",
    "actuals = pd.Categorical(actuals, categories=LABELS)\n",
    "print('\\n -------------------------- \\n')\n",
    "print(pd.crosstab(actuals, preds, rownames=['actuals'], colnames=['preds']))\n",
    "print('\\n -------------------------- \\n')\n",
    "print(classification_report(actuals, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 정확도 : 0.97028\n",
      "\n",
      " -------------------------- \n",
      "\n",
      "preds     _silence  _unknown  down  go  left   no  off  on  right  stop   up  \\\n",
      "actuals                                                                        \n",
      "_silence        54         0     0   0     0    0    0   0      0     0    0   \n",
      "_unknown         4      2029     0   7     1    9    2   1      0     0    4   \n",
      "down             0         4   128   1     0    1    0   0      0     0    0   \n",
      "go               0         5     4  87     0    2    0   0      0     0    0   \n",
      "left             0         6     0   0   126    0    0   0      0     0    2   \n",
      "no               0         4     2   0     0  103    0   0      0     1    0   \n",
      "off              1         6     1   0     1    0  100   0      0     1    1   \n",
      "on               0         4     0   0     0    0    1  98      0     0    0   \n",
      "right            0         5     0   0     1    0    0   0    121     0    0   \n",
      "stop             0         4     1   0     0    1    0   0      0   118    2   \n",
      "up               2         2     0   0     0    0    0   0      0     0  122   \n",
      "yes              0         1     0   0     0    0    0   0      0     0    0   \n",
      "\n",
      "preds     yes  \n",
      "actuals        \n",
      "_silence    0  \n",
      "_unknown    1  \n",
      "down        1  \n",
      "go          0  \n",
      "left        1  \n",
      "no          0  \n",
      "off         0  \n",
      "on          0  \n",
      "right       0  \n",
      "stop        0  \n",
      "up          0  \n",
      "yes       113  \n",
      "\n",
      " -------------------------- \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   _silence       0.89      1.00      0.94        54\n",
      "   _unknown       0.98      0.99      0.98      2058\n",
      "       down       0.94      0.95      0.94       135\n",
      "         go       0.92      0.89      0.90        98\n",
      "       left       0.98      0.93      0.95       135\n",
      "         no       0.89      0.94      0.91       110\n",
      "        off       0.97      0.90      0.93       111\n",
      "         on       0.99      0.95      0.97       103\n",
      "      right       1.00      0.95      0.98       127\n",
      "       stop       0.98      0.94      0.96       126\n",
      "         up       0.93      0.97      0.95       126\n",
      "        yes       0.97      0.99      0.98       114\n",
      "\n",
      "avg / total       0.97      0.97      0.97      3297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = [LABELS[i] for i in np.argmax(preds_proba, axis=1)]\n",
    "actuals = [LABELS[i] for i in np.argmax(y_valid, axis=1)]\n",
    "print('* 정확도 : %.5f' % (np.sum(np.array(actuals) == np.array(preds)) / float(len(actuals))))\n",
    "preds = pd.Categorical(preds, categories=LABELS)\n",
    "actuals = pd.Categorical(actuals, categories=LABELS)\n",
    "print('\\n -------------------------- \\n')\n",
    "print(pd.crosstab(actuals, preds, rownames=['actuals'], colnames=['preds']))\n",
    "print('\\n -------------------------- \\n')\n",
    "print(classification_report(actuals, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "y = []\n",
    "X = []\n",
    "for i, (label, fname) in enumerate(zip(labels, fnames)):\n",
    "    sample_rate, samples = wavfile.read(os.path.join(TRAIN_PATH, label, fname))\n",
    "    if len(samples) > 16000:\n",
    "        pass\n",
    "    else:\n",
    "        samples = pad_audio(samples)\n",
    "#         resampled = signal.resample(samples, int(new_sample_rate / sample_rate * samples.shape[0]))\n",
    "#         _, _, specgram = log_specgram(resampled, sample_rate=new_sample_rate)\n",
    "        _, _, specgram = log_specgram(samples, sample_rate=16000)\n",
    "        y.append(label)\n",
    "        X.append(specgram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = load_model(os.path.join(OUTPUT_PATH, 'cnn_baseline_again_no_cw.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 제출파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 16s, sys: 3.25 s, total: 2min 19s\n",
      "Wall time: 2min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X = []\n",
    "submission_fpaths = sorted(glob(os.path.join(TEST_PATH, r'*wav')))\n",
    "for fpath in submission_fpaths:\n",
    "    sample_rate, samples = wavfile.read(fpath)\n",
    "    _, _, specgram = log_specgram(samples, sample_rate=16000)\n",
    "    X.append(specgram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "X = X.reshape(tuple(list(X.shape) + [1]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158538/158538 [==============================] - 26s    \n"
     ]
    }
   ],
   "source": [
    "preds_proba = model.predict(X, batch_size=2048, verbose=1)\n",
    "preds = [[L.replace('_', '') for L in LABELS][i] for i in np.argmax(preds_proba, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'fname': submission_fpaths, 'label': preds})\n",
    "df['fname'] = df['fname'].apply(lambda p: p.split('/')[-1])\n",
    "df.to_csv(os.path.join(OUTPUT_PATH, 'sub_' + MODEL_NAME.split('.')[0] + '.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  1.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  1.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ..., \n",
       "       [ 0.        ,  0.08      ,  0.        , ...,  0.92000002,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.52999997,  0.43000001,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.02      ],\n",
       "       [ 0.        ,  1.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_proba.round(decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for fpath in submission_fpaths:\n",
    "    sample_rate, samples = wavfile.read(fpath)\n",
    "    samples = pad_audio(samples)\n",
    "    if len(samples) > 16000:\n",
    "        n_samples = chop_audio(samples)\n",
    "    else: \n",
    "        n_samples = [samples]\n",
    "    for samples in n_samples:\n",
    "#         resampled = signal.resample(samples, int(new_sample_rate / sample_rate * samples.shape[0]))\n",
    "#         _, _, specgram = log_specgram(resampled, sample_rate=new_sample_rate)\n",
    "        _, _, specgram = log_specgram(samples, sample_rate=16000)\n",
    "        X.append(specgram)\n",
    "        \n",
    "X = np.array(X)\n",
    "X = X.reshape(tuple(list(X.shape) + [1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds_proba = model.predict(X, batch_size=2048, verbose=1)\n",
    "preds = [[L.replace('_', '') for L in LABELS][i] for i in np.argmax(preds_proba, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'fname': submission_fpaths, 'label': preds})\n",
    "df['fname'] = df['fname'].apply(lambda p: p.split('/')[-1])\n",
    "df.to_csv(os.path.join(OUTPUT_PATH, 'sub_' + MODEL_NAME.split('.')[0] + '.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown    101125\n",
       "off          6768\n",
       "no           6155\n",
       "on           5917\n",
       "go           5738\n",
       "up           5573\n",
       "yes          5297\n",
       "stop         5254\n",
       "left         5175\n",
       "down         4683\n",
       "right        3983\n",
       "silence      2870\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cw\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown    100749\n",
       "up           6000\n",
       "off          5928\n",
       "no           5673\n",
       "silence      5619\n",
       "go           5218\n",
       "left         5197\n",
       "stop         5191\n",
       "on           5160\n",
       "yes          5046\n",
       "right        4558\n",
       "down         4199\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no cw\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown    83693\n",
       "on         12284\n",
       "go          7641\n",
       "up          7575\n",
       "no          7171\n",
       "off         6637\n",
       "yes         6463\n",
       "left        6252\n",
       "stop        5649\n",
       "down        5579\n",
       "right       5492\n",
       "silence     4102\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown    100064\n",
       "up           6329\n",
       "off          6132\n",
       "on           5977\n",
       "no           5945\n",
       "go           5595\n",
       "yes          5563\n",
       "stop         5346\n",
       "left         5344\n",
       "down         4911\n",
       "right        4691\n",
       "silence      2641\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown    79111\n",
       "on         17357\n",
       "no          8149\n",
       "off         7381\n",
       "go          7010\n",
       "up          6905\n",
       "left        6389\n",
       "yes         5975\n",
       "stop        5941\n",
       "right       5803\n",
       "down        4760\n",
       "silence     3757\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#before\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown    100136\n",
       "off          6243\n",
       "stop         5855\n",
       "on           5683\n",
       "left         5659\n",
       "yes          5567\n",
       "no           5381\n",
       "go           5380\n",
       "up           5305\n",
       "right        5006\n",
       "down         4417\n",
       "silence      3906\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weight 안준거\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown    82664\n",
       "on         16551\n",
       "off         7639\n",
       "no          7616\n",
       "left        5922\n",
       "yes         5848\n",
       "right       5774\n",
       "go          5647\n",
       "down        5622\n",
       "stop        5601\n",
       "up          5448\n",
       "silence     4206\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weight 준거\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown    100591\n",
       "yes          6519\n",
       "off          6272\n",
       "stop         6064\n",
       "left         5637\n",
       "no           5428\n",
       "up           5392\n",
       "go           5237\n",
       "down         5135\n",
       "on           5126\n",
       "right        4923\n",
       "silence      2214\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown    81043\n",
       "on         14810\n",
       "off         7550\n",
       "up          7044\n",
       "right       6950\n",
       "left        6659\n",
       "go          6553\n",
       "stop        6360\n",
       "yes         6292\n",
       "no          6199\n",
       "down        4760\n",
       "silence     4318\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown    82108\n",
       "on         15084\n",
       "off         8341\n",
       "no          6978\n",
       "right       6541\n",
       "left        6510\n",
       "up          6284\n",
       "yes         6137\n",
       "stop        5775\n",
       "go          5678\n",
       "down        4916\n",
       "silence     4186\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
