{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.fftpack import fft\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "from glob import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "import gc\n",
    "from scipy.io import wavfile\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import optimizers, losses, activations, models\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.layers import Convolution2D, Dense, Input, Flatten, Dropout, MaxPooling2D, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_sample_rate = 8000\n",
    "\n",
    "LABELS = ['_silence', '_unknown', 'down', 'go', 'left', 'no', 'off', 'on', 'right', 'stop', 'up', 'yes']\n",
    "TRAIN_PATH = './input/train/audio/'\n",
    "OUTPUT_PATH = './output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## custom_fft and log_specgram functions written by DavidS.\n",
    "def custom_fft(y, fs):\n",
    "    T = 1.0 / fs\n",
    "    N = y.shape[0]\n",
    "    yf = fft(y)\n",
    "    xf = np.linspace(0.0, 1.0/(2.0*T), N//2)\n",
    "    # FFT 는 대칭(simmetrical)이므로 반쪽만 얻음.\n",
    "    # FFT 는 복소수이므로 실수값만 취하기 위해 abs()\n",
    "    vals = 2.0/N * np.abs(yf[0:N//2])\n",
    "    return xf, vals\n",
    "\n",
    "def log_specgram(audio, sample_rate, window_size=20, step_size=10, eps=1e-10):\n",
    "    nperseg = int(round(window_size * sample_rate / 1e3))\n",
    "    noverlap = int(round(step_size * sample_rate / 1e3))\n",
    "    freqs, times, spec = signal.spectrogram(audio,\n",
    "                                    fs=sample_rate,\n",
    "                                    window='hann',\n",
    "                                    nperseg=nperseg,\n",
    "                                    noverlap=noverlap,\n",
    "                                    detrend=False)\n",
    "    return freqs, times, np.log(spec.T.astype(np.float32) + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## utility function to grab all wav files inside train data folder.\n",
    "def list_wavs_fname(dirpath, ext='wav'):\n",
    "    print(dirpath)\n",
    "    fpaths = glob(os.path.join(dirpath, r'*/*' + ext))\n",
    "    pat = r'.+/(\\w+)/\\w+\\.' + ext + '$'\n",
    "    labels = []\n",
    "    for fpath in fpaths:\n",
    "        r = re.match(pat, fpath)\n",
    "        if r:\n",
    "            labels.append(r.group(1))\n",
    "    pat = r'.+/(\\w+\\.' + ext + ')$'\n",
    "    fnames = []\n",
    "    for fpath in fpaths:\n",
    "        r = re.match(pat, fpath)\n",
    "        if r:\n",
    "            fnames.append(r.group(1))\n",
    "    return labels, fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pad_audio(samples, L=16000):\n",
    "    '''\n",
    "    pad audios that are less than 16000(1 second) with 0s to make them all have the same length.\n",
    "    '''\n",
    "    if len(samples) >= L: \n",
    "        return samples\n",
    "    else: \n",
    "        return np.pad(samples, pad_width=(L - len(samples), 0), mode='constant', constant_values=(0, 0)) \n",
    "        # sample 앞뒤로 constant_values[0]과 constant_values[1]을 각각 pad_width 갯수 만큼 패딩\n",
    "        # 총길이는 len(samples) + 2*pad_width\n",
    "\n",
    "def chop_audio(samples, L=16000, num=20):\n",
    "    '''\n",
    "    chop audios that are larger than 16000(eg. wav files in background noises folder) to 16000 in length.\n",
    "    create several chunks out of one large wav files given the parameter 'num'.\n",
    "    '''\n",
    "    for i in range(num):\n",
    "        beg = np.random.randint(0, len(samples) - L)\n",
    "        yield samples[beg: beg + L]\n",
    "\n",
    "def label_transform(labels):\n",
    "    '''\n",
    "    레이블 정규화 및 one-hot벡터화 (더미화)\n",
    "    '''\n",
    "    nlabels = []\n",
    "    for label in labels:\n",
    "        if label == '_background_noise_':\n",
    "            nlabels.append('_silence')\n",
    "        elif label not in LABELS:\n",
    "            nlabels.append('_unknown')\n",
    "        else:\n",
    "            nlabels.append(label)\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(nlabels)\n",
    "    nlabels = encoder.transform(nlabels)\n",
    "    return nlabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Data & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Load labels, fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./input/train/audio/\n"
     ]
    }
   ],
   "source": [
    "labels, fnames = list_wavs_fname(TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chad/anaconda3/lib/python3.6/site-packages/scipy/io/wavfile.py:221: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  WavFileWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 2s, sys: 16.7 s, total: 1min 19s\n",
      "Wall time: 1min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y = []\n",
    "X = []\n",
    "\n",
    "for label, fname in zip(labels, fnames):\n",
    "    sample_rate, samples = wavfile.read(os.path.join(TRAIN_PATH, label, fname))\n",
    "    samples = pad_audio(samples)\n",
    "    if len(samples) > 16000:\n",
    "        n_samples = chop_audio(samples)\n",
    "    else: \n",
    "        n_samples = [samples]\n",
    "    for samples in n_samples:\n",
    "        resampled = signal.resample(samples, int(new_sample_rate / sample_rate * samples.shape[0]))\n",
    "        _, _, specgram = log_specgram(resampled, sample_rate=new_sample_rate)\n",
    "        y.append(label)\n",
    "        X.append(specgram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "X = X.reshape(tuple(list(X.shape) + [1])) # (64841, 99, 81, 1) 로 reshape\n",
    "y = to_categorical(label_transform(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Train Validation Set Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=1130) # 9:1로 train, valid 셋 나눔."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape = (99, 81, 1) # in order to fit into Conv2D layer, we need to reshape it.\n",
    "nclass = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 99, 81, 1)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 99, 81, 1)         4         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 98, 80, 8)         40        \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 97, 79, 8)         264       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 48, 39, 8)         0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 48, 39, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 46, 37, 16)        1168      \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 44, 35, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 22, 17, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 22, 17, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 20, 15, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 10, 7, 32)         0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 10, 7, 32)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2240)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               286848    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 12)                1548      \n",
      "=================================================================\n",
      "Total params: 314,368\n",
      "Trainable params: 313,854\n",
      "Non-trainable params: 514\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Modeling\n",
    "inp = Input(shape=input_shape)\n",
    "norm_inp = BatchNormalization()(inp)\n",
    "img_1 = Convolution2D(8, kernel_size=2, activation=activations.relu)(norm_inp)\n",
    "img_1 = Convolution2D(8, kernel_size=2, activation=activations.relu)(img_1)\n",
    "img_1 = MaxPooling2D(pool_size=(2, 2))(img_1)\n",
    "img_1 = Dropout(rate=0.2)(img_1)\n",
    "img_1 = Convolution2D(16, kernel_size=3, activation=activations.relu)(img_1)\n",
    "img_1 = Convolution2D(16, kernel_size=3, activation=activations.relu)(img_1)\n",
    "img_1 = MaxPooling2D(pool_size=(2, 2))(img_1)\n",
    "img_1 = Dropout(rate=0.2)(img_1)\n",
    "img_1 = Convolution2D(32, kernel_size=3, activation=activations.relu)(img_1)\n",
    "img_1 = MaxPooling2D(pool_size=(2, 2))(img_1)\n",
    "img_1 = Dropout(rate=0.2)(img_1)\n",
    "img_1 = Flatten()(img_1)\n",
    "\n",
    "\n",
    "dense_1 = BatchNormalization()(Dense(128, activation=activations.relu)(img_1))\n",
    "dense_1 = BatchNormalization()(Dense(128, activation=activations.relu)(dense_1))\n",
    "dense_1 = Dense(nclass, activation=activations.softmax)(dense_1)\n",
    "\n",
    "# dense_1 = BatchNormalization()(Dense(512, activation=activations.relu)(img_1))\n",
    "# dense_1 = Dropout(rate=0.2)(dense_1)\n",
    "# dense_1 = Dense(512, activation=activations.relu)(dense_1)\n",
    "# dense_1 = Dropout(rate=0.2)(dense_1)\n",
    "# dense_1 = Dense(128, activation=activations.relu)(dense_1)\n",
    "# dense_1 = Dense(nclass, activation=activations.softmax)(dense_1)\n",
    "\n",
    "model = models.Model(inputs=inp, outputs=dense_1)\n",
    "opt = optimizers.Adam(lr=0.001)\n",
    "\n",
    "model.compile(optimizer=opt, loss=losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 네트워크 시각화\n",
    "# plot_model(model, to_file='output/model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 51872 samples, validate on 12969 samples\n",
      "Epoch 1/20\n",
      "51872/51872 [==============================] - 209s - loss: 2.2166 - acc: 0.3566 - val_loss: 1.8523 - val_acc: 0.6390\n",
      "Epoch 2/20\n",
      "51872/51872 [==============================] - 211s - loss: 1.3818 - acc: 0.6375 - val_loss: 1.3336 - val_acc: 0.6377\n",
      "Epoch 3/20\n",
      "51872/51872 [==============================] - 222s - loss: 0.8784 - acc: 0.7459 - val_loss: 1.2161 - val_acc: 0.6382\n",
      "Epoch 4/20\n",
      "51872/51872 [==============================] - 232s - loss: 0.6411 - acc: 0.8066 - val_loss: 1.0710 - val_acc: 0.6436\n",
      "Epoch 5/20\n",
      "51872/51872 [==============================] - 234s - loss: 0.5159 - acc: 0.8398 - val_loss: 0.9833 - val_acc: 0.6469\n",
      "Epoch 6/20\n",
      "51872/51872 [==============================] - 238s - loss: 0.4339 - acc: 0.8647 - val_loss: 0.7566 - val_acc: 0.7021\n",
      "Epoch 7/20\n",
      "51872/51872 [==============================] - 231s - loss: 0.3716 - acc: 0.8829 - val_loss: 0.6427 - val_acc: 0.7488\n",
      "Epoch 8/20\n",
      "51872/51872 [==============================] - 244s - loss: 0.3345 - acc: 0.8945 - val_loss: 0.4659 - val_acc: 0.8333\n",
      "Epoch 9/20\n",
      "51872/51872 [==============================] - 244s - loss: 0.3009 - acc: 0.9050 - val_loss: 0.4135 - val_acc: 0.8592\n",
      "Epoch 10/20\n",
      "51872/51872 [==============================] - 253s - loss: 0.2789 - acc: 0.9094 - val_loss: 0.3365 - val_acc: 0.8918\n",
      "Epoch 11/20\n",
      "51872/51872 [==============================] - 239s - loss: 0.2554 - acc: 0.9184 - val_loss: 0.2844 - val_acc: 0.9134\n",
      "Epoch 12/20\n",
      "51872/51872 [==============================] - 216s - loss: 0.2340 - acc: 0.9250 - val_loss: 0.2731 - val_acc: 0.9148\n",
      "Epoch 13/20\n",
      "51872/51872 [==============================] - 224s - loss: 0.2191 - acc: 0.9301 - val_loss: 0.2491 - val_acc: 0.9235\n",
      "Epoch 14/20\n",
      "51872/51872 [==============================] - 234s - loss: 0.2039 - acc: 0.9352 - val_loss: 0.2293 - val_acc: 0.9300\n",
      "Epoch 15/20\n",
      "51872/51872 [==============================] - 220s - loss: 0.1935 - acc: 0.9375 - val_loss: 0.2320 - val_acc: 0.9294\n",
      "Epoch 16/20\n",
      "51872/51872 [==============================] - 222s - loss: 0.1837 - acc: 0.9409 - val_loss: 0.2288 - val_acc: 0.9308\n",
      "Epoch 17/20\n",
      "51872/51872 [==============================] - 216s - loss: 0.1713 - acc: 0.9451 - val_loss: 0.2123 - val_acc: 0.9345\n",
      "Epoch 18/20\n",
      "51872/51872 [==============================] - 209s - loss: 0.1590 - acc: 0.9497 - val_loss: 0.2175 - val_acc: 0.9359\n",
      "Epoch 19/20\n",
      "51872/51872 [==============================] - 206s - loss: 0.1514 - acc: 0.9507 - val_loss: 0.2034 - val_acc: 0.9382\n",
      "Epoch 20/20\n",
      "51872/51872 [==============================] - 219s - loss: 0.1453 - acc: 0.9534 - val_loss: 0.2080 - val_acc: 0.9360\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19e20df28>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=1024, validation_data=(X_valid, y_valid), epochs=20, shuffle=True, verbose=1,)\n",
    "# model.fit(X, y, batch_size=1024, epochs=100, shuffle=True, verbose=1,)\n",
    "# model.save(os.path.join(OUTPUT_PATH, 'cnn_custom_epoch100.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12969/12969 [==============================] - 19s    \n"
     ]
    }
   ],
   "source": [
    "preds_proba = model.predict(X_valid, batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 정확도 : 0.93600\n",
      "\n",
      " -------------------------- \n",
      "\n",
      "preds     _silence  _unknown  down   go  left   no  off   on  right  stop  \\\n",
      "actuals                                                                     \n",
      "_silence        16         6     0    0     0    0    0    0      0     3   \n",
      "_unknown         2      8081    39   24    14   19   14   25     10    15   \n",
      "down             0        34   411    4     0   11    0    0      0     3   \n",
      "go               0        48    32  334     0   30    3    2      0     6   \n",
      "left             0        44     0    0   412    0    1    0      1     1   \n",
      "no               0        39    11    8     0  390    1    0      0     1   \n",
      "off              0        32     0    0     0    0  438   14      0     4   \n",
      "on               0        44     0    0     0    0    6  412      0     0   \n",
      "right            0        62     1    1     7    0    0    1    369     0   \n",
      "stop             0        37     2    0     0    0    4    0      0   439   \n",
      "up               0        26     0    1     0    1   18    1      0    12   \n",
      "yes              0        31     2    0     5    2    0    0      0     0   \n",
      "\n",
      "preds      up  yes  \n",
      "actuals             \n",
      "_silence    1    0  \n",
      "_unknown   19    7  \n",
      "down        0    0  \n",
      "go          1    0  \n",
      "left        6    5  \n",
      "no          2    2  \n",
      "off        17    0  \n",
      "on          1    0  \n",
      "right       0    0  \n",
      "stop        4    0  \n",
      "up        420    0  \n",
      "yes         0  417  \n",
      "\n",
      " -------------------------- \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   _silence       0.89      0.62      0.73        26\n",
      "   _unknown       0.95      0.98      0.96      8269\n",
      "       down       0.83      0.89      0.86       463\n",
      "         go       0.90      0.73      0.81       456\n",
      "       left       0.94      0.88      0.91       470\n",
      "         no       0.86      0.86      0.86       454\n",
      "        off       0.90      0.87      0.88       505\n",
      "         on       0.91      0.89      0.90       463\n",
      "      right       0.97      0.84      0.90       441\n",
      "       stop       0.91      0.90      0.91       486\n",
      "         up       0.89      0.88      0.88       479\n",
      "        yes       0.97      0.91      0.94       457\n",
      "\n",
      "avg / total       0.94      0.94      0.94     12969\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = [LABELS[i] for i in np.argmax(preds_proba, axis=1)]\n",
    "actuals = [LABELS[i] for i in np.argmax(y_valid, axis=1)]\n",
    "print('* 정확도 : %.5f' % (np.sum(np.array(actuals) == np.array(preds)) / float(len(actuals))))\n",
    "preds = pd.Categorical(preds, categories=LABELS)\n",
    "actuals = pd.Categorical(actuals, categories=LABELS)\n",
    "print('\\n -------------------------- \\n')\n",
    "print(pd.crosstab(actuals, preds, rownames=['actuals'], colnames=['preds']))\n",
    "print('\\n -------------------------- \\n')\n",
    "print(classification_report(actuals, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 정확도 : 0.90166\n",
      "\n",
      " -------------------------- \n",
      "\n",
      "preds     _silence  _unknown  down   go  left   no  off   on  right  stop  \\\n",
      "actuals                                                                     \n",
      "_silence        12        23     0    0     0    0    0    0      0     0   \n",
      "_unknown         0     11922    32   28    16   16   12   45     96    58   \n",
      "down             1       120   512    7     0   23    0    1      0    17   \n",
      "go               0       144    30  412     0   65    0    0      1    11   \n",
      "left             0        92     0    0   547    0    1    0      8     0   \n",
      "no               0        97    24   18     0  553    3    0      0     6   \n",
      "off              0        53     0    1     0    0  547   11      0     2   \n",
      "on               0       127     0    1     0    0   17  544      0     1   \n",
      "right            0        67     0    0     4    0    0    2    615     0   \n",
      "stop             0        46     1    0     0    0    1    0      0   602   \n",
      "up               0        36     0    0     1    0    4    0      0     7   \n",
      "yes              0        72     1    0     6    2    0    0      0     0   \n",
      "\n",
      "preds      up  yes  \n",
      "actuals             \n",
      "_silence    1    0  \n",
      "_unknown  145   10  \n",
      "down        5    1  \n",
      "go         16    1  \n",
      "left       22   10  \n",
      "no          4    5  \n",
      "off       140    0  \n",
      "on         19    0  \n",
      "right       2    0  \n",
      "stop       72    0  \n",
      "up        666    0  \n",
      "yes         2  608  \n",
      "\n",
      " -------------------------- \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   _silence       0.92      0.33      0.49        36\n",
      "   _unknown       0.93      0.96      0.95     12380\n",
      "       down       0.85      0.75      0.80       687\n",
      "         go       0.88      0.61      0.72       680\n",
      "       left       0.95      0.80      0.87       680\n",
      "         no       0.84      0.78      0.81       710\n",
      "        off       0.94      0.73      0.82       754\n",
      "         on       0.90      0.77      0.83       709\n",
      "      right       0.85      0.89      0.87       690\n",
      "       stop       0.86      0.83      0.84       722\n",
      "         up       0.61      0.93      0.74       714\n",
      "        yes       0.96      0.88      0.92       691\n",
      "\n",
      "avg / total       0.91      0.90      0.90     19453\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = [LABELS[i] for i in np.argmax(preds_proba, axis=1)]\n",
    "actuals = [LABELS[i] for i in np.argmax(y_valid, axis=1)]\n",
    "print('* 정확도 : %.5f' % (np.sum(np.array(actuals) == np.array(preds)) / float(len(actuals))))\n",
    "preds = pd.Categorical(preds, categories=LABELS)\n",
    "actuals = pd.Categorical(actuals, categories=LABELS)\n",
    "print('\\n -------------------------- \\n')\n",
    "print(pd.crosstab(actuals, preds, rownames=['actuals'], colnames=['preds']))\n",
    "print('\\n -------------------------- \\n')\n",
    "print(classification_report(actuals, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals = [LABELS[i] for i in np.argmax(y, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_unknown    41039\n",
       "stop         2380\n",
       "yes          2377\n",
       "up           2375\n",
       "no           2375\n",
       "go           2372\n",
       "on           2367\n",
       "right        2367\n",
       "down         2359\n",
       "off          2357\n",
       "left         2353\n",
       "_silence      120\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(actuals).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
