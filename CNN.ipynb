{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.fftpack import fft\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "from glob import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "import gc\n",
    "from scipy.io import wavfile\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import optimizers, losses, activations, models\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.layers import Convolution2D, Dense, Input, Flatten, Dropout, MaxPooling2D, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_sample_rate = 8000\n",
    "\n",
    "LABELS = ['_silence', '_unknown', 'down', 'go', 'left', 'no', 'off', 'on', 'right', 'stop', 'up', 'yes']\n",
    "TRAIN_PATH = './input/train/audio/'\n",
    "TEST_PATH = './input/test/audio/'\n",
    "OUTPUT_PATH = './output/'\n",
    "MODEL_NAME = 'cnn_aug_300_no_cw_2.h5'\n",
    "\n",
    "class_weight = {0: 13.0,\n",
    " 1: 1.0,\n",
    " 2: 9.0,\n",
    " 3: 9.0,\n",
    " 4: 9.0,\n",
    " 5: 9.0,\n",
    " 6: 9.0,\n",
    " 7: 9.0,\n",
    " 8: 9.0,\n",
    " 9: 9.0,\n",
    " 10: 9.0,\n",
    " 11: 9.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 원본 클래스 비율\n",
    "# {0: 1200,\n",
    "#  1: 41039,\n",
    "#  2: 2359,\n",
    "#  3: 2372,\n",
    "#  4: 2353,\n",
    "#  5: 2375,\n",
    "#  6: 2357,\n",
    "#  7: 2367,\n",
    "#  8: 2367,\n",
    "#  9: 2380,\n",
    "#  10: 2375,\n",
    "#  11: 2377}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## custom_fft and log_specgram functions written by DavidS.\n",
    "def custom_fft(y, fs):\n",
    "    T = 1.0 / fs\n",
    "    N = y.shape[0]\n",
    "    yf = fft(y)\n",
    "    xf = np.linspace(0.0, 1.0/(2.0*T), N//2)\n",
    "    # FFT 는 대칭(simmetrical)이므로 반쪽만 얻음.\n",
    "    # FFT 는 복소수이므로 실수값만 취하기 위해 abs()\n",
    "    vals = 2.0/N * np.abs(yf[0:N//2])\n",
    "    return xf, vals\n",
    "\n",
    "def log_specgram(audio, sample_rate, window_size=20, step_size=10, eps=1e-10):\n",
    "    nperseg = int(round(window_size * sample_rate / 1e3))\n",
    "    noverlap = int(round(step_size * sample_rate / 1e3))\n",
    "    freqs, times, spec = signal.spectrogram(audio,\n",
    "                                    fs=sample_rate,\n",
    "                                    window='hann',\n",
    "                                    nperseg=nperseg,\n",
    "                                    noverlap=noverlap,\n",
    "                                    detrend=False)\n",
    "    return freqs, times, np.log(spec.T.astype(np.float32) + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## utility function to grab all wav files inside train data folder.\n",
    "def list_wavs_fname(dirpath, ext='wav'):\n",
    "    print(dirpath)\n",
    "    fpaths = glob(os.path.join(dirpath, r'*/*' + ext))\n",
    "    pat = r'.+/(\\w+)/\\w+\\.' + ext + '$'\n",
    "    labels = []\n",
    "    for fpath in fpaths:\n",
    "        r = re.match(pat, fpath)\n",
    "        if r:\n",
    "            labels.append(r.group(1))\n",
    "    pat = r'.+/(\\w+\\.' + ext + ')$'\n",
    "    fnames = []\n",
    "    for fpath in fpaths:\n",
    "        r = re.match(pat, fpath)\n",
    "        if r:\n",
    "            fnames.append(r.group(1))\n",
    "    return labels, fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pad_audio(samples, L=16000):\n",
    "    '''\n",
    "    pad audios that are less than 16000(1 second) with 0s to make them all have the same length.\n",
    "    '''\n",
    "    if len(samples) >= L: \n",
    "        return samples\n",
    "    else: \n",
    "        return np.pad(samples, pad_width=(L - len(samples), 0), mode='constant', constant_values=(0, 0)) \n",
    "        # sample 앞뒤로 constant_values[0]과 constant_values[1]을 각각 pad_width 갯수 만큼 패딩\n",
    "        # 총길이는 len(samples) + 2*pad_width\n",
    "\n",
    "# def chop_audio(samples, L=16000, num=200):\n",
    "#     '''\n",
    "#     chop audios that are larger than 16000(eg. wav files in background noises folder) to 16000 in length.\n",
    "#     create several chunks out of one large wav files given the parameter 'num'.\n",
    "#     '''\n",
    "#     for i in range(num):\n",
    "#         beg = np.random.randint(0, len(samples) - L)\n",
    "#         yield samples[beg: beg + L]\n",
    "\n",
    "def label_transform(labels):\n",
    "    '''\n",
    "    레이블 정규화 및 one-hot벡터화 (더미화)\n",
    "    '''\n",
    "    nlabels = []\n",
    "    for label in labels:\n",
    "        if label == '_background_noise_':\n",
    "            nlabels.append('_silence')\n",
    "        elif label not in LABELS:\n",
    "            nlabels.append('_unknown')\n",
    "        else:\n",
    "            nlabels.append(label)\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(nlabels)\n",
    "    nlabels = encoder.transform(nlabels)\n",
    "    return nlabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Data & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Load labels, fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./input/train/audio/\n"
     ]
    }
   ],
   "source": [
    "labels, fnames = list_wavs_fname(TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sample_rate, samples = wavfile.read(os.path.join(TRAIN_PATH, labels[0], fnames[0]))\n",
    "# len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 31s, sys: 2.54 s, total: 1min 33s\n",
      "Wall time: 1min 32s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chi/anaconda3/lib/python3.5/site-packages/scipy/io/wavfile.py:273: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  WavFileWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y = []\n",
    "X = []\n",
    "for i, (label, fname) in enumerate(zip(labels, fnames)):\n",
    "    sample_rate, samples = wavfile.read(os.path.join(TRAIN_PATH, label, fname))\n",
    "    if len(samples) > 16000:\n",
    "        pass\n",
    "    else:\n",
    "        samples = pad_audio(samples)\n",
    "        resampled = signal.resample(samples, int(new_sample_rate / sample_rate * samples.shape[0]))\n",
    "        _, _, specgram = log_specgram(resampled, sample_rate=new_sample_rate)\n",
    "        y.append(label)\n",
    "        X.append(specgram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "X = X.reshape(tuple(list(X.shape) + [1])) # (64841, 99, 81, 1) 로 reshape\n",
    "y = to_categorical(label_transform(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Train Validation Set Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.05, random_state=1130) # 9:1로 train, valid 셋 나눔.\n",
    "del X, y\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = load_model(os.path.join(OUTPUT_PATH, MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape = (99, 81, 1) # in order to fit into Conv2D layer, we need to reshape it.\n",
    "nclass = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 99, 81, 1)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 99, 81, 1)         4         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 99, 81, 8)         40        \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 99, 81, 8)         264       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 49, 40, 8)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 49, 40, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 49, 40, 16)        528       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 49, 40, 16)        1040      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 24, 20, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 24, 20, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 24, 20, 16)        2320      \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 24, 20, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 10, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 12, 10, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 12, 10, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 6, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 6, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 960)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 960)               3840      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               492032    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 12)                780       \n",
      "=================================================================\n",
      "Total params: 1,107,040\n",
      "Trainable params: 1,105,118\n",
      "Non-trainable params: 1,922\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Modeling\n",
    "inp = Input(shape=input_shape)\n",
    "norm_inp = BatchNormalization()(inp)\n",
    "img_1 = Convolution2D(8, kernel_size=2, activation=activations.relu, padding='same')(norm_inp)\n",
    "img_1 = Convolution2D(8, kernel_size=2, activation=activations.relu, padding='same')(img_1)\n",
    "img_1 = MaxPooling2D(pool_size=(2, 2))(img_1)\n",
    "img_1 = Dropout(rate=0.2)(img_1)\n",
    "img_1 = Convolution2D(16, kernel_size=2, activation=activations.relu, padding='same')(img_1)\n",
    "img_1 = Convolution2D(16, kernel_size=2, activation=activations.relu, padding='same')(img_1)\n",
    "img_1 = MaxPooling2D(pool_size=(2, 2))(img_1)\n",
    "img_1 = Dropout(rate=0.2)(img_1)\n",
    "img_1 = Convolution2D(16, kernel_size=3, activation=activations.relu, padding='same')(img_1)\n",
    "img_1 = Convolution2D(16, kernel_size=3, activation=activations.relu, padding='same')(img_1)\n",
    "img_1 = MaxPooling2D(pool_size=(2, 2))(img_1)\n",
    "img_1 = Dropout(rate=0.2)(img_1)\n",
    "img_1 = Convolution2D(32, kernel_size=3, activation=activations.relu, padding='same')(img_1)\n",
    "img_1 = MaxPooling2D(pool_size=(2, 2))(img_1)\n",
    "img_1 = Dropout(rate=0.2)(img_1)\n",
    "img_1 = Flatten()(img_1)\n",
    "\n",
    "dense_1 = BatchNormalization()(img_1)\n",
    "dense_1 = Dense(512, activation=activations.relu)(dense_1)\n",
    "dense_1 = Dropout(rate=0.2)(dense_1)\n",
    "dense_1 = Dense(512, activation=activations.relu)(dense_1)\n",
    "dense_1 = Dropout(rate=0.2)(dense_1)\n",
    "dense_1 = Dense(512, activation=activations.relu)(dense_1)\n",
    "dense_1 = Dropout(rate=0.2)(dense_1)\n",
    "dense_1 = Dense(128, activation=activations.relu)(dense_1)\n",
    "dense_1 = Dropout(rate=0.2)(dense_1)\n",
    "dense_1 = Dense(64, activation=activations.relu)(dense_1)\n",
    "dense_1 = Dense(nclass, activation=activations.softmax)(dense_1)\n",
    "\n",
    "model = models.Model(inputs=inp, outputs=dense_1)\n",
    "opt = optimizers.Adam(lr=0.001)\n",
    "\n",
    "model.compile(optimizer=opt, loss=losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 네트워크 시각화\n",
    "# plot_model(model, to_file='output/model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 93216 samples, validate on 4907 samples\n",
      "Epoch 1/300\n",
      "93216/93216 [==============================] - 28s - loss: 1.6157 - acc: 0.6159 - val_loss: 2.3386 - val_acc: 0.6309\n",
      "Epoch 2/300\n",
      "93216/93216 [==============================] - 27s - loss: 1.3985 - acc: 0.6262 - val_loss: 2.1232 - val_acc: 0.6328\n",
      "Epoch 3/300\n",
      "93216/93216 [==============================] - 27s - loss: 1.0761 - acc: 0.6557 - val_loss: 1.9151 - val_acc: 0.7312\n",
      "Epoch 4/300\n",
      "93216/93216 [==============================] - 27s - loss: 0.7871 - acc: 0.7378 - val_loss: 1.6688 - val_acc: 0.7976\n",
      "Epoch 5/300\n",
      "93216/93216 [==============================] - 27s - loss: 0.6236 - acc: 0.7934 - val_loss: 1.4626 - val_acc: 0.8237\n",
      "Epoch 6/300\n",
      "93216/93216 [==============================] - 27s - loss: 0.5288 - acc: 0.8270 - val_loss: 1.2106 - val_acc: 0.8592\n",
      "Epoch 7/300\n",
      "93216/93216 [==============================] - 27s - loss: 0.4650 - acc: 0.8487 - val_loss: 0.9987 - val_acc: 0.8433\n",
      "Epoch 8/300\n",
      "93216/93216 [==============================] - 27s - loss: 0.4192 - acc: 0.8644 - val_loss: 0.7737 - val_acc: 0.8891\n",
      "Epoch 9/300\n",
      "93216/93216 [==============================] - 27s - loss: 0.3890 - acc: 0.8732 - val_loss: 0.6281 - val_acc: 0.8948\n",
      "Epoch 10/300\n",
      "93216/93216 [==============================] - 27s - loss: 0.3570 - acc: 0.8855 - val_loss: 0.4476 - val_acc: 0.9185\n",
      "Epoch 11/300\n",
      "93216/93216 [==============================] - 27s - loss: 0.3313 - acc: 0.8935 - val_loss: 0.3169 - val_acc: 0.9336\n",
      "Epoch 12/300\n",
      "93216/93216 [==============================] - 27s - loss: 0.3130 - acc: 0.8989 - val_loss: 0.2987 - val_acc: 0.9293\n",
      "Epoch 13/300\n",
      "93216/93216 [==============================] - 27s - loss: 0.2905 - acc: 0.9069 - val_loss: 0.2838 - val_acc: 0.9228\n",
      "Epoch 14/300\n",
      "93216/93216 [==============================] - 27s - loss: 0.2757 - acc: 0.9112 - val_loss: 0.2006 - val_acc: 0.9436\n",
      "Epoch 15/300\n",
      "93216/93216 [==============================] - 27s - loss: 0.2610 - acc: 0.9159 - val_loss: 0.1936 - val_acc: 0.9446\n",
      "Epoch 16/300\n",
      "93216/93216 [==============================] - 27s - loss: 0.2472 - acc: 0.9210 - val_loss: 0.1779 - val_acc: 0.9474\n",
      "Epoch 17/300\n",
      "93216/93216 [==============================] - 27s - loss: 0.2355 - acc: 0.9241 - val_loss: 0.1627 - val_acc: 0.9550\n",
      "Epoch 18/300\n",
      "93216/93216 [==============================] - 27s - loss: 0.2344 - acc: 0.9249 - val_loss: 0.1709 - val_acc: 0.9513\n",
      "Epoch 19/300\n",
      "93216/93216 [==============================] - 27s - loss: 0.2211 - acc: 0.9287 - val_loss: 0.1421 - val_acc: 0.9572\n",
      "Epoch 20/300\n",
      "93216/93216 [==============================] - 27s - loss: 0.2137 - acc: 0.9326 - val_loss: 0.1397 - val_acc: 0.9564\n",
      "Epoch 21/300\n",
      "93216/93216 [==============================] - 27s - loss: 0.2050 - acc: 0.9341 - val_loss: 0.1328 - val_acc: 0.9596\n",
      "Epoch 22/300\n",
      "93216/93216 [==============================] - 27s - loss: 0.1986 - acc: 0.9364 - val_loss: 0.1352 - val_acc: 0.9590\n",
      "Epoch 23/300\n",
      "93216/93216 [==============================] - 27s - loss: 0.1896 - acc: 0.9395 - val_loss: 0.1176 - val_acc: 0.9654\n",
      "Epoch 24/300\n",
      "93216/93216 [==============================] - 27s - loss: 0.1894 - acc: 0.9390 - val_loss: 0.1193 - val_acc: 0.9647\n",
      "Epoch 25/300\n",
      "93216/93216 [==============================] - 27s - loss: 0.1797 - acc: 0.9428 - val_loss: 0.1117 - val_acc: 0.9658\n",
      "Epoch 26/300\n",
      "93216/93216 [==============================] - 27s - loss: 0.1778 - acc: 0.9433 - val_loss: 0.1180 - val_acc: 0.9625\n",
      "Epoch 27/300\n",
      "93216/93216 [==============================] - 27s - loss: 0.1689 - acc: 0.9455 - val_loss: 0.1040 - val_acc: 0.9684\n",
      "Epoch 28/300\n",
      "93216/93216 [==============================] - 27s - loss: 0.1680 - acc: 0.9455 - val_loss: 0.1165 - val_acc: 0.9656\n",
      "Epoch 29/300\n",
      "93216/93216 [==============================] - 27s - loss: 0.1632 - acc: 0.9473 - val_loss: 0.1081 - val_acc: 0.9656\n",
      "Epoch 30/300\n",
      "93216/93216 [==============================] - 27s - loss: 0.1594 - acc: 0.9490 - val_loss: 0.1125 - val_acc: 0.9674\n",
      "Epoch 31/300\n",
      "93216/93216 [==============================] - 27s - loss: 0.1532 - acc: 0.9499 - val_loss: 0.0965 - val_acc: 0.9733\n",
      "Epoch 32/300\n",
      "61440/93216 [==================>...........] - ETA: 9s - loss: 0.1524 - acc: 0.9506"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# model.fit(X_train, y_train, batch_size=2048, validation_data=(X_valid, y_valid), \\\n",
    "#           class_weight=class_weight, epochs=300, shuffle=True, verbose=1)\n",
    "model.fit(X_train, y_train, batch_size=2048, validation_data=(X_valid, y_valid), \\\n",
    "          epochs=300, shuffle=True, verbose=1)\n",
    "model.save(os.path.join(OUTPUT_PATH, MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 93216 samples, validate on 4907 samples\n",
      "Epoch 1/300\n",
      "93216/93216 [==============================] - 27s - loss: 0.5189 - acc: 0.9623 - val_loss: 0.1099 - val_acc: 0.9719\n",
      "Epoch 2/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.5298 - acc: 0.9568 - val_loss: 0.0927 - val_acc: 0.9733\n",
      "Epoch 3/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.4385 - acc: 0.9633 - val_loss: 0.0993 - val_acc: 0.9690\n",
      "Epoch 4/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.3931 - acc: 0.9664 - val_loss: 0.0910 - val_acc: 0.9753\n",
      "Epoch 5/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.3670 - acc: 0.9670 - val_loss: 0.1141 - val_acc: 0.9660\n",
      "Epoch 6/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.3437 - acc: 0.9692 - val_loss: 0.1004 - val_acc: 0.9711\n",
      "Epoch 7/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.3217 - acc: 0.9699 - val_loss: 0.0905 - val_acc: 0.9737\n",
      "Epoch 8/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.3098 - acc: 0.9717 - val_loss: 0.1119 - val_acc: 0.9688\n",
      "Epoch 9/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.3126 - acc: 0.9706 - val_loss: 0.0890 - val_acc: 0.9747\n",
      "Epoch 10/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.2207 - acc: 0.9782 - val_loss: 0.0925 - val_acc: 0.9727\n",
      "Epoch 35/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.2123 - acc: 0.9786 - val_loss: 0.0898 - val_acc: 0.9751\n",
      "Epoch 36/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.2007 - acc: 0.9794 - val_loss: 0.0914 - val_acc: 0.9737\n",
      "Epoch 37/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.2084 - acc: 0.9789 - val_loss: 0.0892 - val_acc: 0.9743\n",
      "Epoch 38/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.2155 - acc: 0.9777 - val_loss: 0.0936 - val_acc: 0.9745\n",
      "Epoch 39/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.2180 - acc: 0.9779 - val_loss: 0.0970 - val_acc: 0.9713\n",
      "Epoch 40/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.2107 - acc: 0.9781 - val_loss: 0.0849 - val_acc: 0.9766\n",
      "Epoch 41/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1891 - acc: 0.9804 - val_loss: 0.0974 - val_acc: 0.9749\n",
      "Epoch 42/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1951 - acc: 0.9805 - val_loss: 0.0880 - val_acc: 0.9760\n",
      "Epoch 43/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.2029 - acc: 0.9800 - val_loss: 0.0802 - val_acc: 0.9776\n",
      "Epoch 44/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.2124 - acc: 0.9789 - val_loss: 0.0821 - val_acc: 0.9762\n",
      "Epoch 45/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1976 - acc: 0.9801 - val_loss: 0.0909 - val_acc: 0.9745\n",
      "Epoch 46/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.2002 - acc: 0.9796 - val_loss: 0.0831 - val_acc: 0.9753\n",
      "Epoch 47/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1904 - acc: 0.9806 - val_loss: 0.0991 - val_acc: 0.9731\n",
      "Epoch 48/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.2036 - acc: 0.9794 - val_loss: 0.0921 - val_acc: 0.9741\n",
      "Epoch 49/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1941 - acc: 0.9805 - val_loss: 0.1017 - val_acc: 0.9760\n",
      "Epoch 50/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1992 - acc: 0.9798 - val_loss: 0.0853 - val_acc: 0.9753\n",
      "Epoch 51/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1962 - acc: 0.9795 - val_loss: 0.0904 - val_acc: 0.9747\n",
      "Epoch 52/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1968 - acc: 0.9800 - val_loss: 0.0852 - val_acc: 0.9743\n",
      "Epoch 53/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.2010 - acc: 0.9798 - val_loss: 0.0959 - val_acc: 0.9719\n",
      "Epoch 54/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1985 - acc: 0.9798 - val_loss: 0.0904 - val_acc: 0.9753\n",
      "Epoch 55/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1935 - acc: 0.9794 - val_loss: 0.0804 - val_acc: 0.9780\n",
      "Epoch 56/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1869 - acc: 0.9810 - val_loss: 0.0971 - val_acc: 0.9741\n",
      "Epoch 57/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1821 - acc: 0.9807 - val_loss: 0.0931 - val_acc: 0.9751\n",
      "Epoch 58/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1971 - acc: 0.9800 - val_loss: 0.0846 - val_acc: 0.9760\n",
      "Epoch 59/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1846 - acc: 0.9806 - val_loss: 0.0883 - val_acc: 0.9751\n",
      "Epoch 60/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1818 - acc: 0.9819 - val_loss: 0.0953 - val_acc: 0.9745\n",
      "Epoch 61/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1798 - acc: 0.9807 - val_loss: 0.0913 - val_acc: 0.9747\n",
      "Epoch 62/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1780 - acc: 0.9816 - val_loss: 0.0878 - val_acc: 0.9762\n",
      "Epoch 63/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1880 - acc: 0.9808 - val_loss: 0.0900 - val_acc: 0.9764\n",
      "Epoch 64/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1902 - acc: 0.9804 - val_loss: 0.0836 - val_acc: 0.9755\n",
      "Epoch 65/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1918 - acc: 0.9815 - val_loss: 0.0860 - val_acc: 0.9753\n",
      "Epoch 66/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1763 - acc: 0.9820 - val_loss: 0.0837 - val_acc: 0.9766\n",
      "Epoch 67/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1829 - acc: 0.9817 - val_loss: 0.0982 - val_acc: 0.9725\n",
      "Epoch 68/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1840 - acc: 0.9807 - val_loss: 0.0881 - val_acc: 0.9753\n",
      "Epoch 69/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1919 - acc: 0.9807 - val_loss: 0.0840 - val_acc: 0.9760\n",
      "Epoch 70/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1878 - acc: 0.9811 - val_loss: 0.0859 - val_acc: 0.9768\n",
      "Epoch 71/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1828 - acc: 0.9811 - val_loss: 0.0838 - val_acc: 0.9766\n",
      "Epoch 72/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1751 - acc: 0.9813 - val_loss: 0.0921 - val_acc: 0.9729\n",
      "Epoch 73/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1841 - acc: 0.9809 - val_loss: 0.0833 - val_acc: 0.9762\n",
      "Epoch 74/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1871 - acc: 0.9808 - val_loss: 0.0940 - val_acc: 0.9739\n",
      "Epoch 75/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1803 - acc: 0.9805 - val_loss: 0.0893 - val_acc: 0.9762\n",
      "Epoch 76/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1828 - acc: 0.9811 - val_loss: 0.0784 - val_acc: 0.9780\n",
      "Epoch 77/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1848 - acc: 0.9807 - val_loss: 0.0793 - val_acc: 0.9796\n",
      "Epoch 78/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1794 - acc: 0.9816 - val_loss: 0.0844 - val_acc: 0.9780\n",
      "Epoch 79/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1847 - acc: 0.9810 - val_loss: 0.0851 - val_acc: 0.9768\n",
      "Epoch 80/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1994 - acc: 0.9802 - val_loss: 0.0948 - val_acc: 0.9731\n",
      "Epoch 81/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1761 - acc: 0.9818 - val_loss: 0.0843 - val_acc: 0.9747\n",
      "Epoch 82/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1817 - acc: 0.9824 - val_loss: 0.1005 - val_acc: 0.9721\n",
      "Epoch 83/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1877 - acc: 0.9810 - val_loss: 0.0820 - val_acc: 0.9786\n",
      "Epoch 84/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1809 - acc: 0.9804 - val_loss: 0.0836 - val_acc: 0.9766\n",
      "Epoch 85/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1816 - acc: 0.9810 - val_loss: 0.0753 - val_acc: 0.9780\n",
      "Epoch 86/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1655 - acc: 0.9816 - val_loss: 0.0827 - val_acc: 0.9770\n",
      "Epoch 87/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93216/93216 [==============================] - 26s - loss: 0.1912 - acc: 0.9805 - val_loss: 0.0792 - val_acc: 0.9766\n",
      "Epoch 88/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1749 - acc: 0.9804 - val_loss: 0.0868 - val_acc: 0.9739\n",
      "Epoch 89/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1738 - acc: 0.9816 - val_loss: 0.0834 - val_acc: 0.9792\n",
      "Epoch 90/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1837 - acc: 0.9816 - val_loss: 0.0775 - val_acc: 0.9792\n",
      "Epoch 91/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1761 - acc: 0.9820 - val_loss: 0.0793 - val_acc: 0.9782\n",
      "Epoch 92/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1744 - acc: 0.9824 - val_loss: 0.0825 - val_acc: 0.9772\n",
      "Epoch 93/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1691 - acc: 0.9821 - val_loss: 0.0816 - val_acc: 0.9788\n",
      "Epoch 94/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1802 - acc: 0.9809 - val_loss: 0.0812 - val_acc: 0.9776\n",
      "Epoch 95/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1731 - acc: 0.9815 - val_loss: 0.0809 - val_acc: 0.9784\n",
      "Epoch 96/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1630 - acc: 0.9820 - val_loss: 0.0827 - val_acc: 0.9772\n",
      "Epoch 97/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1621 - acc: 0.9837 - val_loss: 0.0880 - val_acc: 0.9766\n",
      "Epoch 98/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1745 - acc: 0.9818 - val_loss: 0.0817 - val_acc: 0.9774\n",
      "Epoch 99/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1730 - acc: 0.9820 - val_loss: 0.0928 - val_acc: 0.9737\n",
      "Epoch 100/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1729 - acc: 0.9819 - val_loss: 0.0809 - val_acc: 0.9780\n",
      "Epoch 101/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1787 - acc: 0.9815 - val_loss: 0.0840 - val_acc: 0.9757\n",
      "Epoch 102/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1736 - acc: 0.9818 - val_loss: 0.0881 - val_acc: 0.9764\n",
      "Epoch 103/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1698 - acc: 0.9827 - val_loss: 0.0790 - val_acc: 0.9788\n",
      "Epoch 104/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1695 - acc: 0.9817 - val_loss: 0.0876 - val_acc: 0.9770\n",
      "Epoch 105/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1840 - acc: 0.9820 - val_loss: 0.0829 - val_acc: 0.9760\n",
      "Epoch 106/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1713 - acc: 0.9821 - val_loss: 0.0855 - val_acc: 0.9784\n",
      "Epoch 107/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1829 - acc: 0.9815 - val_loss: 0.0835 - val_acc: 0.9755\n",
      "Epoch 108/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1790 - acc: 0.9809 - val_loss: 0.0904 - val_acc: 0.9757\n",
      "Epoch 109/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1681 - acc: 0.9818 - val_loss: 0.0814 - val_acc: 0.9776\n",
      "Epoch 110/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1708 - acc: 0.9825 - val_loss: 0.0856 - val_acc: 0.9764\n",
      "Epoch 111/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1602 - acc: 0.9821 - val_loss: 0.0839 - val_acc: 0.9764\n",
      "Epoch 112/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1655 - acc: 0.9822 - val_loss: 0.0913 - val_acc: 0.9755\n",
      "Epoch 113/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1696 - acc: 0.9819 - val_loss: 0.0937 - val_acc: 0.9755\n",
      "Epoch 114/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1613 - acc: 0.9830 - val_loss: 0.0932 - val_acc: 0.9741\n",
      "Epoch 115/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1790 - acc: 0.9812 - val_loss: 0.0794 - val_acc: 0.9776\n",
      "Epoch 116/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1594 - acc: 0.9831 - val_loss: 0.0851 - val_acc: 0.9757\n",
      "Epoch 117/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1740 - acc: 0.9816 - val_loss: 0.0841 - val_acc: 0.9776\n",
      "Epoch 118/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1696 - acc: 0.9825 - val_loss: 0.0787 - val_acc: 0.9780\n",
      "Epoch 119/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1739 - acc: 0.9819 - val_loss: 0.0861 - val_acc: 0.9762\n",
      "Epoch 120/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1742 - acc: 0.9823 - val_loss: 0.0929 - val_acc: 0.9729\n",
      "Epoch 121/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1500 - acc: 0.9840 - val_loss: 0.0759 - val_acc: 0.9780\n",
      "Epoch 122/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1685 - acc: 0.9824 - val_loss: 0.0826 - val_acc: 0.9770\n",
      "Epoch 123/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1671 - acc: 0.9821 - val_loss: 0.0946 - val_acc: 0.9743\n",
      "Epoch 124/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1663 - acc: 0.9812 - val_loss: 0.0892 - val_acc: 0.9764\n",
      "Epoch 125/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1623 - acc: 0.9825 - val_loss: 0.0938 - val_acc: 0.9762\n",
      "Epoch 126/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1747 - acc: 0.9811 - val_loss: 0.0908 - val_acc: 0.9747\n",
      "Epoch 127/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1581 - acc: 0.9831 - val_loss: 0.0955 - val_acc: 0.9749\n",
      "Epoch 128/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1654 - acc: 0.9826 - val_loss: 0.0892 - val_acc: 0.9768\n",
      "Epoch 129/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1659 - acc: 0.9819 - val_loss: 0.0978 - val_acc: 0.9753\n",
      "Epoch 130/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1647 - acc: 0.9825 - val_loss: 0.0905 - val_acc: 0.9749\n",
      "Epoch 131/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1699 - acc: 0.9815 - val_loss: 0.0864 - val_acc: 0.9755\n",
      "Epoch 132/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1682 - acc: 0.9829 - val_loss: 0.0858 - val_acc: 0.9749\n",
      "Epoch 133/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1702 - acc: 0.9818 - val_loss: 0.0757 - val_acc: 0.9794\n",
      "Epoch 134/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1632 - acc: 0.9821 - val_loss: 0.0882 - val_acc: 0.9757\n",
      "Epoch 135/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1604 - acc: 0.9825 - val_loss: 0.0918 - val_acc: 0.9757\n",
      "Epoch 136/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1679 - acc: 0.9815 - val_loss: 0.0880 - val_acc: 0.9751\n",
      "Epoch 137/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1787 - acc: 0.9808 - val_loss: 0.0840 - val_acc: 0.9755\n",
      "Epoch 138/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1650 - acc: 0.9826 - val_loss: 0.0856 - val_acc: 0.9776\n",
      "Epoch 139/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1576 - acc: 0.9824 - val_loss: 0.0861 - val_acc: 0.9770\n",
      "Epoch 140/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1677 - acc: 0.9823 - val_loss: 0.0809 - val_acc: 0.9786\n",
      "Epoch 141/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1539 - acc: 0.9835 - val_loss: 0.0806 - val_acc: 0.9782\n",
      "Epoch 142/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1684 - acc: 0.9833 - val_loss: 0.0849 - val_acc: 0.9780\n",
      "Epoch 143/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1625 - acc: 0.9825 - val_loss: 0.0860 - val_acc: 0.9792\n",
      "Epoch 144/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1680 - acc: 0.9825 - val_loss: 0.0868 - val_acc: 0.9745\n",
      "Epoch 145/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1646 - acc: 0.9827 - val_loss: 0.0810 - val_acc: 0.9778\n",
      "Epoch 146/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1503 - acc: 0.9839 - val_loss: 0.0827 - val_acc: 0.9774\n",
      "Epoch 147/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1628 - acc: 0.9827 - val_loss: 0.0786 - val_acc: 0.9770\n",
      "Epoch 148/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1626 - acc: 0.9823 - val_loss: 0.0814 - val_acc: 0.9764\n",
      "Epoch 149/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93216/93216 [==============================] - 26s - loss: 0.1493 - acc: 0.9830 - val_loss: 0.0868 - val_acc: 0.9778\n",
      "Epoch 150/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1601 - acc: 0.9832 - val_loss: 0.0860 - val_acc: 0.9755\n",
      "Epoch 151/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1552 - acc: 0.9831 - val_loss: 0.0852 - val_acc: 0.9772\n",
      "Epoch 152/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1703 - acc: 0.9824 - val_loss: 0.0809 - val_acc: 0.9790\n",
      "Epoch 153/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1689 - acc: 0.9830 - val_loss: 0.0865 - val_acc: 0.9766\n",
      "Epoch 154/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1600 - acc: 0.9838 - val_loss: 0.0911 - val_acc: 0.9766\n",
      "Epoch 155/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1650 - acc: 0.9824 - val_loss: 0.0936 - val_acc: 0.9749\n",
      "Epoch 156/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1537 - acc: 0.9832 - val_loss: 0.0862 - val_acc: 0.9764\n",
      "Epoch 157/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1675 - acc: 0.9820 - val_loss: 0.0853 - val_acc: 0.9766\n",
      "Epoch 158/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1613 - acc: 0.9827 - val_loss: 0.0907 - val_acc: 0.9766\n",
      "Epoch 159/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1635 - acc: 0.9828 - val_loss: 0.0848 - val_acc: 0.9780\n",
      "Epoch 160/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1596 - acc: 0.9835 - val_loss: 0.0923 - val_acc: 0.9747\n",
      "Epoch 161/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1563 - acc: 0.9826 - val_loss: 0.0877 - val_acc: 0.9766\n",
      "Epoch 162/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1621 - acc: 0.9832 - val_loss: 0.0831 - val_acc: 0.9772\n",
      "Epoch 163/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1554 - acc: 0.9831 - val_loss: 0.0864 - val_acc: 0.9776\n",
      "Epoch 164/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1527 - acc: 0.9834 - val_loss: 0.0860 - val_acc: 0.9764\n",
      "Epoch 165/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1586 - acc: 0.9830 - val_loss: 0.0903 - val_acc: 0.9762\n",
      "Epoch 166/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1528 - acc: 0.9834 - val_loss: 0.0890 - val_acc: 0.9780\n",
      "Epoch 167/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1492 - acc: 0.9832 - val_loss: 0.0852 - val_acc: 0.9782\n",
      "Epoch 168/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1568 - acc: 0.9826 - val_loss: 0.0844 - val_acc: 0.9788\n",
      "Epoch 169/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1566 - acc: 0.9830 - val_loss: 0.0830 - val_acc: 0.9788\n",
      "Epoch 170/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1629 - acc: 0.9831 - val_loss: 0.0798 - val_acc: 0.9766\n",
      "Epoch 171/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1686 - acc: 0.9832 - val_loss: 0.0892 - val_acc: 0.9747\n",
      "Epoch 172/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1630 - acc: 0.9828 - val_loss: 0.0850 - val_acc: 0.9762\n",
      "Epoch 173/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1594 - acc: 0.9836 - val_loss: 0.0864 - val_acc: 0.9760\n",
      "Epoch 174/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1505 - acc: 0.9835 - val_loss: 0.0824 - val_acc: 0.9768\n",
      "Epoch 175/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1542 - acc: 0.9836 - val_loss: 0.0838 - val_acc: 0.9770\n",
      "Epoch 176/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1474 - acc: 0.9840 - val_loss: 0.0795 - val_acc: 0.9788\n",
      "Epoch 177/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1525 - acc: 0.9835 - val_loss: 0.0896 - val_acc: 0.9757\n",
      "Epoch 178/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1575 - acc: 0.9834 - val_loss: 0.0807 - val_acc: 0.9770\n",
      "Epoch 179/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1497 - acc: 0.9832 - val_loss: 0.0823 - val_acc: 0.9772\n",
      "Epoch 180/300\n",
      "93216/93216 [==============================] - 26s - loss: 0.1486 - acc: 0.9841 - val_loss: 0.0784 - val_acc: 0.9790\n",
      "Epoch 181/300\n",
      "86016/93216 [==========================>...] - ETA: 2s - loss: 0.1639 - acc: 0.9827"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=2048, validation_data=(X_valid, y_valid), \\\n",
    "          class_weight=class_weight, epochs=300, shuffle=True, verbose=1)\n",
    "model.save(os.path.join(OUTPUT_PATH, MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4907/4907 [==============================] - 0s     \n"
     ]
    }
   ],
   "source": [
    "preds_proba = model.predict(X_valid, batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 정확도 : 0.98288\n",
      "\n",
      " -------------------------- \n",
      "\n",
      "preds     _silence  _unknown  down   go  left   no  off   on  right  stop  \\\n",
      "actuals                                                                     \n",
      "_silence        63         0     0    0     0    0    0    0      0     0   \n",
      "_unknown         3      3075     1    4     0    3    1    2      2     2   \n",
      "down             0         2   170    1     0    0    0    0      0     0   \n",
      "go               0         4     0  158     0    3    0    0      0     2   \n",
      "left             0         6     0    0   171    0    0    0      0     0   \n",
      "no               0         1     1    3     0  172    0    0      0     0   \n",
      "off              1         2     0    0     0    0  162    2      0     0   \n",
      "on               0         6     0    1     0    0    4  155      0     0   \n",
      "right            2         2     0    0     1    0    0    0    153     0   \n",
      "stop             1         3     0    0     0    0    0    0      0   198   \n",
      "up               0         2     1    0     0    0    0    0      0     0   \n",
      "yes              0         1     0    0     0    1    0    0      0     0   \n",
      "\n",
      "preds      up  yes  \n",
      "actuals             \n",
      "_silence    0    0  \n",
      "_unknown    1    2  \n",
      "down        0    1  \n",
      "go          0    0  \n",
      "left        0    2  \n",
      "no          0    1  \n",
      "off         4    0  \n",
      "on          0    0  \n",
      "right       0    1  \n",
      "stop        1    0  \n",
      "up        168    0  \n",
      "yes         0  178  \n",
      "\n",
      " -------------------------- \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   _silence       0.90      1.00      0.95        63\n",
      "   _unknown       0.99      0.99      0.99      3096\n",
      "       down       0.98      0.98      0.98       174\n",
      "         go       0.95      0.95      0.95       167\n",
      "       left       0.99      0.96      0.97       179\n",
      "         no       0.96      0.97      0.96       178\n",
      "        off       0.97      0.95      0.96       171\n",
      "         on       0.97      0.93      0.95       166\n",
      "      right       0.99      0.96      0.97       159\n",
      "       stop       0.98      0.98      0.98       203\n",
      "         up       0.97      0.98      0.97       171\n",
      "        yes       0.96      0.99      0.98       180\n",
      "\n",
      "avg / total       0.98      0.98      0.98      4907\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = [LABELS[i] for i in np.argmax(preds_proba, axis=1)]\n",
    "actuals = [LABELS[i] for i in np.argmax(y_valid, axis=1)]\n",
    "print('* 정확도 : %.5f' % (np.sum(np.array(actuals) == np.array(preds)) / float(len(actuals))))\n",
    "preds = pd.Categorical(preds, categories=LABELS)\n",
    "actuals = pd.Categorical(actuals, categories=LABELS)\n",
    "print('\\n -------------------------- \\n')\n",
    "print(pd.crosstab(actuals, preds, rownames=['actuals'], colnames=['preds']))\n",
    "print('\\n -------------------------- \\n')\n",
    "print(classification_report(actuals, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 정확도 : 0.97493\n",
      "\n",
      " -------------------------- \n",
      "\n",
      "preds     _silence  _unknown  down   go  left   no  off   on  right  stop  \\\n",
      "actuals                                                                     \n",
      "_silence        63         0     0    0     0    0    0    0      0     0   \n",
      "_unknown         5      3014     1    7     4    6    6    9     20    12   \n",
      "down             0         2   169    2     0    1    0    0      0     0   \n",
      "go               0         5     0  160     0    1    0    0      0     0   \n",
      "left             0         1     0    0   173    0    0    2      0     1   \n",
      "no               0         0     0    2     0  175    0    0      0     1   \n",
      "off              1         0     0    1     0    0  166    1      0     0   \n",
      "on               0         2     1    2     0    0    1  160      0     0   \n",
      "right            2         2     0    0     0    0    0    0    154     0   \n",
      "stop             0         0     0    0     0    0    1    1      0   200   \n",
      "up               0         0     0    0     0    0    1    0      0     0   \n",
      "yes              0         0     0    0     0    0    0    0      0     0   \n",
      "\n",
      "preds      up  yes  \n",
      "actuals             \n",
      "_silence    0    0  \n",
      "_unknown    5    7  \n",
      "down        0    0  \n",
      "go          1    0  \n",
      "left        0    2  \n",
      "no          0    0  \n",
      "off         2    0  \n",
      "on          0    0  \n",
      "right       0    1  \n",
      "stop        1    0  \n",
      "up        170    0  \n",
      "yes         0  180  \n",
      "\n",
      " -------------------------- \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   _silence       0.89      1.00      0.94        63\n",
      "   _unknown       1.00      0.97      0.98      3096\n",
      "       down       0.99      0.97      0.98       174\n",
      "         go       0.92      0.96      0.94       167\n",
      "       left       0.98      0.97      0.97       179\n",
      "         no       0.96      0.98      0.97       178\n",
      "        off       0.95      0.97      0.96       171\n",
      "         on       0.92      0.96      0.94       166\n",
      "      right       0.89      0.97      0.92       159\n",
      "       stop       0.93      0.99      0.96       203\n",
      "         up       0.95      0.99      0.97       171\n",
      "        yes       0.95      1.00      0.97       180\n",
      "\n",
      "avg / total       0.98      0.97      0.98      4907\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = [LABELS[i] for i in np.argmax(preds_proba, axis=1)]\n",
    "actuals = [LABELS[i] for i in np.argmax(y_valid, axis=1)]\n",
    "print('* 정확도 : %.5f' % (np.sum(np.array(actuals) == np.array(preds)) / float(len(actuals))))\n",
    "preds = pd.Categorical(preds, categories=LABELS)\n",
    "actuals = pd.Categorical(actuals, categories=LABELS)\n",
    "print('\\n -------------------------- \\n')\n",
    "print(pd.crosstab(actuals, preds, rownames=['actuals'], colnames=['preds']))\n",
    "print('\\n -------------------------- \\n')\n",
    "print(classification_report(actuals, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 정확도 : 0.97330\n",
      "\n",
      " -------------------------- \n",
      "\n",
      "preds     _silence  _unknown  down   go  left   no  off   on  right  stop  \\\n",
      "actuals                                                                     \n",
      "_silence        63         0     0    0     0    0    0    0      0     0   \n",
      "_unknown         9      3013     4    7     5    5    7   13     13     8   \n",
      "down             0         1   171    1     0    1    0    0      0     0   \n",
      "go               0         3     0  158     0    2    0    0      1     2   \n",
      "left             0         1     0    0   172    1    1    2      0     0   \n",
      "no               0         0     1    1     0  175    0    0      0     0   \n",
      "off              1         1     0    1     0    0  166    1      0     0   \n",
      "on               0         4     0    1     0    0    1  159      0     0   \n",
      "right            3         1     0    0     0    0    0    0    154     0   \n",
      "stop             1         1     0    0     0    0    1    1      0   197   \n",
      "up               1         0     0    0     0    0    1    0      0     0   \n",
      "yes              0         0     0    0     1    0    0    0      0     0   \n",
      "\n",
      "preds      up  yes  \n",
      "actuals             \n",
      "_silence    0    0  \n",
      "_unknown    5    7  \n",
      "down        0    0  \n",
      "go          1    0  \n",
      "left        1    1  \n",
      "no          0    1  \n",
      "off         1    0  \n",
      "on          1    0  \n",
      "right       0    1  \n",
      "stop        2    0  \n",
      "up        169    0  \n",
      "yes         0  179  \n",
      "\n",
      " -------------------------- \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   _silence       0.81      1.00      0.89        63\n",
      "   _unknown       1.00      0.97      0.98      3096\n",
      "       down       0.97      0.98      0.98       174\n",
      "         go       0.93      0.95      0.94       167\n",
      "       left       0.97      0.96      0.96       179\n",
      "         no       0.95      0.98      0.97       178\n",
      "        off       0.94      0.97      0.95       171\n",
      "         on       0.90      0.96      0.93       166\n",
      "      right       0.92      0.97      0.94       159\n",
      "       stop       0.95      0.97      0.96       203\n",
      "         up       0.94      0.99      0.96       171\n",
      "        yes       0.95      0.99      0.97       180\n",
      "\n",
      "avg / total       0.97      0.97      0.97      4907\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = [LABELS[i] for i in np.argmax(preds_proba, axis=1)]\n",
    "actuals = [LABELS[i] for i in np.argmax(y_valid, axis=1)]\n",
    "print('* 정확도 : %.5f' % (np.sum(np.array(actuals) == np.array(preds)) / float(len(actuals))))\n",
    "preds = pd.Categorical(preds, categories=LABELS)\n",
    "actuals = pd.Categorical(actuals, categories=LABELS)\n",
    "print('\\n -------------------------- \\n')\n",
    "print(pd.crosstab(actuals, preds, rownames=['actuals'], colnames=['preds']))\n",
    "print('\\n -------------------------- \\n')\n",
    "print(classification_report(actuals, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 정확도 : 0.97028\n",
      "\n",
      " -------------------------- \n",
      "\n",
      "preds     _silence  _unknown  down  go  left   no  off  on  right  stop   up  \\\n",
      "actuals                                                                        \n",
      "_silence        54         0     0   0     0    0    0   0      0     0    0   \n",
      "_unknown         4      2029     0   7     1    9    2   1      0     0    4   \n",
      "down             0         4   128   1     0    1    0   0      0     0    0   \n",
      "go               0         5     4  87     0    2    0   0      0     0    0   \n",
      "left             0         6     0   0   126    0    0   0      0     0    2   \n",
      "no               0         4     2   0     0  103    0   0      0     1    0   \n",
      "off              1         6     1   0     1    0  100   0      0     1    1   \n",
      "on               0         4     0   0     0    0    1  98      0     0    0   \n",
      "right            0         5     0   0     1    0    0   0    121     0    0   \n",
      "stop             0         4     1   0     0    1    0   0      0   118    2   \n",
      "up               2         2     0   0     0    0    0   0      0     0  122   \n",
      "yes              0         1     0   0     0    0    0   0      0     0    0   \n",
      "\n",
      "preds     yes  \n",
      "actuals        \n",
      "_silence    0  \n",
      "_unknown    1  \n",
      "down        1  \n",
      "go          0  \n",
      "left        1  \n",
      "no          0  \n",
      "off         0  \n",
      "on          0  \n",
      "right       0  \n",
      "stop        0  \n",
      "up          0  \n",
      "yes       113  \n",
      "\n",
      " -------------------------- \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   _silence       0.89      1.00      0.94        54\n",
      "   _unknown       0.98      0.99      0.98      2058\n",
      "       down       0.94      0.95      0.94       135\n",
      "         go       0.92      0.89      0.90        98\n",
      "       left       0.98      0.93      0.95       135\n",
      "         no       0.89      0.94      0.91       110\n",
      "        off       0.97      0.90      0.93       111\n",
      "         on       0.99      0.95      0.97       103\n",
      "      right       1.00      0.95      0.98       127\n",
      "       stop       0.98      0.94      0.96       126\n",
      "         up       0.93      0.97      0.95       126\n",
      "        yes       0.97      0.99      0.98       114\n",
      "\n",
      "avg / total       0.97      0.97      0.97      3297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = [LABELS[i] for i in np.argmax(preds_proba, axis=1)]\n",
    "actuals = [LABELS[i] for i in np.argmax(y_valid, axis=1)]\n",
    "print('* 정확도 : %.5f' % (np.sum(np.array(actuals) == np.array(preds)) / float(len(actuals))))\n",
    "preds = pd.Categorical(preds, categories=LABELS)\n",
    "actuals = pd.Categorical(actuals, categories=LABELS)\n",
    "print('\\n -------------------------- \\n')\n",
    "print(pd.crosstab(actuals, preds, rownames=['actuals'], colnames=['preds']))\n",
    "print('\\n -------------------------- \\n')\n",
    "print(classification_report(actuals, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 제출파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 26s, sys: 3.8 s, total: 2min 30s\n",
      "Wall time: 2min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X = []\n",
    "submission_fpaths = sorted(glob(os.path.join(TEST_PATH, r'*wav')))\n",
    "for fpath in submission_fpaths:\n",
    "    sample_rate, samples = wavfile.read(fpath)\n",
    "    samples = pad_audio(samples)\n",
    "    if len(samples) > 16000:\n",
    "        n_samples = chop_audio(samples)\n",
    "    else: \n",
    "        n_samples = [samples]\n",
    "    for samples in n_samples:\n",
    "        resampled = signal.resample(samples, int(new_sample_rate / sample_rate * samples.shape[0]))\n",
    "        _, _, specgram = log_specgram(resampled, sample_rate=new_sample_rate)\n",
    "        X.append(specgram)\n",
    "        \n",
    "X = np.array(X)\n",
    "X = X.reshape(tuple(list(X.shape) + [1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158538/158538 [==============================] - 14s    \n"
     ]
    }
   ],
   "source": [
    "preds_proba = model.predict(X, batch_size=2048, verbose=1)\n",
    "preds = [[L.replace('_', '') for L in LABELS][i] for i in np.argmax(preds_proba, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'fname': submission_fpaths, 'label': preds})\n",
    "df['fname'] = df['fname'].apply(lambda p: p.split('/')[-1])\n",
    "df.to_csv(os.path.join(OUTPUT_PATH, 'sub_' + MODEL_NAME.split('.')[0] + '.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown    100591\n",
       "yes          6519\n",
       "off          6272\n",
       "stop         6064\n",
       "left         5637\n",
       "no           5428\n",
       "up           5392\n",
       "go           5237\n",
       "down         5135\n",
       "on           5126\n",
       "right        4923\n",
       "silence      2214\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown    81043\n",
       "on         14810\n",
       "off         7550\n",
       "up          7044\n",
       "right       6950\n",
       "left        6659\n",
       "go          6553\n",
       "stop        6360\n",
       "yes         6292\n",
       "no          6199\n",
       "down        4760\n",
       "silence     4318\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown    82108\n",
       "on         15084\n",
       "off         8341\n",
       "no          6978\n",
       "right       6541\n",
       "left        6510\n",
       "up          6284\n",
       "yes         6137\n",
       "stop        5775\n",
       "go          5678\n",
       "down        4916\n",
       "silence     4186\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
