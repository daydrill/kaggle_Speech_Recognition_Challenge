{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.fftpack import fft\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "from glob import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "import gc\n",
    "from scipy.io import wavfile\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import optimizers, losses, activations, models\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.layers import Convolution2D, Dense, Input, Flatten, Dropout, MaxPooling2D, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# new_sample_rate = 8000\n",
    "\n",
    "LABELS = ['_silence', '_unknown', 'down', 'go', 'left', 'no', 'off', 'on', 'right', 'stop', 'up', 'yes']\n",
    "TRAIN_PATH = './input/train/audio/'\n",
    "TEST_PATH = './input/test/audio/'\n",
    "OUTPUT_PATH = './output/'\n",
    "MODEL_NAME = 'cnn_new.h5'\n",
    "\n",
    "# class_weight = {0: 13.0,\n",
    "#  1: 1.0,\n",
    "#  2: 9.0,\n",
    "#  3: 9.0,\n",
    "#  4: 9.0,\n",
    "#  5: 9.0,\n",
    "#  6: 9.0,\n",
    "#  7: 5.0,\n",
    "#  8: 9.0,\n",
    "#  9: 9.0,\n",
    "#  10: 9.0,\n",
    "#  11: 9.0}\n",
    "\n",
    "# class_weight = {0: 10.0,\n",
    "#  1: 1.0,\n",
    "#  2: 1.0,\n",
    "#  3: 1.0,\n",
    "#  4: 1.0,\n",
    "#  5: 1.0,\n",
    "#  6: 1.0,\n",
    "#  7: 1.0,\n",
    "#  8: 1.0,\n",
    "#  9: 1.0,\n",
    "#  10: 1.0,\n",
    "#  11: 1.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 원본 클래스 비율\n",
    "# {0: 1200,\n",
    "#  1: 41039,\n",
    "#  2: 2359,\n",
    "#  3: 2372,\n",
    "#  4: 2353,\n",
    "#  5: 2375,\n",
    "#  6: 2357,\n",
    "#  7: 2367,\n",
    "#  8: 2367,\n",
    "#  9: 2380,\n",
    "#  10: 2375,\n",
    "#  11: 2377}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## custom_fft and log_specgram functions written by DavidS.\n",
    "def custom_fft(y, fs):\n",
    "    T = 1.0 / fs\n",
    "    N = y.shape[0]\n",
    "    yf = fft(y)\n",
    "    xf = np.linspace(0.0, 1.0/(2.0*T), N//2)\n",
    "    # FFT 는 대칭(simmetrical)이므로 반쪽만 얻음.\n",
    "    # FFT 는 복소수이므로 실수값만 취하기 위해 abs()\n",
    "    vals = 2.0/N * np.abs(yf[0:N//2])\n",
    "    return xf, vals\n",
    "\n",
    "def log_specgram(audio, sample_rate, window_size=20, step_size=10, eps=1e-10):\n",
    "    nperseg = int(round(window_size * sample_rate / 1e3))\n",
    "    noverlap = int(round(step_size * sample_rate / 1e3))\n",
    "    freqs, times, spec = signal.spectrogram(audio,\n",
    "                                    fs=sample_rate,\n",
    "                                    window='hann',\n",
    "                                    nperseg=nperseg,\n",
    "                                    noverlap=noverlap,\n",
    "                                    detrend=False)\n",
    "    return freqs, times, np.log(spec.T.astype(np.float32) + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## utility function to grab all wav files inside train data folder.\n",
    "def list_wavs_fname(dirpath, ext='wav'):\n",
    "    print(dirpath)\n",
    "    fpaths = glob(os.path.join(dirpath, r'*/*' + ext))\n",
    "    pat = r'.+/(\\w+)/\\w+\\.' + ext + '$'\n",
    "    labels = []\n",
    "    for fpath in fpaths:\n",
    "        r = re.match(pat, fpath)\n",
    "        if r:\n",
    "            labels.append(r.group(1))\n",
    "    pat = r'.+/(\\w+\\.' + ext + ')$'\n",
    "    fnames = []\n",
    "    for fpath in fpaths:\n",
    "        r = re.match(pat, fpath)\n",
    "        if r:\n",
    "            fnames.append(r.group(1))\n",
    "    return labels, fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pad_audio(samples, L=16000):\n",
    "    '''\n",
    "    pad audios that are less than 16000(1 second) with 0s to make them all have the same length.\n",
    "    '''\n",
    "    if len(samples) >= L: \n",
    "        return samples\n",
    "    else: \n",
    "        return np.pad(samples, pad_width=(L - len(samples), 0), mode='constant', constant_values=(0, 0)) \n",
    "        # sample 앞뒤로 constant_values[0]과 constant_values[1]을 각각 pad_width 갯수 만큼 패딩\n",
    "        # 총길이는 len(samples) + 2*pad_width\n",
    "\n",
    "# def chop_audio(samples, L=16000, num=200):\n",
    "#     '''\n",
    "#     chop audios that are larger than 16000(eg. wav files in background noises folder) to 16000 in length.\n",
    "#     create several chunks out of one large wav files given the parameter 'num'.\n",
    "#     '''\n",
    "#     for i in range(num):\n",
    "#         beg = np.random.randint(0, len(samples) - L)\n",
    "#         yield samples[beg: beg + L]\n",
    "\n",
    "def label_transform(labels):\n",
    "    '''\n",
    "    레이블 정규화 및 one-hot벡터화 (더미화)\n",
    "    '''\n",
    "    nlabels = []\n",
    "    for label in labels:\n",
    "        if label == '_background_noise_':\n",
    "            nlabels.append('_silence')\n",
    "        elif label not in LABELS:\n",
    "            nlabels.append('_unknown')\n",
    "        else:\n",
    "            nlabels.append(label)\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(nlabels)\n",
    "    nlabels = encoder.transform(nlabels)\n",
    "    return nlabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Data & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Load labels, fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./input/train/audio/\n"
     ]
    }
   ],
   "source": [
    "labels, fnames = list_wavs_fname(TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 23s, sys: 3.18 s, total: 1min 26s\n",
      "Wall time: 1min 26s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chi/anaconda3/lib/python3.5/site-packages/scipy/io/wavfile.py:273: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  WavFileWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y = []\n",
    "X = []\n",
    "for i, (label, fname) in enumerate(zip(labels, fnames)):\n",
    "    sample_rate, samples = wavfile.read(os.path.join(TRAIN_PATH, label, fname))\n",
    "    if len(samples) > 16000:\n",
    "        pass\n",
    "    else:\n",
    "        samples = pad_audio(samples)\n",
    "        _, _, specgram = log_specgram(samples, sample_rate=16000)\n",
    "        y.append(label)\n",
    "        X.append(specgram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "X = X.reshape(tuple(list(X.shape) + [1])) # (64841, 99, 81, 1) 로 reshape\n",
    "y = to_categorical(label_transform(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Train Validation Set Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.05, random_state=1130) # 9:1로 train, valid 셋 나눔.\n",
    "del X, y\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape = (99, 161, 1) #(99, 81, 1) # in order to fit into Conv2D layer, we need to reshape it.\n",
    "nclass = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 99, 161, 1)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 99, 161, 1)        4         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 98, 160, 8)        40        \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 97, 159, 8)        264       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 48, 79, 8)         0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 48, 79, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 46, 77, 16)        1168      \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 44, 75, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 22, 37, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 20, 35, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 18, 33, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 9, 16, 32)         0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 9, 16, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 7, 14, 32)         9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 3, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 3, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 672)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 128)               86144     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 12)                1548      \n",
      "=================================================================\n",
      "Total params: 148,672\n",
      "Trainable params: 148,158\n",
      "Non-trainable params: 514\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Modeling\n",
    "inp = Input(shape=input_shape)\n",
    "norm_inp = BatchNormalization()(inp)\n",
    "img_1 = Convolution2D(8, kernel_size=2, activation=activations.relu)(norm_inp)\n",
    "img_1 = Convolution2D(8, kernel_size=2, activation=activations.relu)(img_1)\n",
    "img_1 = MaxPooling2D(pool_size=(2, 2))(img_1)\n",
    "img_1 = Dropout(rate=0.2)(img_1)\n",
    "img_1 = Convolution2D(16, kernel_size=3, activation=activations.relu)(img_1)\n",
    "img_1 = Convolution2D(16, kernel_size=3, activation=activations.relu)(img_1)\n",
    "img_1 = MaxPooling2D(pool_size=(2, 2))(img_1)\n",
    "img_1 = Convolution2D(32, kernel_size=3, activation=activations.relu)(img_1)\n",
    "img_1 = Convolution2D(32, kernel_size=3, activation=activations.relu)(img_1)\n",
    "img_1 = MaxPooling2D(pool_size=(2, 2))(img_1)\n",
    "img_1 = Dropout(rate=0.2)(img_1)\n",
    "img_1 = Convolution2D(32, kernel_size=3, activation=activations.relu)(img_1)\n",
    "img_1 = MaxPooling2D(pool_size=(2, 2))(img_1)\n",
    "img_1 = Dropout(rate=0.2)(img_1)\n",
    "img_1 = Flatten()(img_1)\n",
    "\n",
    "dense_1 = BatchNormalization()(Dense(128, activation=activations.relu)(img_1))\n",
    "dense_1 = Dropout(rate=0.2)(dense_1)\n",
    "dense_1 = BatchNormalization()(Dense(128, activation=activations.relu)(dense_1))\n",
    "dense_1 = Dense(128, activation=activations.relu)(dense_1)\n",
    "dense_1 = Dense(nclass, activation=activations.softmax)(dense_1)\n",
    "\n",
    "model = models.Model(inputs=inp, outputs=dense_1)\n",
    "opt = optimizers.Adam()\n",
    "\n",
    "model.compile(optimizer=opt, loss=losses.binary_crossentropy, metrics=['categorical_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ## Modeling\n",
    "# inp = Input(shape=input_shape)\n",
    "# norm_inp = BatchNormalization()(inp)\n",
    "# img_1 = Convolution2D(8, kernel_size=2, activation=activations.relu, padding='same')(norm_inp)\n",
    "# img_1 = Convolution2D(8, kernel_size=2, activation=activations.relu, padding='same')(img_1)\n",
    "# img_1 = MaxPooling2D(pool_size=(2, 2))(img_1)\n",
    "# img_1 = Dropout(rate=0.2)(img_1)\n",
    "# img_1 = Convolution2D(16, kernel_size=2, activation=activations.relu, padding='same')(img_1)\n",
    "# img_1 = Convolution2D(16, kernel_size=2, activation=activations.relu, padding='same')(img_1)\n",
    "# img_1 = MaxPooling2D(pool_size=(2, 2))(img_1)\n",
    "# img_1 = Dropout(rate=0.2)(img_1)\n",
    "# img_1 = Convolution2D(16, kernel_size=3, activation=activations.relu, padding='same')(img_1)\n",
    "# img_1 = Convolution2D(16, kernel_size=3, activation=activations.relu, padding='same')(img_1)\n",
    "# img_1 = MaxPooling2D(pool_size=(2, 2))(img_1)\n",
    "# img_1 = Dropout(rate=0.2)(img_1)\n",
    "# img_1 = Convolution2D(32, kernel_size=3, activation=activations.relu, padding='same')(img_1)\n",
    "# img_1 = MaxPooling2D(pool_size=(2, 2))(img_1)\n",
    "# img_1 = Dropout(rate=0.2)(img_1)\n",
    "# img_1 = Flatten()(img_1)\n",
    "\n",
    "# dense_1 = BatchNormalization()(img_1)\n",
    "# dense_1 = Dense(512, activation=activations.relu)(dense_1)\n",
    "# dense_1 = Dropout(rate=0.2)(dense_1)\n",
    "# dense_1 = Dense(512, activation=activations.relu)(dense_1)\n",
    "# dense_1 = Dropout(rate=0.2)(dense_1)\n",
    "# dense_1 = Dense(512, activation=activations.relu)(dense_1)\n",
    "# dense_1 = Dropout(rate=0.2)(dense_1)\n",
    "# dense_1 = Dense(128, activation=activations.relu)(dense_1)\n",
    "# dense_1 = Dropout(rate=0.2)(dense_1)\n",
    "# dense_1 = Dense(64, activation=activations.relu)(dense_1)\n",
    "# dense_1 = Dense(nclass, activation=activations.softmax)(dense_1)\n",
    "\n",
    "# model = models.Model(inputs=inp, outputs=dense_1)\n",
    "# opt = optimizers.Adam(lr=0.001)\n",
    "\n",
    "# model.compile(optimizer=opt, loss=losses.binary_crossentropy, metrics=['categorical_accuracy'])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 네트워크 시각화\n",
    "# plot_model(model, to_file='output/model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 93413 samples, validate on 4917 samples\n",
      "Epoch 1/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.2056 - categorical_accuracy: 0.5676 - val_loss: 0.2153 - val_categorical_accuracy: 0.6179\n",
      "Epoch 2/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.1693 - categorical_accuracy: 0.6424 - val_loss: 0.1883 - val_categorical_accuracy: 0.6179\n",
      "Epoch 3/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.1256 - categorical_accuracy: 0.7044 - val_loss: 0.1899 - val_categorical_accuracy: 0.6179\n",
      "Epoch 4/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0915 - categorical_accuracy: 0.7807 - val_loss: 0.1513 - val_categorical_accuracy: 0.6347\n",
      "Epoch 5/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0754 - categorical_accuracy: 0.8212 - val_loss: 0.0986 - val_categorical_accuracy: 0.7393\n",
      "Epoch 6/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0647 - categorical_accuracy: 0.8489 - val_loss: 0.0670 - val_categorical_accuracy: 0.8351\n",
      "Epoch 7/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0583 - categorical_accuracy: 0.8648 - val_loss: 0.0495 - val_categorical_accuracy: 0.8853\n",
      "Epoch 8/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0532 - categorical_accuracy: 0.8786 - val_loss: 0.0436 - val_categorical_accuracy: 0.8973\n",
      "Epoch 9/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0491 - categorical_accuracy: 0.8875 - val_loss: 0.0403 - val_categorical_accuracy: 0.9077\n",
      "Epoch 10/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0456 - categorical_accuracy: 0.8955 - val_loss: 0.0345 - val_categorical_accuracy: 0.9223\n",
      "Epoch 11/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0426 - categorical_accuracy: 0.9032 - val_loss: 0.0349 - val_categorical_accuracy: 0.9152\n",
      "Epoch 12/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0408 - categorical_accuracy: 0.9074 - val_loss: 0.0302 - val_categorical_accuracy: 0.9321\n",
      "Epoch 13/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0393 - categorical_accuracy: 0.9108 - val_loss: 0.0317 - val_categorical_accuracy: 0.9252\n",
      "Epoch 14/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0364 - categorical_accuracy: 0.9178 - val_loss: 0.0279 - val_categorical_accuracy: 0.9374\n",
      "Epoch 15/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0360 - categorical_accuracy: 0.9191 - val_loss: 0.0278 - val_categorical_accuracy: 0.9370\n",
      "Epoch 16/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0340 - categorical_accuracy: 0.9231 - val_loss: 0.0282 - val_categorical_accuracy: 0.9376\n",
      "Epoch 17/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0334 - categorical_accuracy: 0.9245 - val_loss: 0.0277 - val_categorical_accuracy: 0.9353\n",
      "Epoch 18/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0324 - categorical_accuracy: 0.9266 - val_loss: 0.0278 - val_categorical_accuracy: 0.9345\n",
      "Epoch 19/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0312 - categorical_accuracy: 0.9302 - val_loss: 0.0254 - val_categorical_accuracy: 0.9418\n",
      "Epoch 20/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0304 - categorical_accuracy: 0.9324 - val_loss: 0.0278 - val_categorical_accuracy: 0.9359\n",
      "Epoch 21/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0301 - categorical_accuracy: 0.9324 - val_loss: 0.0236 - val_categorical_accuracy: 0.9443\n",
      "Epoch 22/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0287 - categorical_accuracy: 0.9346 - val_loss: 0.0226 - val_categorical_accuracy: 0.9481\n",
      "Epoch 23/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0280 - categorical_accuracy: 0.9371 - val_loss: 0.0221 - val_categorical_accuracy: 0.9481\n",
      "Epoch 24/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0275 - categorical_accuracy: 0.9378 - val_loss: 0.0215 - val_categorical_accuracy: 0.9496\n",
      "Epoch 25/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0274 - categorical_accuracy: 0.9385 - val_loss: 0.0234 - val_categorical_accuracy: 0.9475\n",
      "Epoch 26/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0266 - categorical_accuracy: 0.9395 - val_loss: 0.0215 - val_categorical_accuracy: 0.9506\n",
      "Epoch 27/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0258 - categorical_accuracy: 0.9422 - val_loss: 0.0213 - val_categorical_accuracy: 0.9500\n",
      "Epoch 28/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0258 - categorical_accuracy: 0.9417 - val_loss: 0.0223 - val_categorical_accuracy: 0.9492\n",
      "Epoch 29/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0252 - categorical_accuracy: 0.9433 - val_loss: 0.0204 - val_categorical_accuracy: 0.9516\n",
      "Epoch 30/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0245 - categorical_accuracy: 0.9445 - val_loss: 0.0200 - val_categorical_accuracy: 0.9512\n",
      "Epoch 31/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0243 - categorical_accuracy: 0.9451 - val_loss: 0.0187 - val_categorical_accuracy: 0.9561\n",
      "Epoch 32/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0238 - categorical_accuracy: 0.9467 - val_loss: 0.0189 - val_categorical_accuracy: 0.9553\n",
      "Epoch 33/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0236 - categorical_accuracy: 0.9471 - val_loss: 0.0189 - val_categorical_accuracy: 0.9549\n",
      "Epoch 34/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0228 - categorical_accuracy: 0.9489 - val_loss: 0.0185 - val_categorical_accuracy: 0.9571\n",
      "Epoch 35/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0231 - categorical_accuracy: 0.9482 - val_loss: 0.0187 - val_categorical_accuracy: 0.9567\n",
      "Epoch 36/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0225 - categorical_accuracy: 0.9491 - val_loss: 0.0192 - val_categorical_accuracy: 0.9553\n",
      "Epoch 37/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0222 - categorical_accuracy: 0.9502 - val_loss: 0.0181 - val_categorical_accuracy: 0.9589\n",
      "Epoch 38/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0213 - categorical_accuracy: 0.9524 - val_loss: 0.0173 - val_categorical_accuracy: 0.9571\n",
      "Epoch 39/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0216 - categorical_accuracy: 0.9516 - val_loss: 0.0167 - val_categorical_accuracy: 0.9612\n",
      "Epoch 40/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0215 - categorical_accuracy: 0.9520 - val_loss: 0.0196 - val_categorical_accuracy: 0.9551\n",
      "Epoch 41/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0212 - categorical_accuracy: 0.9522 - val_loss: 0.0179 - val_categorical_accuracy: 0.9569\n",
      "Epoch 42/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0212 - categorical_accuracy: 0.9526 - val_loss: 0.0169 - val_categorical_accuracy: 0.9591\n",
      "Epoch 43/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0208 - categorical_accuracy: 0.9533 - val_loss: 0.0182 - val_categorical_accuracy: 0.9585\n",
      "Epoch 44/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0203 - categorical_accuracy: 0.9553 - val_loss: 0.0172 - val_categorical_accuracy: 0.9577\n",
      "Epoch 45/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0201 - categorical_accuracy: 0.9545 - val_loss: 0.0175 - val_categorical_accuracy: 0.9583\n",
      "Epoch 46/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0198 - categorical_accuracy: 0.9557 - val_loss: 0.0159 - val_categorical_accuracy: 0.9626\n",
      "Epoch 47/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0198 - categorical_accuracy: 0.9556 - val_loss: 0.0176 - val_categorical_accuracy: 0.9595\n",
      "Epoch 48/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0194 - categorical_accuracy: 0.9562 - val_loss: 0.0163 - val_categorical_accuracy: 0.9610\n",
      "Epoch 49/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0195 - categorical_accuracy: 0.9560 - val_loss: 0.0155 - val_categorical_accuracy: 0.9603\n",
      "Epoch 50/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0193 - categorical_accuracy: 0.9569 - val_loss: 0.0154 - val_categorical_accuracy: 0.9656\n",
      "Epoch 51/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0190 - categorical_accuracy: 0.9571 - val_loss: 0.0157 - val_categorical_accuracy: 0.9642\n",
      "Epoch 52/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0189 - categorical_accuracy: 0.9575 - val_loss: 0.0153 - val_categorical_accuracy: 0.9660\n",
      "Epoch 53/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0184 - categorical_accuracy: 0.9586 - val_loss: 0.0153 - val_categorical_accuracy: 0.9650\n",
      "Epoch 54/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0183 - categorical_accuracy: 0.9598 - val_loss: 0.0152 - val_categorical_accuracy: 0.9650\n",
      "Epoch 55/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0185 - categorical_accuracy: 0.9585 - val_loss: 0.0169 - val_categorical_accuracy: 0.9614\n",
      "Epoch 56/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0186 - categorical_accuracy: 0.9585 - val_loss: 0.0152 - val_categorical_accuracy: 0.9638\n",
      "Epoch 57/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0180 - categorical_accuracy: 0.9596 - val_loss: 0.0146 - val_categorical_accuracy: 0.9662\n",
      "Epoch 58/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0177 - categorical_accuracy: 0.9602 - val_loss: 0.0169 - val_categorical_accuracy: 0.9620\n",
      "Epoch 59/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0177 - categorical_accuracy: 0.9603 - val_loss: 0.0164 - val_categorical_accuracy: 0.9614\n",
      "Epoch 60/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0174 - categorical_accuracy: 0.9612 - val_loss: 0.0158 - val_categorical_accuracy: 0.9636\n",
      "Epoch 61/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0177 - categorical_accuracy: 0.9598 - val_loss: 0.0147 - val_categorical_accuracy: 0.9664\n",
      "Epoch 62/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0172 - categorical_accuracy: 0.9621 - val_loss: 0.0145 - val_categorical_accuracy: 0.9691\n",
      "Epoch 63/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0169 - categorical_accuracy: 0.9626 - val_loss: 0.0158 - val_categorical_accuracy: 0.9632\n",
      "Epoch 64/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0168 - categorical_accuracy: 0.9619 - val_loss: 0.0137 - val_categorical_accuracy: 0.9711\n",
      "Epoch 65/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0168 - categorical_accuracy: 0.9625 - val_loss: 0.0156 - val_categorical_accuracy: 0.9660\n",
      "Epoch 66/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0168 - categorical_accuracy: 0.9630 - val_loss: 0.0156 - val_categorical_accuracy: 0.9648\n",
      "Epoch 67/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0170 - categorical_accuracy: 0.9619 - val_loss: 0.0132 - val_categorical_accuracy: 0.9707\n",
      "Epoch 68/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0162 - categorical_accuracy: 0.9637 - val_loss: 0.0141 - val_categorical_accuracy: 0.9687\n",
      "Epoch 69/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0164 - categorical_accuracy: 0.9633 - val_loss: 0.0145 - val_categorical_accuracy: 0.9671\n",
      "Epoch 70/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0163 - categorical_accuracy: 0.9641 - val_loss: 0.0144 - val_categorical_accuracy: 0.9689\n",
      "Epoch 71/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0161 - categorical_accuracy: 0.9639 - val_loss: 0.0145 - val_categorical_accuracy: 0.9671\n",
      "Epoch 72/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0160 - categorical_accuracy: 0.9645 - val_loss: 0.0139 - val_categorical_accuracy: 0.9673\n",
      "Epoch 73/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0161 - categorical_accuracy: 0.9641 - val_loss: 0.0143 - val_categorical_accuracy: 0.9683\n",
      "Epoch 74/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0157 - categorical_accuracy: 0.9651 - val_loss: 0.0143 - val_categorical_accuracy: 0.9673\n",
      "Epoch 75/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0155 - categorical_accuracy: 0.9651 - val_loss: 0.0136 - val_categorical_accuracy: 0.9701\n",
      "Epoch 76/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0164 - categorical_accuracy: 0.9627 - val_loss: 0.0135 - val_categorical_accuracy: 0.9697\n",
      "Epoch 77/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0155 - categorical_accuracy: 0.9651 - val_loss: 0.0138 - val_categorical_accuracy: 0.9677\n",
      "Epoch 78/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0155 - categorical_accuracy: 0.9652 - val_loss: 0.0127 - val_categorical_accuracy: 0.9705\n",
      "Epoch 79/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0156 - categorical_accuracy: 0.9651 - val_loss: 0.0135 - val_categorical_accuracy: 0.9681\n",
      "Epoch 80/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0153 - categorical_accuracy: 0.9661 - val_loss: 0.0135 - val_categorical_accuracy: 0.9699\n",
      "Epoch 81/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0157 - categorical_accuracy: 0.9650 - val_loss: 0.0139 - val_categorical_accuracy: 0.9703\n",
      "Epoch 82/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0152 - categorical_accuracy: 0.9657 - val_loss: 0.0132 - val_categorical_accuracy: 0.9695\n",
      "Epoch 83/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0152 - categorical_accuracy: 0.9658 - val_loss: 0.0125 - val_categorical_accuracy: 0.9719\n",
      "Epoch 84/200\n",
      "93413/93413 [==============================] - 49s - loss: 0.0149 - categorical_accuracy: 0.9666 - val_loss: 0.0132 - val_categorical_accuracy: 0.9703\n",
      "Epoch 85/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0145 - categorical_accuracy: 0.9675 - val_loss: 0.0125 - val_categorical_accuracy: 0.9701\n",
      "Epoch 86/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0151 - categorical_accuracy: 0.9665 - val_loss: 0.0133 - val_categorical_accuracy: 0.9715\n",
      "Epoch 87/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0148 - categorical_accuracy: 0.9671 - val_loss: 0.0129 - val_categorical_accuracy: 0.9705\n",
      "Epoch 88/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0142 - categorical_accuracy: 0.9688 - val_loss: 0.0128 - val_categorical_accuracy: 0.9727\n",
      "Epoch 89/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0147 - categorical_accuracy: 0.9671 - val_loss: 0.0123 - val_categorical_accuracy: 0.9736\n",
      "Epoch 90/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0146 - categorical_accuracy: 0.9675 - val_loss: 0.0135 - val_categorical_accuracy: 0.9707\n",
      "Epoch 91/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0146 - categorical_accuracy: 0.9677 - val_loss: 0.0127 - val_categorical_accuracy: 0.9725\n",
      "Epoch 92/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0144 - categorical_accuracy: 0.9677 - val_loss: 0.0126 - val_categorical_accuracy: 0.9721\n",
      "Epoch 93/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0143 - categorical_accuracy: 0.9678 - val_loss: 0.0127 - val_categorical_accuracy: 0.9721\n",
      "Epoch 94/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0142 - categorical_accuracy: 0.9689 - val_loss: 0.0137 - val_categorical_accuracy: 0.9699\n",
      "Epoch 95/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0140 - categorical_accuracy: 0.9688 - val_loss: 0.0126 - val_categorical_accuracy: 0.9730\n",
      "Epoch 96/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0139 - categorical_accuracy: 0.9693 - val_loss: 0.0123 - val_categorical_accuracy: 0.9719\n",
      "Epoch 97/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0141 - categorical_accuracy: 0.9681 - val_loss: 0.0119 - val_categorical_accuracy: 0.9738\n",
      "Epoch 98/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0144 - categorical_accuracy: 0.9682 - val_loss: 0.0134 - val_categorical_accuracy: 0.9703\n",
      "Epoch 99/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0143 - categorical_accuracy: 0.9678 - val_loss: 0.0127 - val_categorical_accuracy: 0.9703\n",
      "Epoch 100/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93413/93413 [==============================] - 48s - loss: 0.0140 - categorical_accuracy: 0.9688 - val_loss: 0.0115 - val_categorical_accuracy: 0.9754\n",
      "Epoch 101/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0138 - categorical_accuracy: 0.9694 - val_loss: 0.0131 - val_categorical_accuracy: 0.9719\n",
      "Epoch 102/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0137 - categorical_accuracy: 0.9695 - val_loss: 0.0125 - val_categorical_accuracy: 0.9730\n",
      "Epoch 103/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0140 - categorical_accuracy: 0.9682 - val_loss: 0.0117 - val_categorical_accuracy: 0.9750\n",
      "Epoch 104/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0135 - categorical_accuracy: 0.9695 - val_loss: 0.0115 - val_categorical_accuracy: 0.9764\n",
      "Epoch 105/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0134 - categorical_accuracy: 0.9699 - val_loss: 0.0116 - val_categorical_accuracy: 0.9738\n",
      "Epoch 106/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0133 - categorical_accuracy: 0.9700 - val_loss: 0.0114 - val_categorical_accuracy: 0.9754\n",
      "Epoch 107/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0137 - categorical_accuracy: 0.9690 - val_loss: 0.0126 - val_categorical_accuracy: 0.9725\n",
      "Epoch 108/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0135 - categorical_accuracy: 0.9696 - val_loss: 0.0122 - val_categorical_accuracy: 0.9734\n",
      "Epoch 109/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0129 - categorical_accuracy: 0.9706 - val_loss: 0.0120 - val_categorical_accuracy: 0.9744\n",
      "Epoch 110/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0134 - categorical_accuracy: 0.9701 - val_loss: 0.0121 - val_categorical_accuracy: 0.9727\n",
      "Epoch 111/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0134 - categorical_accuracy: 0.9698 - val_loss: 0.0118 - val_categorical_accuracy: 0.9744\n",
      "Epoch 112/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0131 - categorical_accuracy: 0.9706 - val_loss: 0.0128 - val_categorical_accuracy: 0.9709\n",
      "Epoch 113/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0132 - categorical_accuracy: 0.9704 - val_loss: 0.0128 - val_categorical_accuracy: 0.9697\n",
      "Epoch 114/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0132 - categorical_accuracy: 0.9706 - val_loss: 0.0117 - val_categorical_accuracy: 0.9746\n",
      "Epoch 115/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0133 - categorical_accuracy: 0.9703 - val_loss: 0.0120 - val_categorical_accuracy: 0.9736\n",
      "Epoch 116/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0130 - categorical_accuracy: 0.9705 - val_loss: 0.0125 - val_categorical_accuracy: 0.9715\n",
      "Epoch 117/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0128 - categorical_accuracy: 0.9714 - val_loss: 0.0116 - val_categorical_accuracy: 0.9736\n",
      "Epoch 118/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0127 - categorical_accuracy: 0.9712 - val_loss: 0.0118 - val_categorical_accuracy: 0.9742\n",
      "Epoch 119/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0129 - categorical_accuracy: 0.9716 - val_loss: 0.0124 - val_categorical_accuracy: 0.9734\n",
      "Epoch 120/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0127 - categorical_accuracy: 0.9717 - val_loss: 0.0127 - val_categorical_accuracy: 0.9723\n",
      "Epoch 121/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0128 - categorical_accuracy: 0.9717 - val_loss: 0.0115 - val_categorical_accuracy: 0.9752\n",
      "Epoch 122/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0134 - categorical_accuracy: 0.9699 - val_loss: 0.0136 - val_categorical_accuracy: 0.9705\n",
      "Epoch 123/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0128 - categorical_accuracy: 0.9716 - val_loss: 0.0110 - val_categorical_accuracy: 0.9762\n",
      "Epoch 124/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0124 - categorical_accuracy: 0.9725 - val_loss: 0.0118 - val_categorical_accuracy: 0.9746\n",
      "Epoch 125/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0125 - categorical_accuracy: 0.9717 - val_loss: 0.0114 - val_categorical_accuracy: 0.9752\n",
      "Epoch 126/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0122 - categorical_accuracy: 0.9727 - val_loss: 0.0118 - val_categorical_accuracy: 0.9732\n",
      "Epoch 127/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0122 - categorical_accuracy: 0.9728 - val_loss: 0.0110 - val_categorical_accuracy: 0.9742\n",
      "Epoch 128/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0127 - categorical_accuracy: 0.9722 - val_loss: 0.0120 - val_categorical_accuracy: 0.9734\n",
      "Epoch 129/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0123 - categorical_accuracy: 0.9727 - val_loss: 0.0109 - val_categorical_accuracy: 0.9758\n",
      "Epoch 130/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0122 - categorical_accuracy: 0.9726 - val_loss: 0.0115 - val_categorical_accuracy: 0.9764\n",
      "Epoch 131/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0119 - categorical_accuracy: 0.9736 - val_loss: 0.0120 - val_categorical_accuracy: 0.9760\n",
      "Epoch 132/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0128 - categorical_accuracy: 0.9710 - val_loss: 0.0108 - val_categorical_accuracy: 0.9764\n",
      "Epoch 133/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0123 - categorical_accuracy: 0.9725 - val_loss: 0.0106 - val_categorical_accuracy: 0.9788\n",
      "Epoch 134/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0119 - categorical_accuracy: 0.9735 - val_loss: 0.0119 - val_categorical_accuracy: 0.9730\n",
      "Epoch 135/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0122 - categorical_accuracy: 0.9730 - val_loss: 0.0110 - val_categorical_accuracy: 0.9772\n",
      "Epoch 136/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0123 - categorical_accuracy: 0.9721 - val_loss: 0.0106 - val_categorical_accuracy: 0.9772\n",
      "Epoch 137/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0120 - categorical_accuracy: 0.9732 - val_loss: 0.0106 - val_categorical_accuracy: 0.9762\n",
      "Epoch 138/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0118 - categorical_accuracy: 0.9737 - val_loss: 0.0112 - val_categorical_accuracy: 0.9748\n",
      "Epoch 139/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0123 - categorical_accuracy: 0.9726 - val_loss: 0.0111 - val_categorical_accuracy: 0.9752\n",
      "Epoch 140/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0119 - categorical_accuracy: 0.9742 - val_loss: 0.0110 - val_categorical_accuracy: 0.9746\n",
      "Epoch 141/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0123 - categorical_accuracy: 0.9727 - val_loss: 0.0113 - val_categorical_accuracy: 0.9744\n",
      "Epoch 142/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0117 - categorical_accuracy: 0.9736 - val_loss: 0.0126 - val_categorical_accuracy: 0.9725\n",
      "Epoch 143/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0122 - categorical_accuracy: 0.9727 - val_loss: 0.0108 - val_categorical_accuracy: 0.9762\n",
      "Epoch 144/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0114 - categorical_accuracy: 0.9748 - val_loss: 0.0104 - val_categorical_accuracy: 0.9770\n",
      "Epoch 145/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0117 - categorical_accuracy: 0.9739 - val_loss: 0.0103 - val_categorical_accuracy: 0.9784\n",
      "Epoch 146/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0117 - categorical_accuracy: 0.9738 - val_loss: 0.0116 - val_categorical_accuracy: 0.9740\n",
      "Epoch 147/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0115 - categorical_accuracy: 0.9745 - val_loss: 0.0109 - val_categorical_accuracy: 0.9754\n",
      "Epoch 148/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0120 - categorical_accuracy: 0.9733 - val_loss: 0.0107 - val_categorical_accuracy: 0.9758\n",
      "Epoch 149/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0118 - categorical_accuracy: 0.9740 - val_loss: 0.0107 - val_categorical_accuracy: 0.9758\n",
      "Epoch 150/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0115 - categorical_accuracy: 0.9741 - val_loss: 0.0111 - val_categorical_accuracy: 0.9756\n",
      "Epoch 151/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0117 - categorical_accuracy: 0.9739 - val_loss: 0.0117 - val_categorical_accuracy: 0.9750\n",
      "Epoch 152/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0117 - categorical_accuracy: 0.9740 - val_loss: 0.0123 - val_categorical_accuracy: 0.9758\n",
      "Epoch 153/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0116 - categorical_accuracy: 0.9742 - val_loss: 0.0100 - val_categorical_accuracy: 0.9780\n",
      "Epoch 154/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0112 - categorical_accuracy: 0.9745 - val_loss: 0.0101 - val_categorical_accuracy: 0.9770\n",
      "Epoch 155/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0113 - categorical_accuracy: 0.9748 - val_loss: 0.0119 - val_categorical_accuracy: 0.9734\n",
      "Epoch 156/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0114 - categorical_accuracy: 0.9745 - val_loss: 0.0105 - val_categorical_accuracy: 0.9788\n",
      "Epoch 157/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0114 - categorical_accuracy: 0.9745 - val_loss: 0.0109 - val_categorical_accuracy: 0.9756\n",
      "Epoch 158/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0113 - categorical_accuracy: 0.9749 - val_loss: 0.0098 - val_categorical_accuracy: 0.9786\n",
      "Epoch 159/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0113 - categorical_accuracy: 0.9745 - val_loss: 0.0101 - val_categorical_accuracy: 0.9797\n",
      "Epoch 160/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0112 - categorical_accuracy: 0.9751 - val_loss: 0.0116 - val_categorical_accuracy: 0.9770\n",
      "Epoch 161/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0114 - categorical_accuracy: 0.9747 - val_loss: 0.0102 - val_categorical_accuracy: 0.9791\n",
      "Epoch 162/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0113 - categorical_accuracy: 0.9748 - val_loss: 0.0103 - val_categorical_accuracy: 0.9780\n",
      "Epoch 163/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0110 - categorical_accuracy: 0.9758 - val_loss: 0.0110 - val_categorical_accuracy: 0.9772\n",
      "Epoch 164/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0109 - categorical_accuracy: 0.9760 - val_loss: 0.0104 - val_categorical_accuracy: 0.9784\n",
      "Epoch 165/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0114 - categorical_accuracy: 0.9748 - val_loss: 0.0102 - val_categorical_accuracy: 0.9786\n",
      "Epoch 166/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0108 - categorical_accuracy: 0.9760 - val_loss: 0.0108 - val_categorical_accuracy: 0.9774\n",
      "Epoch 167/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0112 - categorical_accuracy: 0.9755 - val_loss: 0.0103 - val_categorical_accuracy: 0.9782\n",
      "Epoch 168/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0109 - categorical_accuracy: 0.9760 - val_loss: 0.0107 - val_categorical_accuracy: 0.9762\n",
      "Epoch 169/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0112 - categorical_accuracy: 0.9749 - val_loss: 0.0091 - val_categorical_accuracy: 0.9793\n",
      "Epoch 170/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0109 - categorical_accuracy: 0.9751 - val_loss: 0.0103 - val_categorical_accuracy: 0.9768\n",
      "Epoch 171/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0111 - categorical_accuracy: 0.9751 - val_loss: 0.0109 - val_categorical_accuracy: 0.9768\n",
      "Epoch 172/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0114 - categorical_accuracy: 0.9741 - val_loss: 0.0098 - val_categorical_accuracy: 0.9793\n",
      "Epoch 173/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0112 - categorical_accuracy: 0.9746 - val_loss: 0.0106 - val_categorical_accuracy: 0.9770\n",
      "Epoch 174/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0107 - categorical_accuracy: 0.9760 - val_loss: 0.0099 - val_categorical_accuracy: 0.9801\n",
      "Epoch 175/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0113 - categorical_accuracy: 0.9746 - val_loss: 0.0109 - val_categorical_accuracy: 0.9782\n",
      "Epoch 176/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0109 - categorical_accuracy: 0.9754 - val_loss: 0.0093 - val_categorical_accuracy: 0.9784\n",
      "Epoch 177/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0110 - categorical_accuracy: 0.9756 - val_loss: 0.0104 - val_categorical_accuracy: 0.9778\n",
      "Epoch 178/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0106 - categorical_accuracy: 0.9767 - val_loss: 0.0094 - val_categorical_accuracy: 0.9807\n",
      "Epoch 179/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0109 - categorical_accuracy: 0.9759 - val_loss: 0.0099 - val_categorical_accuracy: 0.9803\n",
      "Epoch 180/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0108 - categorical_accuracy: 0.9759 - val_loss: 0.0099 - val_categorical_accuracy: 0.9791\n",
      "Epoch 181/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0107 - categorical_accuracy: 0.9768 - val_loss: 0.0107 - val_categorical_accuracy: 0.9770\n",
      "Epoch 182/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0106 - categorical_accuracy: 0.9768 - val_loss: 0.0101 - val_categorical_accuracy: 0.9791\n",
      "Epoch 183/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0105 - categorical_accuracy: 0.9773 - val_loss: 0.0097 - val_categorical_accuracy: 0.9788\n",
      "Epoch 184/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0107 - categorical_accuracy: 0.9761 - val_loss: 0.0097 - val_categorical_accuracy: 0.9784\n",
      "Epoch 185/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0103 - categorical_accuracy: 0.9769 - val_loss: 0.0104 - val_categorical_accuracy: 0.9786\n",
      "Epoch 186/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0108 - categorical_accuracy: 0.9761 - val_loss: 0.0100 - val_categorical_accuracy: 0.9782\n",
      "Epoch 187/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0105 - categorical_accuracy: 0.9766 - val_loss: 0.0106 - val_categorical_accuracy: 0.9778\n",
      "Epoch 188/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0105 - categorical_accuracy: 0.9767 - val_loss: 0.0101 - val_categorical_accuracy: 0.9801\n",
      "Epoch 189/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0104 - categorical_accuracy: 0.9767 - val_loss: 0.0096 - val_categorical_accuracy: 0.9807\n",
      "Epoch 190/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0101 - categorical_accuracy: 0.9776 - val_loss: 0.0097 - val_categorical_accuracy: 0.9795\n",
      "Epoch 191/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0104 - categorical_accuracy: 0.9769 - val_loss: 0.0103 - val_categorical_accuracy: 0.9788\n",
      "Epoch 192/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0111 - categorical_accuracy: 0.9750 - val_loss: 0.0097 - val_categorical_accuracy: 0.9809\n",
      "Epoch 193/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0105 - categorical_accuracy: 0.9765 - val_loss: 0.0095 - val_categorical_accuracy: 0.9793\n",
      "Epoch 194/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0105 - categorical_accuracy: 0.9768 - val_loss: 0.0102 - val_categorical_accuracy: 0.9784\n",
      "Epoch 195/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0102 - categorical_accuracy: 0.9773 - val_loss: 0.0094 - val_categorical_accuracy: 0.9782\n",
      "Epoch 196/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0103 - categorical_accuracy: 0.9775 - val_loss: 0.0102 - val_categorical_accuracy: 0.9776\n",
      "Epoch 197/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0102 - categorical_accuracy: 0.9774 - val_loss: 0.0104 - val_categorical_accuracy: 0.9776\n",
      "Epoch 198/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93413/93413 [==============================] - 48s - loss: 0.0104 - categorical_accuracy: 0.9771 - val_loss: 0.0091 - val_categorical_accuracy: 0.9803\n",
      "Epoch 199/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0101 - categorical_accuracy: 0.9777 - val_loss: 0.0103 - val_categorical_accuracy: 0.9797\n",
      "Epoch 200/200\n",
      "93413/93413 [==============================] - 48s - loss: 0.0102 - categorical_accuracy: 0.9771 - val_loss: 0.0093 - val_categorical_accuracy: 0.9793\n",
      "CPU times: user 1h 50min 12s, sys: 17min 40s, total: 2h 7min 52s\n",
      "Wall time: 2h 42min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# model.fit(X_train, y_train, batch_size=2048, validation_data=(X_valid, y_valid), \\\n",
    "#           class_weight=class_weight, epochs=300, shuffle=True, verbose=1)\n",
    "model.fit(X_train, y_train, batch_size=1024, validation_data=(X_valid, y_valid), \\\n",
    "          epochs=200, shuffle=True, verbose=1)\n",
    "model.save(os.path.join(OUTPUT_PATH, MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4917/4917 [==============================] - 1s     \n"
     ]
    }
   ],
   "source": [
    "preds_proba = model.predict(X_valid, batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 정확도 : 0.98312\n",
      "\n",
      " -------------------------- \n",
      "\n",
      "preds     _silence  _unknown  down   go  left   no  off   on  right  stop  \\\n",
      "actuals                                                                     \n",
      "_silence        49         2     0    0     0    0    0    0      0     0   \n",
      "_unknown         0      3030     2    2     0    1    0    0      1     1   \n",
      "down             0         7   167    0     0    1    0    0      0     0   \n",
      "go               0         5     0  161     0    0    0    0      1     0   \n",
      "left             0         9     0    0   202    0    0    0      0     0   \n",
      "no               0         1     2    1     0  175    0    0      0     0   \n",
      "off              0         7     0    0     0    0  167    0      0     0   \n",
      "on               0        11     0    0     0    0    1  190      0     0   \n",
      "right            0         9     0    0     0    0    0    0    163     0   \n",
      "stop             0         4     0    0     0    0    0    0      0   186   \n",
      "up               0         3     0    0     0    0    3    0      0     0   \n",
      "yes              1         1     0    0     0    0    0    0      0     0   \n",
      "\n",
      "preds      up  yes  \n",
      "actuals             \n",
      "_silence    0    0  \n",
      "_unknown    1    0  \n",
      "down        0    0  \n",
      "go          0    0  \n",
      "left        0    0  \n",
      "no          0    0  \n",
      "off         3    0  \n",
      "on          0    0  \n",
      "right       0    0  \n",
      "stop        2    0  \n",
      "up        187    0  \n",
      "yes         1  157  \n",
      "\n",
      " -------------------------- \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   _silence       0.98      0.96      0.97        51\n",
      "   _unknown       0.98      1.00      0.99      3038\n",
      "       down       0.98      0.95      0.97       175\n",
      "         go       0.98      0.96      0.97       167\n",
      "       left       1.00      0.96      0.98       211\n",
      "         no       0.99      0.98      0.98       179\n",
      "        off       0.98      0.94      0.96       177\n",
      "         on       1.00      0.94      0.97       202\n",
      "      right       0.99      0.95      0.97       172\n",
      "       stop       0.99      0.97      0.98       192\n",
      "         up       0.96      0.97      0.97       193\n",
      "        yes       1.00      0.98      0.99       160\n",
      "\n",
      "avg / total       0.98      0.98      0.98      4917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = [LABELS[i] for i in np.argmax(preds_proba, axis=1)]\n",
    "actuals = [LABELS[i] for i in np.argmax(y_valid, axis=1)]\n",
    "print('* 정확도 : %.5f' % (np.sum(np.array(actuals) == np.array(preds)) / float(len(actuals))))\n",
    "preds = pd.Categorical(preds, categories=LABELS)\n",
    "actuals = pd.Categorical(actuals, categories=LABELS)\n",
    "print('\\n -------------------------- \\n')\n",
    "print(pd.crosstab(actuals, preds, rownames=['actuals'], colnames=['preds']))\n",
    "print('\\n -------------------------- \\n')\n",
    "print(classification_report(actuals, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for i in range(100):\n",
    "#     t= preds_proba[i].round(decimals=2)\n",
    "#     print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = load_model(os.path.join(OUTPUT_PATH, 'cnn_new_400.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 제출파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 16s, sys: 3.82 s, total: 2min 20s\n",
      "Wall time: 2min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X = []\n",
    "submission_fpaths = sorted(glob(os.path.join(TEST_PATH, r'*wav')))\n",
    "for fpath in submission_fpaths:\n",
    "    sample_rate, samples = wavfile.read(fpath)\n",
    "    _, _, specgram = log_specgram(samples, sample_rate=16000)\n",
    "    X.append(specgram)\n",
    "    \n",
    "X = np.array(X)\n",
    "X = X.reshape(tuple(list(X.shape) + [1]))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158538/158538 [==============================] - 28s    \n"
     ]
    }
   ],
   "source": [
    "preds_proba = model.predict(X, batch_size=2048, verbose=1)\n",
    "preds = [[L.replace('_', '') for L in LABELS][i] for i in np.argmax(preds_proba, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'fname': submission_fpaths, 'label': preds})\n",
    "df['fname'] = df['fname'].apply(lambda p: p.split('/')[-1])\n",
    "df.to_csv(os.path.join(OUTPUT_PATH, 'sub_' + MODEL_NAME.split('.')[0] + '.csv'), index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds_proba.round(decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown    103420\n",
       "no           5945\n",
       "off          5917\n",
       "up           5458\n",
       "on           5437\n",
       "left         5284\n",
       "stop         5176\n",
       "yes          5171\n",
       "go           4916\n",
       "right        4729\n",
       "down         4586\n",
       "silence      2499\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cw\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
